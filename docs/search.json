[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAnalyzing the Digital Skills Indicator in the Context of the EU Digital Decade\n\n\n\ndata analysis\n\n\ndata visualization\n\n\neurostat\n\n\ndigital skills indicator\n\n\n\nAn Exploratory Data Analysis of the components of the Digital Skills Indicator using data from the EU surveys on ICT use in households and by individuals provided by…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe components of EU’s Digital Intensity Index (DII) in 2023\n\n\n\ndata analysis\n\n\ndata visualization\n\n\neurostat\n\n\ndigital intensity index\n\n\n\nComparative Analysis of the EU’s Digital Intensity Index’s 12 components in 2023.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEU’s Digital Intensity Index (DII) in 2023\n\n\n\ndata analysis\n\n\ndata visualization\n\n\neurostat\n\n\ndigital intensity index\n\n\n\nThe level of digital intensity of EU enterprises. An analysis of data from the EU survey on ICT usage and e-commerce in enterprises provided by Eurostat, the Statistical…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Analysis (Part I)\n\n\n\ntime series\n\n\ntrends\n\n\nSQL\n\n\ndata analysis\n\n\ndata visualization\n\n\n\nAnalyzing time series data and looking for trends.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Sales Revenue and Orders\n\n\n\nSQL\n\n\ndata analysis\n\n\ndata visualization\n\n\nsales data\n\n\n\nAnalyzing annual and monthly sales revenue and orders using data from the Northwind database.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Driver Analysis to understand customer loyalty in a financial organization (case study)\n\n\n\nkey driver analysis\n\n\ndata cleaning\n\n\ndata visualization\n\n\n\nAnalyzing a customer satisfaction survey to determine the most important factors influencing customer loyalty.\n\n\n\nJan 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a Dashboard with Quarto\n\n\n\ndashboard\n\n\ndata visualization\n\n\n\nCreating a customized dashboard with Quarto to visualize and present data.\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test\n\n\n\nsummary statistics\n\n\nindependent samples t-test\n\n\nquantitative analysis\n\n\n\nDiscover how to extract valuable insights from data using summary statistics and the independent samples t-test, with a case study on team diversity within a large…\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test\n\n\n\ncross-table\n\n\nchi-squared test\n\n\nquantitative analysis\n\n\n\nDiscover how to extract valuable insights from categorical data using cross-tables and the chi-squared test, with a case study on gender representation in senior roles.\n\n\n\nSep 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployees’ perception of well-being at work: A qualitative study\n\n\n\nqualitative analysis\n\n\nempirical study\n\n\nwell-being at work\n\n\n\nAn empirical study that explores how employees perceive the work environment factors and managers’ behaviors influencing their well-being at work.\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "",
    "text": "For this analysis, I will use sales data from Northwind database1 to answer the following questions:"
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "Steps to answer the questions",
    "text": "Steps to answer the questions\n\nIdentify the tables that contain the sales revenue and order data\nUnderstand the schema, columns that store date, sales, and orders\nUse SQL and R to retrieve, prepare and summarize data\nData Visualization\nData Interpretation\n\n\nPrerequisites\n\nlibrary(DBI) \nlibrary(dbplyr)\nlibrary(tidyverse) \nlibrary(knitr)\nlibrary(DT)\nlibrary(patchwork)\nlibrary(glue)\nsleep_default &lt;- 3\ntheme_set(theme_minimal(base_size = 12))\n\n\n\nConnect to the database\n\ncon &lt;- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = 'northwind', \n                 host = 'localhost', \n                 port = 5432, \n                 user = Sys.getenv(\"DEFAULT_POSTGRES_USER_NAME\"),\n                 password = Sys.getenv(\"DEFAULT_POSTGRES_PASSWORD\"))\n \ndbListTables(conn = con) ## list tables in the database\n\n [1] \"us_states\"              \"customers\"              \"orders\"                \n [4] \"employees\"              \"shippers\"               \"products\"              \n [7] \"order_details\"          \"categories\"             \"suppliers\"             \n[10] \"region\"                 \"territories\"            \"employee_territories\"  \n[13] \"customer_demographics\"  \"customer_customer_demo\" \"sales_revenue\"         \n\n\nThe data used to answer the questions can be found in two tables: orders and order_details.\n\n\nEntity Relationship Diagram\n\n\n\n\n\nSource DBeaver"
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-sales-revenue-and-number-of-orders",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-sales-revenue-and-number-of-orders",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "What is the annual sales revenue and number of orders?",
    "text": "What is the annual sales revenue and number of orders?\n\nsales_revenue &lt;- \"\n\nselect \n    min(o.order_date) as start_date,\n    max(o.order_date) as end_date,\n    extract(year from o.order_date) as year,\n    count(*) as order_number,\n    round(cast(sum(od.unit_price* od.quantity) as numeric),\n    2) as total_revenue,\n    round(cast(avg(od.unit_price* od.quantity)as numeric),\n    2) as avg_revenue\nfrom public.order_details od\ninner join public.orders as o on od.order_id = o.order_id\ngroup by year\norder by year;\n\"\nsales_revenue_tbl &lt;- (dbGetQuery(con, sales_revenue))\n\n\nkable(sales_revenue_tbl)\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nend_date\nyear\norder_number\ntotal_revenue\navg_revenue\n\n\n\n\n1996-07-04\n1996-12-31\n1996\n405\n226298.5\n558.76\n\n\n1997-01-01\n1997-12-31\n1997\n1059\n658388.8\n621.71\n\n\n1998-01-01\n1998-05-06\n1998\n691\n469771.3\n679.84\n\n\n\nAnnual summary of sales, number of orders and average sale\n\n\n\n\nCode\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\norder_number &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = as.numeric(order_number)))+\n  geom_col()+\n  geom_text(aes(label = as.numeric(order_number)), vjust = 1.5, color = \"white\")+\n  labs(\n    title = \"Number of Orders per Year\",\n    x = NULL,\n    y = \"Total Number of Orders\"\n  )+\n   theme_minimal()\n\navg_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = avg_revenue))+\n  geom_col()+\n  geom_text(aes(label = avg_revenue), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Average Dollars per Sale\",\n    x = \"Years between July 04, 1996 to May 06, 1998\",\n    y = \"Average Sale Amount\"\n  )+\n   theme_minimal()\n\n(total_revenue  + plot_spacer() + order_number + plot_layout(widths = c(4, -1, 4))) / avg_revenue\n\n\n\n\n\nNorthwind annual sales performance\n\n\n\n\n\nInsights\n\nThe available periods for 1996 and 1998 are shorter than those for 1997, making it difficult to interpret comparisons.\nThe graph shows that the sales revenue and the number of orders for the first five months of 1998 are greater than those for the last six months of the year 1996. However, since the data is not for the same period or consecutive years, it is difficult to determine the sales trend. Even though the context is different, we can say that sales revenue doubled in the first four months of 1998 compared with the last six months of 1996.\nIn the absence of data for an entire year for more than one year, we can look at the average dollar amount of sales. Based on the average dollar amount of sales, the graph shows an increase from year to year.\n\nHow about the monthly sales?"
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "What is the monthly variation in sales revenue?",
    "text": "What is the monthly variation in sales revenue?\nTo have the monthly sales revenue and number of orders, the previous query is modified as follows:\n\nmonthly_revenue &lt;- \"\nselect \n    cast(date_trunc('month', o.order_date) as date) as sales_month,\n    count(*) as total_number,\n    round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\nfrom public.orders o \ninner join public.order_details od on o.order_id = od.order_id \ngroup by sales_month\norder by sales_month;\n\"\nmonthly_revenue_tbl &lt;- (dbGetQuery(con, monthly_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\nNext, let’s create a graph to visualize the monthly sales data.\n\n\nCode\nmin_order_date &lt;- min(sales_revenue_tbl$start_date)\nmax_order_date &lt;- max(sales_revenue_tbl$end_date)\n\n(monthly_revenue_plot &lt;- ggplot(monthly_revenue_tbl, aes(x = sales_month, y = monthly_revenue))+\n  geom_col()+\n  scale_y_continuous(labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Sales by Month \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Sales Dollars\"\n  )+\n  theme_minimal())\n\n\n\n\n\nNorthwind monthly sales performance\n\n\n\n\nThe graph shows that there is much variation from one month to another. As there is month-over-month sales variation we can use the lag() function (SQL) to help to see the differences.\n\nmonthly_var_revenue &lt;- \"\nwith monthly_revenue as\n    (select \n        cast(date_trunc('month', o.order_date) as date) as sales_month,\n        count(*) as total_number,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    group by sales_month\n    order by sales_month),\n    prev_month_revenue as\n    (select \n        mr.sales_month,\n        mr.total_number,\n        mr.monthly_revenue,\n        lag(mr.monthly_revenue, 1, mr.monthly_revenue) over (order by mr.sales_month) as prev_month_revenue\n    from monthly_revenue mr)\nselect\n    pmr.sales_month,\n    pmr.total_number,\n    pmr.monthly_revenue,\n    prev_month_revenue,\n    pmr.monthly_revenue - pmr.prev_month_revenue as delta_revenue\nfrom prev_month_revenue pmr;\n\"\nmonthly_var_revenue_tbl &lt;- (dbGetQuery(con, monthly_var_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\nAlso, based on the graph, it is evident that the data follows a left-tailed distribution. I will utilize the summary() function in R to examine the descriptive statistics.\n\nmedian(monthly_var_revenue_tbl$delta_revenue)\n\n[1] 3707\n\n(summary_delta_revenue &lt;- summary(monthly_var_revenue_tbl$delta_revenue))\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-114732.0   -2405.0    3707.0    -447.5   14643.5   31563.0 \n\n\nThe median is positive ($3.707) while the mean is negative: (447.5). Month-over-month sales data shows a wide spread between the lower and upper quartiles.\nThe plot below shows how the sales vary month-over-month.\n\n\nCode\n(monthly_var_revenue_plot &lt;- ggplot(monthly_var_revenue_tbl, aes(x = sales_month, y = delta_revenue))+\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\", date_minor_breaks = \"3 months\") +\n  geom_line()+\n  scale_y_continuous(limits = c(-200000, 150000), labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Monthly Sales Variation \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Dollars Change\"\n  )+\n  theme_minimal()\n  )\n\n\n\n\n\nNorthwind monthly sales variation\n\n\n\n\n\nInsights\n\nWith real data, we would want to investigate more to understand the business context that occurred in May of 1998.\nFrom the data available in the Northwind database, we know that the data collection ended at the beginning of May 1998 which can explain the high difference compared with the previous month.\n\nWe have the data for the entire year of 1997 and we can look at revenue and number of orders together and compare the monthly data to the yearly average. By comparing monthly sales to yearly average, businesses can identify which months consistently perform above or below average, helping in informing various business decisions."
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "How do monthly revenue and orders compare to the yearly average?",
    "text": "How do monthly revenue and orders compare to the yearly average?\n\nmonth_data_year_avg &lt;- \"\nwith montly_data as\n    (select \n        cast(date_trunc('month', o.order_date) as date) year_month,\n        count(*) as monthly_orders,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    where extract(year from o.order_date) = 1997 \n    group by year_month\n    order by year_month)\nselect\n    md.year_month,\n    md.monthly_orders, \n    md.monthly_revenue\nfrom montly_data md\norder by md.year_month;\n\"\nmonth_data_year_avg_tbl &lt;- (dbGetQuery(con,month_data_year_avg))\n\n\n\n\n\nMonthly sales data and Yearly averages\n\n\n\n(yearly_revenue_average &lt;- mean(month_data_year_avg_tbl$monthly_revenue))\n\n[1] 54865.67\n\n(yearly_order_average &lt;- mean(month_data_year_avg_tbl$monthly_orders))\n\ninteger64\n[1] 88\n\n\n\n\nCode\nmonth_data_year_avg_rev_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = monthly_revenue))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  geom_hline(yintercept = yearly_revenue_average ,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_revenue_average +1000,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Revenue Average \\n\",\n                  \"Monthly Revenue \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Revenue Dollars\"\n  )+\n  theme_minimal()\n\n\nmonth_data_year_avg_order_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = as.numeric(monthly_orders)))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  geom_hline(yintercept = yearly_order_average,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_order_average +1,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Order Average \\n\",\n                  \"Monthly Orders \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Number of Orders\"\n  )+\n  theme_minimal()\n\n\nmonth_data_year_avg_rev_plot + plot_spacer() + month_data_year_avg_order_plot+ plot_layout(widths = c(4, -1, 4))\n\n\n\n\n\n\n\n\n\n\nInsights\n\nBoth the monthly sales revenue and number of orders vary widely compared with the yearly average.\nThe highest values for sales revenue are at the beginning and the end of the year while the lowest values are in the first half of the year. This indicates that the business can have seasonal fluctuations in sales.\nThis is also supported by the number of orders placed each month. The highest number of orders is in the second half of the year which can explain the increased revenue at the final of the year.\n\nKnowing in which months the business performs below or above the average can help in the strategic planning of the company and the allocation of resources.\n\nFor example :\n\nwhen the sales volumes are low the business can design loyalty programs that encourage repeated business during slower months;\nduring off-peak times the company can plan training programs to ensure that the staff are fully equipped for busy periods;\ntargeted campaigns by allocating budgets to peak seasons to maximize returns or promotions during low-performing months to increase sales.\n\n\nComparing monthly sales data to yearly averages is a powerful analytical tool that provides deep insights into business performance, aids in strategic planning and drives informed decision-making. It allows businesses to adapt proactively to changes, optimize operations, and achieve better financial outcomes.\n\n# Close the database connection\ndbDisconnect(con)"
  },
  {
    "objectID": "posts/sales_revenue/1_sales_revenue_and_orders.html#footnotes",
    "href": "posts/sales_revenue/1_sales_revenue_and_orders.html#footnotes",
    "title": "Analyzing Sales Revenue and Orders",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Northwind database is a sample database that was originally created by Microsoft for demonstrating the features of their database management systems. It contains a variety of tables and data related to a fictional company called Northwind Traders, which imports and exports specialty foods from around the world.↩︎"
  },
  {
    "objectID": "posts/employee-well-being-at-work/index.html#presentation",
    "href": "posts/employee-well-being-at-work/index.html#presentation",
    "title": "Employees’ perception of well-being at work: A qualitative study",
    "section": "Presentation",
    "text": "Presentation\nUnable to display PDF file. Download instead."
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html",
    "href": "posts/digital_intensity_index_components_eu/index.html",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "",
    "text": "In the previous post on analyzing EU’s Digital Intensity Index, I enumerated the 12 components of the index. As a result of learning more about the index’s components, I was curious to know how the enterprises that participated in the survey performed on each component.\nIn this post, I analyze the components of the DII index for each EU country, specifically, I will answer the question:"
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#build-data-set-for-analysis",
    "href": "posts/digital_intensity_index_components_eu/index.html#build-data-set-for-analysis",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "1. Build Data Set for Analysis",
    "text": "1. Build Data Set for Analysis\nFor this analysis, I use open data provided by Eurostat, the results of the EU survey on ICT usage and e-commerce in enterprises 2023, available in MS-Access format. This format allows me to work with database files and make the data set I need for the analysis.\n\n\nCode\nsql_dataset &lt;- '\nSELECT \n  y.\"ExpPeriod\" AS \"Year\",\n  c.\"ExpCountryCaption\" AS \"Country\",\n  r.\"ExpRegionCaption\" AS \"Region\",\n  i.\"ExpIndicatorCaption\" AS \"Indicator\",\n  r.\"ExpRegion\" AS \"Geo\",\n  es.\"ExpEntSizeCaption\" AS \"EnterpriseSize\",\n  a.\"ExpActivityCaption\" AS \"Activity\",\n  u.\"ExpUnitCaption\" AS \"Unit\",\n  COALESCE(CAST(dwa.\"Value\" AS decimal) *100, 0) AS \"Value\",\n  dwa.\"Flags\" ,\n  n.\"Note\" \nFROM public.\"DataWithAggregates\" dwa \nINNER JOIN public.\"Years\" y ON dwa.\"IdYear\" = y.\"IdYear\" \nINNER JOIN public.\"Countries\" c ON dwa.\"IdCountry\" = c.\"IdCountry\" \nINNER JOIN public.\"Indicators\" i ON dwa.\"IdIndicator\" = i.\"IdIndicator\" \nINNER JOIN public.\"EntSizes\" es ON dwa.\"IdEntSize\" = es.\"IdEntSize\" \nINNER JOIN public.\"Activities\" a ON dwa.\"IdActivity\" = a.\"IdActivity\" \nINNER JOIN public.\"Regions\" r ON dwa.\"IdRegion\" = r.\"IdRegion\" \nINNER JOIN public.\"CustBrkdwns\" cb ON dwa.\"IdCustBrkdwn\" = cb.\"IdCustBrkdwn\" \nINNER JOIN public.\"Units\" u ON dwa.\"IdUnit\" = u.\"IdUnit\" \nINNER JOIN public.\"Notes\" n ON dwa.\"IdYear\"  = n.\"IdYear\" AND dwa.\"IdNote\" = n.\"IdNote\" \nWHERE y.\"IdYear\"  IN (23)\n  AND c.\"IdCountry\" IN (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,22,23,25,26,27,28,29,30,45)\n  AND i.\"IdIndicator\" IN (1525, 2256, 315, 1499, 1598, 2347, 1769, 1764, 3124, 2305, 1068, 3122)\n  AND es.\"IdEntSize\" IN (2578)\n  AND a.\"IdActivity\" IN (2585) \n  AND cb.\"IdCustBrkdwn\" IN (2632) \n  AND u.\"IdUnit\" IN (16)\nORDER BY \"Year\", \"Value\"'\n\nsql_dataset_tbl &lt;- as_tibble(dbGetQuery(con,sql_dataset))"
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#prepare-the-data",
    "href": "posts/digital_intensity_index_components_eu/index.html#prepare-the-data",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "2. Prepare the Data",
    "text": "2. Prepare the Data\n\n2.1 Data Description\nData from the EU survey on ICT (Information and Communication Technologies) usage and e-commerce in enterprises 2023 provided by Eurostat, are collected annually by the National Statistical Institutes and are based on the annual Eurostat model questionnaires on ICT usage and e-commerce in enterprises.\nThe model questionnaire on ICT usage and e-commerce in enterprises provides a large variety of variables covering among others the following areas:\n\nGeneral information about ICT systems\nAccess to and use of the internet including mobile use of the internet\ne-commerce\ne-business including Artificial Intelligence, Data analytics, Cloud computing, Internet of Things, Big data analysis, 3D printing, Robotics, etc.\nICT specialists, training on ICT and e-skills\nICT security\nICT and the environment1.\n\n\nThe structure, data types, and content of the data set.\n\nThe data set includes 822 observations and 11 variables.\nThe data type is string (character) for all variables except the Value variable which is of data type numeric (double).\nOnly the Flags and Note variables are missing values. These variables have values only if there is something special to mention.\n\n\n\nCode\nglimpse(sql_dataset_tbl)\n\n\nRows: 822\nColumns: 11\n$ Year           &lt;chr&gt; \"2023A00\", \"2023A00\", \"2023A00\", \"2023A00\", \"2023A00\", …\n$ Country        &lt;chr&gt; \"Romania\", \"Romania\", \"Romania\", \"Romania\", \"Romania\", …\n$ Region         &lt;chr&gt; \"Sud-Vest Oltenia\", \"Sud-Est\", \"Macroregiunea doi\", \"No…\n$ Indicator      &lt;chr&gt; \"Enterprises use at least one of the AI technologies: A…\n$ Geo            &lt;chr&gt; \"RO41\", \"RO22\", \"RO2\", \"RO11\", \"RO21\", \"RO4\", \"RO1\", \"R…\n$ EnterpriseSize &lt;chr&gt; \"10 persons employed or more\", \"10 persons employed or …\n$ Activity       &lt;chr&gt; \"All activities, without financial sector\", \"All activi…\n$ Unit           &lt;chr&gt; \"Percentage of enterprises\", \"Percentage of enterprises…\n$ Value          &lt;dbl&gt; 0.1516, 0.4106, 0.6444, 0.7938, 0.8899, 0.9024, 1.0346,…\n$ Flags          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ Note           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\nCode\nskimr::skim(sql_dataset_tbl)\n\n\n\nData summary\n\n\nName\nsql_dataset_tbl\n\n\nNumber of rows\n822\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nYear\n0\n1.00\n7\n7\n0\n1\n0\n\n\nCountry\n0\n1.00\n5\n41\n0\n28\n0\n\n\nRegion\n0\n1.00\n4\n60\n0\n84\n0\n\n\nIndicator\n0\n1.00\n33\n131\n0\n12\n0\n\n\nGeo\n0\n1.00\n2\n4\n0\n86\n0\n\n\nEnterpriseSize\n0\n1.00\n27\n27\n0\n1\n0\n\n\nActivity\n0\n1.00\n40\n40\n0\n1\n0\n\n\nUnit\n0\n1.00\n25\n25\n0\n1\n0\n\n\nFlags\n806\n0.02\n1\n1\n0\n1\n0\n\n\nNote\n808\n0.02\n72\n92\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nValue\n0\n1\n38.27\n25.05\n0.15\n17.74\n34.69\n52.68\n98.84\n▇▇▇▃▂\n\n\n\n\n\n\n\nDescription of variables\nThe data set contains the following variables:\n\nYear - the year when the survey was conducted (2023)\nCountry - the EU countries (27) + European Union - 27 countries (from 2020)\nRegion the regions of each country\nGeo - the geographical code for each region\nIndicator - the 12 components of the Digital Intensity Index in 2023\nEnterprise size - 10 persons employed or more\nActivity - All activities, without financial sector\nUnit - Percentage of enterprises\nValue - the value, rounded to 4 decimals\nFlags - The flags attached to the value if it is the case\nNote - The text of a specific note mentioned if it is the case"
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#data-cleaning",
    "href": "posts/digital_intensity_index_components_eu/index.html#data-cleaning",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nAs we see, there are no necessary missing values to address and the data type is correct for each variable.\nThe Indicator values are too long to be displayed when visualizing the data and I will change them with a shorter version.\nI will exclude the data for regions and keep only data for the 27 countries.\n\n\nCode\ndata_cleaned &lt;- sql_dataset_tbl |&gt;\n  filter(Geo == \"_z\" &\n        Country != \"European Union - 27 countries (from 2020)\") |&gt;\n  mutate(Value = round(Value, 1),\n         Indicator_code = case_when(\n           Indicator == \"Enterprises use at least one of the AI technologies: AI_TTM, AI_TSR, AI_TNLG, AI_TIR, AI_TML, AI_TPA, AI_TAR\" ~ \"Use any AI technology\",\n           Indicator == \"Enterprises where web sales are more than 1% of total turnover and B2C web sales more than 10% of the web sales\" ~ \"Have web sales &gt;1% turnover, B2C web sales &gt;10% web sales\",\n           Indicator == \"Buy cloud computing services used over the internet\" ~ \"Buy cloud computing services used over the internet\",\n           Indicator == \"Enterprises using Customer Relationship Management (CRM) software (as of 2023)\" ~ \"Use CRM software\",\n           Indicator == \"Enterprises where more than 50% of the persons employed have access to the internet for business purposes\" ~\"Access to the internet for over 50% of employees\",\n           Indicator == \"Enterprises who have ERP software package to share information between different functional areas\" ~\"Have ERP software\",\n           Indicator == \"Enterprises with e-commerce sales of at least 1% turnover\" ~\"Have e-commerce sales of at least 1% turnover\",\n           Indicator == \"Use two or more social media (as of 2014)\" ~\"Use two or more social media\",\n           Indicator == \"Enterprises buying sophisticated or intermediate CC services, at least one of: CC_PFACC, CC_PERP, CC_PCRM, CC_PSEC, CC_PDB, CC_PDEV\" ~ \"Buy sophisticated or intermediate cloud computing services\",\n           Indicator == \"Data analytics for the enterprise is performed by the enterprise's own employees or by an external provider\" ~\"Use data analytics*\", \n           Indicator == \"Use any social media (as of 2014)\" ~ \"Use any social media\",\n           Indicator == \"The maximum contracted download speed of the fastest fixed line internet connection is at least 30 Mb/s\" ~ \"Have fastest fixed line internet at least 30 Mb/s\",\n           TRUE ~\"other\")) |&gt;\n  select(Country, Indicator, Indicator_code, Value)\n\nhead(data_cleaned)\n\n\n# A tibble: 6 × 4\n  Country  Indicator                                        Indicator_code Value\n  &lt;chr&gt;    &lt;chr&gt;                                            &lt;chr&gt;          &lt;dbl&gt;\n1 Romania  Enterprises use at least one of the AI technolo… Use any AI te…   1.5\n2 Romania  Enterprises where web sales are more than 1% of… Have web sale…   3.1\n3 Bulgaria Enterprises use at least one of the AI technolo… Use any AI te…   3.6\n4 Poland   Enterprises use at least one of the AI technolo… Use any AI te…   3.7\n5 Hungary  Enterprises use at least one of the AI technolo… Use any AI te…   3.7\n6 Poland   Enterprises where web sales are more than 1% of… Have web sale…   3.9\n\n\n\nIdentify outliers (IQR method)\nOne more thing I will do in this step is to investigate if there are outliers. An outlier is a data point that lies outside the overall pattern in a distribution. To detect outliers in the data set I will use the interquartile range (IQR) method. This method indicates that any values in a boxplot that fall outside of Q1 and Q3 are considered outliers. First, let’s visualize the distribution.\n\n\nCode\nggplot(data_cleaned, aes(x = Indicator_code, y = Value))+\n  geom_boxplot(width = 0.1, color = \"black\", alpha = 0.2) +\n  scale_x_discrete(labels = scales::label_wrap(10)) +\n  scale_y_continuous(labels = scales::percent_format(scale = 1))+\n  labs(\n    title = \"EU's digital intensity index components distribution\",\n    caption = \"*Data analytics was the new component added in 2023,replacing the 'Enterprises use IoT'.\"\n  ) +\n  theme_ts() +\n  theme(\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 6.5),\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(size = 18),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nThe chart shows that the components “Access to the internet for over 50% of employees” and “Use CRM software” have values that lies outside the overall pattern in the distribution.\nNext, I will investigate to find out more about these values.\n\n\nCode\n# Detect outliers using IQR method\noutliers &lt;- data_cleaned |&gt;\n  group_by(Indicator_code) |&gt;\n  mutate(\n    Q1 = round(quantile(Value, 0.25),1),\n    Q3 = round(quantile(Value, 0.75),1),\n    IQR = round((Q3 - Q1),1),\n    Lower_Bound = round(Q1 - (1.5 * IQR), 1),\n    Upper_Bound = round(Q3 + (1.5 * IQR), 1),\n    Outlier = ifelse(Value &lt; Lower_Bound | Value &gt; Upper_Bound, TRUE, FALSE)\n  ) |&gt;\n  filter(Outlier == TRUE) |&gt;\n  select(-Indicator)\n\noutliers |&gt;\n  datatable(options = list(pageLength = 5, scrollY = TRUE))\n\n\n\n\n\n\nIn Romania, Bulgaria, and Greece, the proportion of enterprises where more than 50% of employees have internet access for business purposes is the lowest, deviating significantly from the overall pattern. Conversely, Sweden, the Netherlands, Denmark, and Finland exhibit the highest proportions of such enterprises, also deviating from the overall pattern. Regarding the use of Customer Relationship Management (CRM) software, Finland and the Netherland stand out with the highest proportions of enterprises using CRM, again deviating from the overall pattern.\nThe analysis of the outliers partially answered the question, showing what countries scored the highest or lowest on two out of twelve components. I will move on with the analysis to find out which countries scored the highest or lowest on all digital intensity index components."
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#create-data-frame-for-the-visualization",
    "href": "posts/digital_intensity_index_components_eu/index.html#create-data-frame-for-the-visualization",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "Create Data Frame for the Visualization",
    "text": "Create Data Frame for the Visualization\nBefore making the graph and answer the question, I will create the data frame I need for the visualization. I need to find out the maximum and minimum values for each components and country, then I will select only the necessary variables : the digital intensity index components (Indicator_code), the countries (Country), the Value, and the highest and lowest percentages of the enterprises on each component (Rank_value).\n\n\nCode\nmax_min_value &lt;- data_cleaned |&gt;\n  group_by(Indicator_code) |&gt;\n  mutate(Rank_value = rank(Value)) |&gt;\n  filter(Rank_value %in% c(1, 27)) |&gt;\n  mutate(Rank_value = ifelse(Rank_value == 1, \"Lowest\", \"Highest\")) |&gt;\n  select(Country, Indicator_code, Value, Rank_value) |&gt;\n  ungroup()\n\n# Set 'Rank_value' factor levels to ensure \"Highest\" is first\nmax_min_value &lt;- max_min_value |&gt;\n  mutate(Rank_value = factor(Rank_value, levels = c(\"Highest\", \"Lowest\")))\n\n# Arrange by Value to get the correct order\nmax_min_value &lt;- max_min_value |&gt;\n  arrange(desc(Value))\n\n# Convert 'Indicator_code' to a factor with levels ordered by 'Value', then reverse the order\nmax_min_value &lt;- max_min_value |&gt;\n  mutate(Indicator_code = factor(Indicator_code, levels = rev(unique(Indicator_code))))\n\n\nmax_min_value  |&gt;\n  datatable(options = list(pageLength = 5, scrollY = TRUE))"
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#which-countries-rank-highest-or-lowest-on-the-twelve-components-of-the-eus-digital-intensity-index",
    "href": "posts/digital_intensity_index_components_eu/index.html#which-countries-rank-highest-or-lowest-on-the-twelve-components-of-the-eus-digital-intensity-index",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "Which countries rank highest or lowest on the twelve components of the EU’s digital intensity index?",
    "text": "Which countries rank highest or lowest on the twelve components of the EU’s digital intensity index?\n\n\nCode\nplot &lt;- ggplot(max_min_value, aes(\n  x = Indicator_code,\n  y = Value,\n  fill = Rank_value\n)) +\n  geom_bar(position = position_dodge2(width = NULL,\n                                      padding = 0.1,\n                                      preserve = \"single\",\n                                      reverse = TRUE),\n           stat = \"identity\",\n           width = 0.95) +\n  coord_flip() +\n  scale_x_discrete(labels = label_wrap(30)) +\n  scale_y_continuous(limits = c(0,120)) +\n  scale_fill_manual(values = c(\"Highest\" = \"#99AACC\", \"Lowest\" = \"#26324B\")) +\n  ggtext::geom_textbox(aes(\n    label = paste0(\"&lt;span style='font-size:11pt'&gt;&lt;br&gt;\",\n                   Value, \"%\",\n                   \"&lt;br&gt;&lt;/span&gt;\",\n                   Country),\n    hjust = ifelse(Rank_value == \"Lowest\",  0.65, 1),\n    halign = ifelse(Rank_value == \"Lowest\", 1, 1),\n    vjust = ifelse(Rank_value == \"Lowest\" , 1, -0.2),\n    fill = ifelse(Rank_value == \"Lowest\" ,\"white\", \"#1A242F\")),\n    size = 3,\n    family = \"Georgia\",\n    fill = NA,\n    box.colour = NA,\n    fontface = \"bold\",\n    position = position_dodge2(width = 0.95, preserve = \"single\")) +\n  labs(\n     title = \"EU's Digital Intensity Index composition in 2023\",\n    subtitle = \"Comparative analysis based on highest and lowest scores &lt;br&gt;% enterprises (10 persons employed or more)\",\n    caption = \"Graph: @cozminasecula \\nData: Eurostat, EU survey on ICT usage and e-commerce in enterprises (2023). \\n*Data analytics was the new component added in 2023, replacing the 'Enterprises use IoT'.\") +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank() ,\n    axis.title = element_blank(), \n    axis.text.x = element_blank() ,\n    axis.text = element_text(size = 12,\n                             family = \"Georgia\",\n                             color = \"#1A242F\"),\n    plot.subtitle = ggtext::element_textbox_simple(size = 18,\n                                                   vjust = 1,\n                                                   margin = margin(0, 0, 12, 0),\n                                                   color = \"#1A242F\",\n                                                   family = \"Georgia\"),\n    plot.title.position = \"plot\",\n    plot.title = element_textbox_simple(size = 22,\n                              color = \"#1A242F\",\n                              face = \"bold\", \n                              family = \"Georgia\",\n                              margin = margin(12, 0, 12, 0)),\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(color = \"#828282\" , size = 8, hjust = 0, family = \"Georgia\"),\n    legend.position = \"top\",\n    legend.text.align = 0,\n    legend.background = element_blank(),\n    legend.title = element_blank(), \n    legend.justification = 0.04,\n    legend.text = element_text(family = \"Georgia\",\n                               size = 14,\n                               color = \"#1A242F\"),\n  )\n\n  \nggsave(plot, filename = \"dii_eu_components_bar_plot.png\",\n      width = 9.5,\n      height = 11,\n      dpi = 300)\n\n\n\n\nHighest score\n\nThe largest percentage of enterprises having the fastest fixed line internet connection of at least 30 Mbps is in Romania, with 96.6%.\n87.1% of enterprises that use any social media are in Malta, which is the highest score. This country also has the highest percentage, 21.8%, of enterprises where web sales are more than 1% of total turnover and B2C web sales more than 10% of the web sales.\nIn Sweden, the highest percentage of enterprises, 83.6%, have more than 50% of employees with internet access for business purposes.\nFinland, the country with a very high digital intensity index level, scored highest on four out of twelve components:\n\n78.3% of enterprises buy cloud computing services used over the internet\n73% of enterprises buy sophisticated or intermediate cloud computing services\n53.6 % of enterprises use two or more social media\n49.4% of enterprises use CRM software\n\nDenmark scored highest on three out of twelve components of the digital intensity index:\n\n67.3% of enterprises that ERP software\n36.5% of enterprises have e-commerce sales of at least 1% turnover\n15.2% of enterprises use any AI technology\n\nData analytics for the enterprise is performed by the enterprise’s own employees or by an external provider is a new component added in 2023, replacing the “Enterprise use IoT”. The highest score was in Hungary where 53.2% of enterprises use data analytics.\n\n\n\nLowest score\n\nHungary is the country with 68.9% of enterprises having the fastest fixed line internet connection of at least 30 Mbps.\nIn Slovenia, only 19.1% of enterprises use data analytics, the lowest score among the EU countries.\nIn Luxembourg, only 9.4% of of enterprises have e-commerce sales of at least 1% turnover.\nRomania the country with a very low digital intensity index level, scored lowest on four out of twelve components:\n\n25.6% of enterprises have more than 50% of employees with internet access for business purposes.\n10.1% of enterprises use CRM software\n3.1% of enterprises where web sales are more than 1% of total turnover and B2C web sales more than 10% of the web sales.\n1.5% of enterprises use any AI technology\n\nBulgaria scored lowest on five out of twelve component sof the digital intensity index:\n\n38% of enterprises use any social media\n17.5% of enterprises buy cloud computing services used over the internet\n14.2% of enterprises buy sophisticated or intermediate cloud computing services\n21.7% of enterprises have ERP software\n13.6% of enterprises use two or more social media"
  },
  {
    "objectID": "posts/digital_intensity_index_components_eu/index.html#footnotes",
    "href": "posts/digital_intensity_index_components_eu/index.html#footnotes",
    "title": "The components of EU’s Digital Intensity Index (DII) in 2023",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor more details the metadata are available here: https://ec.europa.eu/eurostat/cache/metadata/en/isoc_e_esms.htm↩︎"
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html",
    "href": "posts/2023-12-05-create-a-dashboard/index.html",
    "title": "Creating a Dashboard with Quarto",
    "section": "",
    "text": "Over the last few weeks, I have spent some time doing data analysis and visualization. The chosen tools for analysis, documenting, presenting, and sharing my work are R and Quarto. To acquire specific skills and knowledge, I adopted a project-based approach and designed small projects around my learning objectives. However, I encountered a challenge: how can I effectively display different visual data in one place, such as a dashboard? I needed a tool to simplify data presentation while allowing for tailored content. That’s when I discovered Quarto Dashboards, a recent addition to Quarto. This feature allowed me to create a custom dashboard using R, complete with personalized colors and styles. In the following sections, I will share how I created the dashboard.\nYou can find the finished dashboard here:\nThe code for the dashboard can be accessed on GitHub."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#customization",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#customization",
    "title": "Creating a Dashboard with Quarto",
    "section": "Customization",
    "text": "Customization\nThe dashboard allows selecting from 25 themes or creating personalized themes using Sass. For this dashboard I opted for the litera theme and customized the background color of the navbar, text, and navigation."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#designing-navigation-bar",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#designing-navigation-bar",
    "title": "Creating a Dashboard with Quarto",
    "section": "Designing Navigation Bar",
    "text": "Designing Navigation Bar\nYou can choose a title and optionally add a logo or author. You can also decide between a single-page dashboard or multiple pages. I chose to use five pages in this dashboard."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#designing-the-dashboard-layout",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#designing-the-dashboard-layout",
    "title": "Creating a Dashboard with Quarto",
    "section": "Designing the Dashboard Layout",
    "text": "Designing the Dashboard Layout\nYou can arrange dashboard components using rows and columns and use tabsets to include multiple views of data. Here are more details and layout options. I organized the dashboard with columns and tabsets for clear visualizations. Each column had tabs displaying different visualizations. Below is an example: on the left, the average compensation by department and experience level is displayed, while on the right, a visualization summarizes the spread of data within each category."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#finalizing-and-sharing-the-dashboard",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#finalizing-and-sharing-the-dashboard",
    "title": "Creating a Dashboard with Quarto",
    "section": "Finalizing and Sharing the Dashboard",
    "text": "Finalizing and Sharing the Dashboard\nOnce your dashboard is done, you may want to share it with others. I hosted the dashboard using GitHub Pages. In the GitHub repository for your dashboard, go to ‘Settings’ and then ‘Pages.’ Select the branch and folder of your dashboard’s index.html file, click ‘Save,’ and you’ll get a URL to display your work. Here’s the final link for this dashboard: https://cozminasecula.github.io/dashboard/."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#case-study",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#case-study",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Case study",
    "text": "Case study\n\nFocused on diversity and inclusion (D&I)\nSourced from the book Predictive HR Analytics : Mastering the HR Metric\nWith data available here"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#problem-statement",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#problem-statement",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Problem Statement",
    "text": "Problem Statement\nA hypothetical company aims to employ data analytics to address a significant people problem: gender diversity.\nFrom a commercial perspective, the organization seeks to foster a greater diversity of thought in senior and strategic discussions. On the other hand, from a people perspective, the organization wants to assess whether it maintains gender balance by providing positive role models for younger employees."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analysis-question",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analysis-question",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Analysis question",
    "text": "Analysis question\nAre women underrepresented in senior leadership roles within the organization?"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#data-preparation-and-exploration",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#data-preparation-and-exploration",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Data Preparation and exploration",
    "text": "Data Preparation and exploration\n\nData set\nFor this case study I used a data set available here.\n\nDescriptionData summary\n\n\n\nA hypothetical organization, a management consulting firm, has 1.493 employees.\nThe data set contains 11 variables.\nData type (in the data set): numeric for all variables.\n\n\n\n\ndiversity1 &lt;- read_csv(\"./diversity1.csv\")\n\nskimr::skim(diversity1)\n\n\nData summary\n\n\nName\ndiversity1\n\n\nNumber of rows\n1493\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBossGender\n0\n1.00\n1.69\n0.46\n1\n1\n2\n2\n2\n▃▁▁▁▇\n\n\nGender\n2\n1.00\n1.50\n0.50\n1\n1\n1\n2\n2\n▇▁▁▁▇\n\n\nJobGrade\n0\n1.00\n4.02\n1.73\n1\n2\n4\n5\n8\n▆▅▇▃▂\n\n\nAge\n0\n1.00\n38.27\n9.57\n16\n31\n38\n46\n66\n▂▇▇▅▁\n\n\nTenure\n0\n1.00\n10.00\n9.88\n0\n2\n7\n14\n42\n▇▃▁▁▁\n\n\nStatus\n0\n1.00\n1.24\n0.76\n1\n1\n1\n1\n5\n▇▁▁▁▁\n\n\nPerformanceScore\n203\n0.86\n4.13\n0.34\n4\n4\n4\n4\n5\n▇▁▁▁▁\n\n\nBossPerformance\n44\n0.97\n3.74\n0.65\n2\n3\n4\n4\n5\n▁▅▁▇▂\n\n\nDivision\n0\n1.00\n8.27\n3.91\n1\n5\n10\n11\n12\n▂▁▁▁▇\n\n\nCountry\n0\n1.00\n8.21\n1.76\n1\n8\n9\n9\n10\n▁▁▁▂▇\n\n\nleaver\n2\n1.00\n1.07\n0.26\n1\n1\n1\n1\n2\n▇▁▁▁▁\n\n\n\n\n\n\n\n\n\n\nVariables of interest\nTo answer the question, the variables of interest are JobGrade and Gender.\nThe organization has eight distinct job grades, which are detailed below.\nOf the 1.493 employees, 746 are female and 745 are male.\n\n\n\n\n\nLevel\nJob Grade\n\n\n\n\n1\nClerical/Officer\n\n\n2\nAdministrator/Assistant\n\n\n3\nGraduate/Trainee Consultant\n\n\n4\nConsultant\n\n\n5\nSenior Consultant\n\n\n6\nManaging Consultant\n\n\n7\nPrincipal Consultant\n\n\n8\nPartner\n\n\n\n\n\n\n\nLevel\nGender\n\n\n\n\n1\nFemale\n\n\n2\nMale\n\n\n\n\n\n\n\nData preparation\n\nChange variables of interest as categorical\nIn the original data set, all variables are numeric. However, our variables of interest are not numeric; they are categorical. As a result, for the analysis, I will treat these variables as categorical. So, first, I will change the variables to categorical.\n\n\nCode\n# create new variables \"gender\" and \"jobgrade\"\ndiversity1 &lt;- diversity1 |&gt;\n  mutate(gender= factor(Gender,\n                        levels= c(1:2),\n                        labels= c(\"Female\", \"Male\")),\n         jobgrade= factor(JobGrade,\n                          levels= c(1:8),\n                          labels= c(\"Clerical/Officer\", \"Administrator/Assistant\", \"Graduate/Trainee Consultant\", \"Consultant\", \"Senior Consultant\", \"Managing Consultant\", \"Principal Consultant\", \"Partner\")))\n\n\n\n\n\nCreate Cross-Table with the data for the two variables\n\n\nCode\ndiversity1 |&gt;\n  filter(gender != \"NA\") |&gt;\n  tabyl(jobgrade, gender) |&gt;\n  gt()|&gt;\n  cols_label(jobgrade = \"Job Grade\") |&gt;\n  tab_header(title = \"Cross-table of gender and job grade \",\n             subtitle = \"Count\")\n\n\n\n\n\n\n\n\nCross-table of gender and job grade\n\n\nCount\n\n\nJob Grade\nFemale\nMale\n\n\n\n\nClerical/Officer\n31\n8\n\n\nAdministrator/Assistant\n227\n116\n\n\nGraduate/Trainee Consultant\n160\n103\n\n\nConsultant\n139\n104\n\n\nSenior Consultant\n98\n152\n\n\nManaging Consultant\n68\n171\n\n\nPrincipal Consultant\n19\n62\n\n\nPartner\n4\n29\n\n\n\n\n\n\n\nWe can see a pattern more clearly by expressing the data as percentages. I will convert the values to a percentage of the total numbers of each job grade.\n\n\nCode\ndiversity1 |&gt;\n  filter(gender != \"NA\") |&gt;\n  tabyl(jobgrade, gender) |&gt;\n  adorn_percentages() |&gt;\n  mutate(across(where(is.numeric), ~ round(.x, 2)*100)) |&gt;\n  gt()|&gt;\n  cols_label(jobgrade = \"Job Grade\") |&gt;\n  tab_header(title = \"Cross-table of gender and job grade \",\n             subtitle = \"Percent %\")\n\n\n\n\n\n\n\n\nCross-table of gender and job grade\n\n\nPercent %\n\n\nJob Grade\nFemale\nMale\n\n\n\n\nClerical/Officer\n79\n21\n\n\nAdministrator/Assistant\n66\n34\n\n\nGraduate/Trainee Consultant\n61\n39\n\n\nConsultant\n57\n43\n\n\nSenior Consultant\n39\n61\n\n\nManaging Consultant\n28\n72\n\n\nPrincipal Consultant\n23\n77\n\n\nPartner\n12\n88"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#are-women-underrepresented-in-senior-leadership-roles-within-the-organization",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#are-women-underrepresented-in-senior-leadership-roles-within-the-organization",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Are women underrepresented in senior leadership roles within the organization?",
    "text": "Are women underrepresented in senior leadership roles within the organization?\nUp to this point, the data reveal a clear pattern: males are more common in senior roles, while females tend to occupy junior positions.\n\n\nCode\n# Custom label function\n\npercent_label &lt;- function(x) {\n  paste0(100*x, \"%\")\n}\n\ndiversity1 |&gt;\nfilter(gender != \"NA\") |&gt;\nggplot(aes(x=jobgrade, fill= gender))+\n  geom_bar(position = \"fill\", width = 0.6)+\n  labs(title = \"Gender by Job Grade\",\n      x = \"Job Grade\",\n      y = \"Proportions\",\n      fill= \"Gender\")+\n  theme_minimal(base_size = 14)+\n  theme(plot.background = element_blank(),\n        panel.grid = element_blank())+\n  scale_fill_manual(values = c(\"Female\" = \"#414040\", \"Male\"= \"#BFBEBE\"))+\n  scale_y_continuous(labels = percent_label, breaks = seq(0, 1, 0.25))+\n  coord_flip()"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#does-this-organization-have-a-gender-diversity-issue",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#does-this-organization-have-a-gender-diversity-issue",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Does this organization have a gender diversity issue?",
    "text": "Does this organization have a gender diversity issue?\n\nThe data indicate a pattern where women are more commonly in junior roles and men in senior roles.\nHowever, it’s unclear from the data whether this pattern is by chance or statistically significant.\nTo assess this, we can employ a chi-squared test to determine the statistical significance of the observed pattern."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#the-hypotheses",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#the-hypotheses",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "The hypotheses",
    "text": "The hypotheses\nH0: There is no association between gender and job grade within the organization.\n\nthe observed distribution of females and males across job grades is due to random chance.\n\nH1: There is a significant association between gender and job grade within the organization.\n\nthe observed distribution of females and males across job grades is not a result of random chance; it reflects a significant pattern of male predominance in senior roles and a greater representation of females in entry-level positions."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#chi-squared-test-in-r",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#chi-squared-test-in-r",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Chi squared test in R",
    "text": "Chi squared test in R\n\ncross_tab &lt;- table(diversity1$jobgrade, diversity1$gender)\nchisq.test(cross_tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  cross_tab\nX-squared = 164.7, df = 7, p-value &lt; 2.2e-16\n\n\n\nThe p-value is extremely small, less than 2.2e-16, which is very close to zero.\nSince the p-value is less than the significance level of 0.05, we can confidently reject the null hypothesis, concluding that the two variables are dependent.\nThis result indicates a statistically significant association between gender and job grade.\nIt suggests that certain factors are influencing the observed distribution of genders within job grades."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analyzing-gender-distribution-across-job-grades",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analyzing-gender-distribution-across-job-grades",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Analyzing gender distribution across job grades",
    "text": "Analyzing gender distribution across job grades\n\nCross-tables and graphical visualization offer a concise summary of gender distribution across job grades, revealing a clear pattern: men are more common in senior roles, while women predominantly hold junior positions.\nThe results of the chi-squared test, with a p-value close to zero, confirm a very strong association between gender and job grade."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#recommendation",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#recommendation",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Recommendation",
    "text": "Recommendation\n\nWhile this statistical evidence does not directly imply a gender diversity issue within the organization, it signals that factors beyond chance influence the gender distribution across job grades.\nTo address potential gender bias or discrimination and foster diversity and inclusion within the organization, further analysis and actions are necessary."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Cozmina Secula",
    "section": "",
    "text": "Translate Widget"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cozmina Secula",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n  \n    \n       \n  \n    \n     Email\n  \n  \n    \n     Linkedin\n  \n  \n    \n     Github\n  \n\n      \n\n    \n    \n  \n\n\nI am passionate about making sense of data for better decisions and actions. This is the space where I store and share some of my work in practicing data analysis and visualization.\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing the Digital Skills Indicator in the Context of the EU Digital Decade\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe components of EU’s Digital Intensity Index (DII) in 2023\n\n\n\n\n\n\n\n\n\n\n\nEU’s Digital Intensity Index (DII) in 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Driver Analysis to understand customer loyalty in a financial organization (case study)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a Dashboard with Quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployees’ perception of well-being at work: A qualitative study\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#case-study",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#case-study",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Case study",
    "text": "Case study\n\nFocused on diversity and inclusion (D&I)\nSourced from the book Predictive HR Analytics : Mastering the HR Metric\nWith data available here"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#problem-statement",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#problem-statement",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Problem Statement",
    "text": "Problem Statement\nA hypothetical company aims to employ data analytics to tackle a significant people problem: employee diversity. It recognizes that:\n\nCommercial Perspective : a more diverse workforce can provide a competitive advantage by enhancing the organization’s understanding of its customers, consequently improving overall performance.\nPeople Perspective : the organization gains access to a broader candidate pool, increases employee engagement, and elevates retention rates."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analysis-question",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analysis-question",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Analysis question",
    "text": "Analysis question\nHow does the distribution of Black, Asian, or Minority Ethnic (BAME) employees vary across different professions?"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#load-packages",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#load-packages",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Load packages",
    "text": "Load packages\n\n library(tidyverse)\n library(car)\n library(paletteer)\n library(kableExtra)"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-set",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-set",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Data set",
    "text": "Data set\nFor this case study I used a data set available here.\n\nDescriptionData summary\n\n\n\nThe company, a hypothetical organization, comprises 29,976 employees in two functional areas across the UK, and these employees are organized into 928 teams.\nThe data set contains 30 variables.\nData type (in the data set): numeric for all variables.\n\n\n\n\ndiversity &lt;- read_csv(\"diversity2.csv\")\n\nskimr::skim(diversity)\n\n\n\nData summary\n\n\n\n\nName\n\n\ndiversity\n\n\n\n\nNumber of rows\n\n\n928\n\n\n\n\nNumber of columns\n\n\n30\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nnumeric\n\n\n30\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\nVariable type: numeric\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\n\nDepartmentGroupNumber\n\n\n0\n\n\n1.00\n\n\n470.62\n\n\n270.05\n\n\n1.00\n\n\n237.75\n\n\n470.50\n\n\n704.25\n\n\n937.00\n\n\n▇▇▇▇▇\n\n\n\n\nGroupSize\n\n\n1\n\n\n1.00\n\n\n32.30\n\n\n16.24\n\n\n10.00\n\n\n18.00\n\n\n28.00\n\n\n45.00\n\n\n71.00\n\n\n▇▆▃▃▂\n\n\n\n\nPercentMale\n\n\n1\n\n\n1.00\n\n\n58.95\n\n\n22.27\n\n\n1.00\n\n\n45.00\n\n\n65.00\n\n\n67.00\n\n\n100.00\n\n\n▁▃▅▇▃\n\n\n\n\nBAME\n\n\n182\n\n\n0.80\n\n\n0.12\n\n\n0.11\n\n\n0.00\n\n\n0.03\n\n\n0.09\n\n\n0.20\n\n\n0.45\n\n\n▇▃▂▂▁\n\n\n\n\nNumberTeamLeads\n\n\n1\n\n\n1.00\n\n\n4.61\n\n\n2.33\n\n\n1.00\n\n\n3.00\n\n\n4.00\n\n\n6.00\n\n\n10.00\n\n\n▅▇▅▃▂\n\n\n\n\nNumberFeMaleTeamLeads\n\n\n20\n\n\n0.98\n\n\n0.68\n\n\n1.06\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n1.00\n\n\n8.00\n\n\n▇▂▁▁▁\n\n\n\n\nLocation\n\n\n0\n\n\n1.00\n\n\n2.12\n\n\n0.85\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n3.00\n\n\n3.00\n\n\n▆▁▅▁▇\n\n\n\n\nLondonorNot\n\n\n0\n\n\n1.00\n\n\n1.43\n\n\n0.49\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n▇▁▁▁▆\n\n\n\n\nFunction\n\n\n1\n\n\n1.00\n\n\n1.46\n\n\n0.50\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n▇▁▁▁▇\n\n\n\n\nEMPsurvEngage_1\n\n\n1\n\n\n1.00\n\n\n88.14\n\n\n11.24\n\n\n22.00\n\n\n83.00\n\n\n91.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_2\n\n\n1\n\n\n1.00\n\n\n87.50\n\n\n10.88\n\n\n45.00\n\n\n82.00\n\n\n90.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▂▅▇\n\n\n\n\nEMPsurvEngage_3\n\n\n1\n\n\n1.00\n\n\n85.63\n\n\n13.43\n\n\n33.00\n\n\n80.00\n\n\n89.00\n\n\n95.00\n\n\n100.00\n\n\n▁▁▁▃▇\n\n\n\n\nEMPsurvEngage_4\n\n\n1\n\n\n1.00\n\n\n75.98\n\n\n13.77\n\n\n29.00\n\n\n68.00\n\n\n78.00\n\n\n86.00\n\n\n100.00\n\n\n▁▂▅▇▅\n\n\n\n\nEMPsurvEngage_5\n\n\n1\n\n\n1.00\n\n\n91.49\n\n\n8.80\n\n\n44.00\n\n\n88.00\n\n\n93.00\n\n\n98.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_6\n\n\n1\n\n\n1.00\n\n\n68.60\n\n\n15.96\n\n\n11.00\n\n\n58.00\n\n\n69.00\n\n\n80.00\n\n\n100.00\n\n\n▁▂▆▇▃\n\n\n\n\nEMPsurvEngage_7\n\n\n1\n\n\n1.00\n\n\n89.98\n\n\n9.82\n\n\n25.00\n\n\n86.00\n\n\n92.00\n\n\n97.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_8\n\n\n1\n\n\n1.00\n\n\n66.75\n\n\n15.31\n\n\n0.00\n\n\n57.00\n\n\n68.00\n\n\n78.00\n\n\n100.00\n\n\n▁▁▅▇▃\n\n\n\n\nEMPsurvEngage_9\n\n\n1\n\n\n1.00\n\n\n76.64\n\n\n15.54\n\n\n10.00\n\n\n68.00\n\n\n79.00\n\n\n88.00\n\n\n100.00\n\n\n▁▁▃▇▇\n\n\n\n\nEMPsurvEngagement\n\n\n1\n\n\n1.00\n\n\n81.18\n\n\n10.02\n\n\n39.00\n\n\n75.00\n\n\n83.00\n\n\n89.00\n\n\n99.00\n\n\n▁▁▃▇▆\n\n\n\n\nEMPorgIntegrity1\n\n\n1\n\n\n1.00\n\n\n69.99\n\n\n14.33\n\n\n18.00\n\n\n61.00\n\n\n71.00\n\n\n80.00\n\n\n100.00\n\n\n▁▂▅▇▃\n\n\n\n\nEMPorgIntegrity2\n\n\n1\n\n\n1.00\n\n\n85.74\n\n\n10.94\n\n\n35.00\n\n\n80.00\n\n\n88.00\n\n\n94.00\n\n\n100.00\n\n\n▁▁▂▆▇\n\n\n\n\nEMPorgIntegrity3\n\n\n1\n\n\n1.00\n\n\n88.73\n\n\n10.31\n\n\n35.00\n\n\n83.00\n\n\n91.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▁▃▇\n\n\n\n\nEMPorgIntegrity4\n\n\n1\n\n\n1.00\n\n\n84.91\n\n\n10.88\n\n\n27.00\n\n\n80.00\n\n\n86.00\n\n\n92.00\n\n\n100.00\n\n\n▁▁▁▆▇\n\n\n\n\nEMPorgIntegrity5\n\n\n1\n\n\n1.00\n\n\n470.11\n\n\n269.76\n\n\n1.00\n\n\n237.50\n\n\n470.00\n\n\n703.50\n\n\n936.00\n\n\n▇▇▇▇▇\n\n\n\n\nEmpSurvOrgIntegrity\n\n\n1\n\n\n1.00\n\n\n159.89\n\n\n54.53\n\n\n54.00\n\n\n113.10\n\n\n164.60\n\n\n207.60\n\n\n258.20\n\n\n▅▇▇▇▇\n\n\n\n\nEMPsurvSUP1\n\n\n1\n\n\n1.00\n\n\n82.96\n\n\n10.65\n\n\n33.00\n\n\n77.00\n\n\n84.00\n\n\n91.00\n\n\n100.00\n\n\n▁▁▂▇▇\n\n\n\n\nEMPsurvSUP2\n\n\n1\n\n\n1.00\n\n\n85.24\n\n\n10.99\n\n\n30.00\n\n\n79.00\n\n\n87.00\n\n\n93.00\n\n\n100.00\n\n\n▁▁▂▆▇\n\n\n\n\nEMPsurvSUP3\n\n\n1\n\n\n1.00\n\n\n79.89\n\n\n12.72\n\n\n34.00\n\n\n73.00\n\n\n81.00\n\n\n89.00\n\n\n100.00\n\n\n▁▂▃▇▆\n\n\n\n\nEMPsurvSUP4\n\n\n1\n\n\n1.00\n\n\n81.35\n\n\n12.13\n\n\n27.00\n\n\n73.00\n\n\n82.00\n\n\n91.00\n\n\n100.00\n\n\n▁▁▃▇▇\n\n\n\n\nEmpSurvSupervisor\n\n\n1\n\n\n1.00\n\n\n82.36\n\n\n10.07\n\n\n35.75\n\n\n76.50\n\n\n83.50\n\n\n89.75\n\n\n100.00\n\n\n▁▁▂▇▆"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#variables-of-interest",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#variables-of-interest",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Variables of interest",
    "text": "Variables of interest\n\nBAME: Percentage of the team comprised of Black, Asian, or Minority Ethnic employees.\nFunction: Function 1 = Sales staff (customer-facing roles) or 2 = Professional Service (non-customer-facing roles).\nThe data set contains both variables of interest as numbers.\nThe “BAME” variable is numeric, while the “Function” variable is categorical and needs to be transformed into a factor for analysis in R."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-preparation",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-preparation",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Data preparation",
    "text": "Data preparation\n\nChange the variable “Function” to categorical by creating a new variable named “profession” with two levels “Sales Staff” and “Professional Service”.\n\n\n\nCode\n# Create a new variable named \"profession\" with two levels \"Sales Staff\" and \"Professional Service\"\n# Drop \"NA\" levels as they are not meaningful for the analysis\n\ndiversity &lt;- diversity|&gt;\n  mutate(profession = factor(Function,\n                           levels = c(1:2),\n                           labels = c(\"Sales Staff\", \"Professional Service\")))|&gt;\n  filter(profession != \"NA\")|&gt;\n  droplevels()"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-i",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-i",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "How does the distribution of BAME employees vary across different professions? (I)",
    "text": "How does the distribution of BAME employees vary across different professions? (I)\n\nBAME employees are distributed differently across the two professions. There are more “Sales Staff” teams with a lower percentage of BAME employees, while “Professional Service” teams have a more even distribution.\nIt’s essential to note that these findings are based on summary statistics and visual examinations, which may not be highly precise.\nTo gain more confidence in comparing BAME representation between the two professions and to deepen our understanding of the organization’s ethnicity dynamics, we will conduct an Independent Samples t-Test."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#levenes-test-for-equality-of-variances",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#levenes-test-for-equality-of-variances",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Levene’s Test for Equality of Variances",
    "text": "Levene’s Test for Equality of Variances\nOne of the requirements for the independent Samples t-test is the homogeneity of variances (i.e., variances approximately equal across groups).\nHowever, if this requirement is violated and the sample sizes for each group differ, we can calculate t-test statistics. The independent samples t-test output also includes an approximate t-statistic, which doesn’t assume equal variances across populations. The Welch t-test statistic can be employed when equal variances between populations cannot be assumed.\nThe hypotheses\n\nH0: The population variances of “Sales Staff” and “Professional Service” are equal.\nH1: The population variances of “Sales Staff” and “Professional Service” are not equal.\n\n\nleveneTest(diversity$BAME, group = diversity$profession, center=mean)\n\nLevene's Test for Homogeneity of Variance (center = mean)\n       Df F value    Pr(&gt;F)    \ngroup   1  35.396 4.141e-09 ***\n      744                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value is 4.141e-09, which is less than 0.05. This indicates very strong evidence against the null hypothesis, leading us to reject the null hypothesis of Levene’s Test.\nThis suggests that the variances of the two groups are not equal, meaning the assumption of homogeneity of variances is violated."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#independent-samples-t-test-1",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#independent-samples-t-test-1",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Independent Samples t-Test",
    "text": "Independent Samples t-Test\n\nWe want to determine if there is a statistically significant difference between the mean percentages of BAME employees in the “Sales Staff” and “Professional Service” professions within this organization.\nTo achieve this, we can employ an Independent Samples t-Test to compare the means of BAME percentages for “Sales Staff” and “Professional Service.”\n\nThe hypotheses\n\nH0: The difference of the means is equal to 0\nH1: The difference of the means is not equal to 0.\n\n\nt.test(diversity$BAME ~ diversity$profession, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  diversity$BAME by diversity$profession\nt = -5.7695, df = 744, p-value = 1.166e-08\nalternative hypothesis: true difference in means between group Sales Staff and group Professional Service is not equal to 0\n95 percent confidence interval:\n -0.06302979 -0.03102614\nsample estimates:\n         mean in group Sales Staff mean in group Professional Service \n                        0.09683168                         0.14385965 \n\nt.test(diversity$BAME ~ diversity$profession, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  diversity$BAME by diversity$profession\nt = -5.6553, df = 640.61, p-value = 2.345e-08\nalternative hypothesis: true difference in means between group Sales Staff and group Professional Service is not equal to 0\n95 percent confidence interval:\n -0.06335727 -0.03069866\nsample estimates:\n         mean in group Sales Staff mean in group Professional Service \n                        0.09683168                         0.14385965 \n\n\n\nThe result of Levene’s Test suggests that we should consider using the Welch Two Sample t-test because the variances of the two groups are not equal.\nThe p-value is 2.345e-08 for the t-test for unequal variances, which is less than 0.001. Therefore, we can conclude that there is a significant difference in the mean percentage of BAME employees between the two functions."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-ii",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-ii",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "How does the distribution of BAME employees vary across different professions? (II)",
    "text": "How does the distribution of BAME employees vary across different professions? (II)\n\nWhen comparing the “Sales Staff” and “Professional Service” functions, it becomes evident that the mean proportion of BAME staff is significantly lower in “Sales Staff” than in “Professional Service.”\nSpecifically, the average proportion of BAME staff in teams within the “Sales Staff” function is 9.7%, while in “Professional Service” teams, it stands at 14.39%.\nA more in-depth analysis reveals that the likelihood of this difference occurring by chance alone is less than 1 in 1,000, suggesting that there is a significant issue within the “Sales Staff” function that requires attention in the organization."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analyzing-bame-distribution-across-professional-functions",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analyzing-bame-distribution-across-professional-functions",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Analyzing BAME distribution across professional functions",
    "text": "Analyzing BAME distribution across professional functions\n\nSummary statistics and graphical visualization offer a concise overview of the distribution of BAME employees in the two professions. It’s evident that more “Sales Staff” teams have a lower percentage of BAME employees, while “Professional Service” teams exhibit a more even distribution.\nThe results of the independent samples t-test, with a p-value close to 0, confirm a significant difference in the mean percentage of BAME employees between the two functions. This implies that there is an issue that needs attention within the “Sales Staff” function in the organization."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#recommendation",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#recommendation",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Recommendation",
    "text": "Recommendation\n\nAccording to our analysis, the organization faces challenges in BAME representation across professions, particularly in the “Sales Staff”.\nFurther research should be conducted to identify the factors influencing or associated with the diversity disparities between these two teams."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#footnotes",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#footnotes",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\n\n\nA typical boxplot. The ends of the box mark the quartiles, and the vertical line through the box is located at the median. The whiskers of a boxplot extend to values known as adjacent values. These are the values in the data that are furthest away from the median on either side of the box, but are still within a distance of 1.5 times the interquartile range from the nearest end of the box (that is, the nearer quartile). In many cases the whiskers actually extend right out to the most extreme values in the data set. However, in other cases they do not. Any values in the data set that are more extreme than the adjacent values are plotted as separate points on the boxplot. This identifies them as potential outliers that may need further investigation.\n\n\n↩︎"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html",
    "href": "posts/2024-01-15-key-driver-analysis/index.html",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "",
    "text": "In the competitive business landscape, every organization strives to cultivate a loyal customer base. This loyalty, often a result of trust and satisfaction with a company’s products and services, is a key driver of repeat business. Consequently, companies are increasingly focusing on identifying and enhancing the critical factors influencing customer loyalty and encouraging repeat investments.\nThis post will guide you on how to use key driver analysis to identify the essential factors that impact customer satisfaction and, consequently, customer loyalty."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#load-packages",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#load-packages",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Load packages",
    "text": "Load packages\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggtext)\nsource(\"helper_functions.R\")\nsource(\"theme_msd.R\")\nlibrary(janitor)"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#data-set2",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#data-set2",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Data Set2",
    "text": "Data Set2\n\nRead dataScan data\n\n\nThe data set includes responses from 2,507 customers and 8 variables.\n\n\nRows: 2,507\nColumns: 8\n$ Sat1             &lt;dbl&gt; 1, 2, 3, 3, NA, 3, 4, 1, 4, 3, 4, 3, 4, 5, 3, 3, 4, 4…\n$ Sat2             &lt;dbl&gt; 1, 3, 5, 4, NA, 3, 4, 2, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4…\n$ Sat3             &lt;dbl&gt; 1, 3, 4, 4, NA, 3, 4, 1, NA, 3, 4, 3, 3, 4, 5, 3, 4, …\n$ Sat4             &lt;dbl&gt; 3, 3, 5, 3, NA, 3, 5, 1, 5, 3, 4, 3, 4, 5, 4, 4, 4, 4…\n$ CustSatMean      &lt;dbl&gt; 1.50, 2.75, 4.25, 3.50, NA, 3.00, 4.25, 1.25, 4.67, 3…\n$ Custloyalty      &lt;dbl&gt; 4, 2, 2, 3, 5, 3, 4, 1, 3, 3, 4, 4, 4, 4, 1, 4, 4, 4,…\n$ INvestMore       &lt;dbl&gt; 3, 1, 3, 3, 3, 3, 2, 1, 3, NA, 2, 3, 3, 3, 3, 2, NA, …\n$ SexOfSalesperson &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n\n\n\n\nAll variables in the data set are numeric.\nFor each variable, there are missing values (NAs).\n\n\nCode\nskimr::skim(cssurvey_raw)\n\n\n\nData summary\n\n\nName\ncssurvey_raw\n\n\nNumber of rows\n2507\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSat1\n128\n0.95\n3.47\n1.04\n1\n3\n4.00\n4\n5\n▁▃▇▇▃\n\n\nSat2\n124\n0.95\n3.79\n0.95\n1\n3\n4.00\n4\n5\n▁▁▅▇▅\n\n\nSat3\n142\n0.94\n3.43\n1.10\n1\n3\n4.00\n4\n5\n▂▃▇▇▅\n\n\nSat4\n450\n0.82\n3.59\n0.98\n1\n3\n4.00\n4\n5\n▁▂▆▇▃\n\n\nCustSatMean\n66\n0.97\n3.56\n0.91\n1\n3\n3.67\n4\n5\n▁▂▆▇▆\n\n\nCustloyalty\n338\n0.87\n3.80\n1.10\n1\n3\n4.00\n5\n5\n▁▂▃▇▇\n\n\nINvestMore\n476\n0.81\n2.93\n0.82\n1\n3\n3.00\n3\n5\n▁▁▇▂▁\n\n\nSexOfSalesperson\n121\n0.95\n1.79\n0.41\n1\n2\n2.00\n2\n2\n▂▁▁▁▇"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#understanding-data-structure",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#understanding-data-structure",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Understanding data structure",
    "text": "Understanding data structure\n\nData structure:\n\nThe dataset consists of 2.507 rows, as per the description provided by the data source.\nIt contains 8 variables. Seven of them represent the questions from the survey, and an additional variable calculates the mean value of the customer satisfaction survey responses."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#understanding-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#understanding-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Understanding variables",
    "text": "Understanding variables\n\nData DictionaryProblems and Solutions\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDetail\nUnit\nRange\n\n\n\n\nSat1\nThe salesperson understanding your needs\nnumeric\n1-5\n\n\nSat2\nThe salesperson seems confident\nnumeric\n1-5\n\n\nSat3\nThe salesperson has a recommendation\nnumeric\n1-5\n\n\nSat4\nThe salesperson is knowledgeable\nnumeric\n1-5\n\n\nCustSatMean\nValue derived from mathematical operation (mean)  of customer responses\nnumeric\n1-5\n\n\nCustloyalty\nLikelihood of reinvesting\nnumeric\n1-5\n\n\nINvestMore\nHow much they may or may not reinvest\nnumeric\n1-5\n\n\nSexOfSalesperson\nGender\nnumeric\n1-2\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nProblem\nSolution\n\n\n\n\nSat1, Sat2, Sat3, Sat4\nvariables’names are not meaningful\nrename variables\n\n\nCustSatMean, Custloyalty, INvestMore\ninconsistent entries\nrename variables\n\n\nAll except CustSatMean\nvariable type is not numeric; they are ordinal and binary\nchange variable type\n\n\nAll except CustSatMean\nvariable labels\nassign labels"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#clean-name-and-rename-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#clean-name-and-rename-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Clean name and rename variables",
    "text": "Clean name and rename variables\n\nProblemSolution\n\n\nCustSatMean, Custloyalty, INvestMore have inconsistent entries (e.g. IN..More).\n\n\n\nClean names and rename these variables\n\n\n\nCode\n# use janitor::clean_name()\n\n(cssurvey_clean &lt;- cssurvey_raw|&gt;\n   rename(invest_more = INvestMore,\n          cust_loyalty = Custloyalty)|&gt;\n    clean_names())\n\n\n# A tibble: 2,507 × 8\n    sat1  sat2  sat3  sat4 cust_sat_mean cust_loyalty invest_more\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1     1     1     1     3          1.5             4           3\n 2     2     3     3     3          2.75            2           1\n 3     3     5     4     5          4.25            2           3\n 4     3     4     4     3          3.5             3           3\n 5    NA    NA    NA    NA         NA               5           3\n 6     3     3     3     3          3               3           3\n 7     4     4     4     5          4.25            4           2\n 8     1     2     1     1          1.25            1           1\n 9     4     5    NA     5          4.67            3           3\n10     3     4     3     3          3.25            3          NA\n# ℹ 2,497 more rows\n# ℹ 1 more variable: sex_of_salesperson &lt;dbl&gt;"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#assign-labels-and-rename-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#assign-labels-and-rename-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Assign labels and rename variables",
    "text": "Assign labels and rename variables\n\nProblemSolutionConfirm\n\n\n\nThe variable names ‘Sat1’, ‘Sat2’, ‘Sat3’, and ‘Sat4’ lack clarity. Although they are numeric in the data set, the data source classifies them as ordinal variables.\nThe variable ‘sex_of_salesperson’ could be more appropriately named as ‘gender’.\n\n\n\n\nCreate new variables based on the existing variables, rename variables, assign labels, and change variable type in factor.\n\n\n\nCode\n# Create new variables, assign labels, change variable type in factor\n\n(cssurvey_clean &lt;- cssurvey_clean |&gt;\n  mutate(undst_cust_need = factor(sat1,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         sales_confidence = factor(sat2,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         give_recomm = factor(sat3,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         product_know = factor(sat4,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         gender = factor(sex_of_salesperson,\n                           levels = c(1:2),\n                           labels = c(\"female\", \"male\"))))\n\n\n# A tibble: 2,507 × 13\n    sat1  sat2  sat3  sat4 cust_sat_mean cust_loyalty invest_more\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1     1     1     1     3          1.5             4           3\n 2     2     3     3     3          2.75            2           1\n 3     3     5     4     5          4.25            2           3\n 4     3     4     4     3          3.5             3           3\n 5    NA    NA    NA    NA         NA               5           3\n 6     3     3     3     3          3               3           3\n 7     4     4     4     5          4.25            4           2\n 8     1     2     1     1          1.25            1           1\n 9     4     5    NA     5          4.67            3           3\n10     3     4     3     3          3.25            3          NA\n# ℹ 2,497 more rows\n# ℹ 6 more variables: sex_of_salesperson &lt;dbl&gt;, undst_cust_need &lt;fct&gt;,\n#   sales_confidence &lt;fct&gt;, give_recomm &lt;fct&gt;, product_know &lt;fct&gt;, gender &lt;fct&gt;\n\n\n\n\n\n\nCode\ncssurvey_clean|&gt;\n  skimr::skim()\n\n\n\nData summary\n\n\nName\ncssurvey_clean\n\n\nNumber of rows\n2507\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n5\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nundst_cust_need\n128\n0.95\nFALSE\n5\nSat: 828, Neu: 747, Ver: 393, Dis: 315\n\n\nsales_confidence\n124\n0.95\nFALSE\n5\nSat: 1014, Neu: 620, Ver: 562, Dis: 125\n\n\ngive_recomm\n142\n0.94\nFALSE\n5\nSat: 780, Neu: 717, Ver: 417, Dis: 313\n\n\nproduct_know\n450\n0.82\nFALSE\n5\nSat: 803, Neu: 648, Ver: 360, Dis: 183\n\n\ngender\n121\n0.95\nFALSE\n2\nmal: 1884, fem: 502\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nsat1\n128\n0.95\n3.47\n1.04\n1\n3\n4.00\n4\n5\n▁▃▇▇▃\n\n\nsat2\n124\n0.95\n3.79\n0.95\n1\n3\n4.00\n4\n5\n▁▁▅▇▅\n\n\nsat3\n142\n0.94\n3.43\n1.10\n1\n3\n4.00\n4\n5\n▂▃▇▇▅\n\n\nsat4\n450\n0.82\n3.59\n0.98\n1\n3\n4.00\n4\n5\n▁▂▆▇▃\n\n\ncust_sat_mean\n66\n0.97\n3.56\n0.91\n1\n3\n3.67\n4\n5\n▁▂▆▇▆\n\n\ncust_loyalty\n338\n0.87\n3.80\n1.10\n1\n3\n4.00\n5\n5\n▁▂▃▇▇\n\n\ninvest_more\n476\n0.81\n2.93\n0.82\n1\n3\n3.00\n3\n5\n▁▁▇▂▁\n\n\nsex_of_salesperson\n121\n0.95\n1.79\n0.41\n1\n2\n2.00\n2\n2\n▂▁▁▁▇"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#percentage-of-responses-in-the-customer-survey-data",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#percentage-of-responses-in-the-customer-survey-data",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Percentage of Responses in the Customer Survey Data",
    "text": "Percentage of Responses in the Customer Survey Data\nSurveyed customers expressed satisfaction and high satisfaction with the ‘The salesperson seems confident’. However, they were less satisfied with ‘The salesperson understanding your needs’ and ‘The salesperson has a recommendation’.\n\n\nCode\n# Get the column names of the initial dataset\ninitial_order &lt;- colnames(cssurvey_clean)[9:12]\n\n\n# Calculate percentages for each category for each survey question\n\nkda &lt;- cssurvey_clean |&gt;\n  drop_na()|&gt;\n  pivot_longer(cols = 9:12, names_to = \"question\", values_to = \"value\" )|&gt;\n  mutate(question= factor(question,\n                          levels= initial_order))|&gt;\n  count(question, value) |&gt;\n  group_by(question)|&gt;\n  mutate(prtc = round(n/sum(n) * 100),\n         prtc = ifelse(row_number() == n(), 100 - sum(prtc[-n()]), prtc)) |&gt;\n  pivot_wider(id_cols = question, names_from = value, values_from = prtc)\n\nkda$question &lt;- c(\"The salesperson \\nunderstanding your needs\",\n                 \"The salesperson \\nseems confident\",\n                 \"The salesperson \\nhas a recommendation\",\n                 \"The salesperson \\nis knowledgeable\")\n\nkda|&gt;\n  kableExtra::kable(col.names = c(\"Question\", \"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\"),\n                    align = \"lccccc\",\n                    caption = \"Customer Satisfaction with Salesperson Competencies (%)\")\n\n\n\nCustomer Satisfaction with Salesperson Competencies (%)\n\n\nQuestion\nVery Dissatisfied\nDissatisfied\nNeutral\nSatisfied\nVery Satisfied\n\n\n\n\nThe salesperson understanding your needs\n4\n14\n33\n35\n14\n\n\nThe salesperson seems confident\n2\n6\n27\n43\n22\n\n\nThe salesperson has a recommendation\n5\n14\n31\n33\n17\n\n\nThe salesperson is knowledgeable\n3\n9\n33\n39\n16\n\n\n\n\n\n\n\n\n\nCode\ntheme_set(theme_msd() + theme(\n  axis.title.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.text.y = element_text(color = GRAY3, size = 10),\n  panel.border = element_blank(),\n  axis.line = element_line(),\n  axis.title.x = element_text(hjust = 0.03, color = GRAY6, size = 10),\n  axis.text.x = element_text(size = 8),\n  plot.subtitle = element_markdown(hjust = 0.65),\n  axis.line.y = element_blank()\n))\n\n\ndf &lt;- kda |&gt;\n  rename(Item = \"question\") |&gt;\n  pivot_longer(cols = -Item, names_to = \"Answer\", values_to = \"Value\") |&gt;\n  mutate(\n    Answer = factor(Answer, levels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n    Value = as.numeric(Value) /100\n  )\n\ndf$Answer &lt;- fct_rev(df$Answer)\n\n\n\ncolor_scale &lt;- c(\n  \"Very Dissatisfied\" = GRAY2,\n  \"Dissatisfied\" = GRAY2,\n  \"Neutral\" = GRAY9,\n  \"Satisfied\" = GRAY5,\n  \"Very Satisfied\" = GRAY5)\n\n\nformatted_subtitle &lt;- paste0(\n  \"&lt;span style='color:\", color_scale[1], \"'&gt;**\", names(color_scale)[1], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[2], \"'&gt;**\", names(color_scale)[2], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[3], \"'&gt;**\", names(color_scale)[3], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[4], \"'&gt;**\", names(color_scale)[4], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[5], \"'&gt;**\", names(color_scale)[5], \"**&lt;/span&gt;\"\n)\n\npt &lt;- df |&gt;\n  ggplot(aes(y = Item, x = Value, fill = Answer)) +\n  geom_bar(stat = \"Identity\", width = 0.65, color = \"white\") +\n  scale_fill_manual(values = color_scale, guide = \"none\") +\n  labs(\n    title = \"Customer Satisfaction with Salesperson Competencies \\n\",\n    subtitle = formatted_subtitle,\n    x = \"\\nPercent of total\"\n  ) +\n  scale_x_continuous(position = \"top\", \n                     breaks = seq(0,1,by = 0.2),\n                     labels = scales::percent_format(accuracy = 1)) +\n  lemon::coord_capped_cart(top = \"both\")\n\npt |&gt;\n  save_and_show_plot(width = 6, height = 4, \"FIG01.png\")"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#correlation",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#correlation",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Correlation",
    "text": "Correlation\nAnother approach to analyzing the customer survey data is through correlation. Correlation is a statistical measure of the relationship between two variables, how they are interconnected.\nAmong the four questions on the survey, at this stage, I aim to identify which ones have the strongest correlation with the question related to customer loyalty: the likelihood of reinvestment.\n\n\nCode\n# Correlation for several pairs of variables\n     \ncor_cust_loyalty &lt;- cssurvey_clean |&gt;\n  select(sat1, sat2, sat3, sat4, cust_loyalty)|&gt;\n  cor(method = \"spearman\",\n      use = \"pairwise.complete.obs\")|&gt;\n  round(digits = 2)\n\nsurvey_quest = c(\"The salesperson understanding your needs\",\n                 \"The salesperson seems confident\",\n                 \"The salesperson has a recommendation\",\n                 \"The salesperson is knowledgeable\")\n\n                        \ncor_to_cust_loyalty = c(0.49, 0.37, 0.49, 0.40)\n                            \n(cor_matrix &lt;- tibble(survey_quest, cor_to_cust_loyalty)|&gt;\n    arrange(desc(cor_to_cust_loyalty))|&gt;\n  kableExtra::kable(col.names = c(\"Survey Question\", \"Correlation to \\nCustomer Loyalty\"),\n                    align = \"lr\",\n                    caption = \"Correlation of survey questions to customer loyalty\"))\n\n\n\nCorrelation of survey questions to customer loyalty\n\n\nSurvey Question\nCorrelation to Customer Loyalty\n\n\n\n\nThe salesperson understanding your needs\n0.49\n\n\nThe salesperson has a recommendation\n0.49\n\n\nThe salesperson is knowledgeable\n0.40\n\n\nThe salesperson seems confident\n0.37\n\n\n\n\n\n\n\n‘The salesperson understanding your needs’ , ‘The salesperson has a recommendation’ , and ‘The salesperson is knowledgeable’ are the most highly correlated to the question related to loyalty (0.49, respectively 0.40). The company might see these areas to focus in its efforts to improve customer loyalty."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#consolidating-the-percentage-and-correlation",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#consolidating-the-percentage-and-correlation",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Consolidating the Percentage and Correlation",
    "text": "Consolidating the Percentage and Correlation\nIn this step, I will integrate the customer satisfaction questions and their correlation to customer loyalty into a unified view for enhanced insights. To calculate the customer’s importance of loyalty, I calculated the percentage of dissatisfied and very dissatisfied customers in a single metric, percent dissatisfaction. The ‘Customer Loyalty Importance’ is a calculated metric that combines percent dissatisfaction and the correlation to customer loyalty in one measure (see the table below). It allows us to rank survey questions by importance.\n\n\nCode\n# we need to consolidate data from \"kda\" data set and \"cor_matrix\" data set\n\n# define cor_matrix as data frame\n\ncor_matrix &lt;- as.data.frame(cor_matrix)\n\ncor_matrix &lt;- tibble(survey_quest, cor_to_cust_loyalty)\n\n\nkda_cor &lt;- bind_cols(kda, cor_matrix)\n  \n            \nkda_cor &lt;- kda_cor |&gt;\n  mutate(percent_dissatisfied = Dissatisfied + `Very Dissatisfied`,\n         percent_satisfied = Satisfied + `Very Satisfied`,\n         percent_neutral = Neutral) |&gt;\n  group_by(percent_dissatisfied, cor_to_cust_loyalty) |&gt;\n  mutate(cust_loyalty_importance = percent_dissatisfied*cor_to_cust_loyalty)|&gt;\n  ungroup()\n \n\nkda_consolidate &lt;- kda_cor |&gt;\n  select(question, percent_dissatisfied, cor_to_cust_loyalty, cust_loyalty_importance)|&gt;\n  arrange(desc(cust_loyalty_importance))|&gt;\n  kableExtra::kable(col.names = c(\"Survey Question\", \"Percent Dissatisfaction\", \"Correlation to \\nCustomer Loyalty\", \"Customer Loyalty \\nImportance\"),\n                    align = \"lrrr\",\n                    caption = \"Customer Satisfaction items ranked by importance\")\n  \nkda_consolidate\n\n\n\nCustomer Satisfaction items ranked by importance\n\n\nSurvey Question\nPercent Dissatisfaction\nCorrelation to Customer Loyalty\nCustomer Loyalty Importance\n\n\n\n\nThe salesperson has a recommendation\n19\n0.49\n9.31\n\n\nThe salesperson understanding your needs\n18\n0.49\n8.82\n\n\nThe salesperson is knowledgeable\n12\n0.40\n4.80\n\n\nThe salesperson seems confident\n8\n0.37\n2.96\n\n\n\n\n\n\n\nWhat is the data from the table telling us?\n\n\nCode\ntheme_set(theme_msd() + theme(\n  axis.title.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.text.y = element_text(color = GRAY3, size = 10),\n  panel.border = element_blank(),\n  axis.line = element_line(),\n  axis.title.x = element_text(hjust = 0.03, color = GRAY6, size = 9),\n  axis.text.x = element_text(color = GRAY3, size = 10),\n  plot.subtitle = element_markdown(hjust = 0),\n  axis.line.y = element_blank()\n))\n\n\nkda_consolidate_plot &lt;- kda_cor |&gt;\n  mutate(question = fct_reorder(question, cust_loyalty_importance))|&gt;\n  ggplot(aes(x = cust_loyalty_importance, y = question))+\n  geom_bar(stat = \"identity\", width = 0.6, color = GRAY2)+\n  geom_text(aes(label = cust_loyalty_importance), hjust = -0.15, size = 3.5)+\n  labs(\n    title = \"The sales person having a recommendation and understanding customers \\nneeds are the issues that require some improvments \\n\",\n    subtitle = \"\",\n    x = \"Customer Loyalty Importance\"\n  )\n  \n  \nkda_consolidate_plot |&gt;\n  save_and_show_plot(width = 6.5, height = 4, \"FIG02.png\")"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#key-driver-analysis-results",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#key-driver-analysis-results",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Key Driver Analysis Results",
    "text": "Key Driver Analysis Results\nThe findings of the key driver analysis are presented below in a key driver quadrant. It allows us to see the two intersecting information points: the correlation of the four survey questions to customer loyalty, our chosen indicator to understand (axis x), and the satisfaction of customers’ responses (axis y).\nKey drivers for customer loyalty\n\nImprove Weakness: The correlation to customer loyalty is 0.49, and customer satisfaction is low (dissatisfied and very dissatisfied). In the lower right quadrant of the key driver analysis chart, customer satisfaction with the salesperson competency “has a recommendation” is 19%, and with the salesperson competency “understanding your needs” is 18%. On the upper side of this quadrant, it is essential to note the significant percentage of neutral responses for these two questions.\nLeverage Great: The correlation to customer loyalty is 0.49, and customer satisfaction is high (satisfied and very satisfied). In the upper right quadrant, customer satisfaction with salesperson competency “has a recommendation” is 50%, and with salesperson competency “understanding your needs” is 49%.\nDisregard: The remaining survey questions have a mix of positive and negative customer responses. However, they are not as important for customer loyalty as the other two questions.\n\n\n\n\n\n\n\nKey driver analysis explores a wide range of measures to uncover what is most important in influencing the chosen objective. It helps you understand where to focus your energy and resources to obtain the results you are looking for.\n\n\n\n\n\nCode\nlibrary(glue)\nlibrary(grid)\n\n# Data ----\n# |- KDA Quadrant ----\n\n# First, I organize columns and rows in the data frame to make easier \n# to work with. I made a column \"sum_satisfaction\" with 3 categories where\n# I summed up the percentage of categories satisfied and very satisfied, dissatisfied and very dissatisfied and neutral to keep the plot simple to visualize\n\nkda_quadrant &lt;- kda_cor |&gt;\n    pivot_longer(cols = 2:6, names_to = \"satisfaction\", values_to = \"score\")\n\nkda_quadrant &lt;- kda_quadrant|&gt;\n  pivot_longer(cols = c(4:6), names_to = \"sum_satisfaction\", values_to = \"percent_score\")\n\n# Set the theme for the plot\n\ntheme_set(theme_msd()+ theme(\n  axis.text.y = element_text(color = GRAY6, size = 9),\n  axis.title.x = element_text(color = GRAY6, size = 10, margin = margin(6, 0, 15, 0, \"pt\")),\n  axis.title.y = element_text(color = GRAY6, size = 10),\n  axis.text.x = element_text(color = GRAY6, size = 9, margin = margin(0, 6, 0, 15, \"pt\"))\n))\n\n# Set seed for reproducible plot\n\nset.seed(123)\n\n\n# Plot ----\n# |- Palette ----\nsurvey_quest_palette &lt;- list(\"The salesperson has a recommendation\" = \"#1A242F\",\n                             \"The salesperson understanding your needs\" = \"#94989D\",\n                             \"The salesperson seems confident\" = \"#1A242F\",\n                             \"The salesperson is knowledgeable\" = \"#1A242F\",\n                             \"dark_text\" = \"#1A242F\",\n                             \"light_text\" = \"#94989D\")\n\n# |- Shape ----\n\nsurvey_quest_shape &lt;- list(\"The salesperson has a recommendation\" = 22,\n                             \"The salesperson understanding your needs\" = 21,\n                             \"The salesperson seems confident\" = 0,\n                             \"The salesperson is knowledgeable\" = 1)\n\n# Create text grobs for the labels with a specific font size and color\n\nlabel1 &lt;- textGrob(\"Very Dissatisfied\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6) )\nlabel2 &lt;- textGrob(\"Neutral\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6))\nlabel3 &lt;- textGrob(\"Very Satisfied\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6))\nlabel4 &lt;- textGrob(\"Low\", gp = gpar(fontsize = 9, col = GRAY6))\nlabel5 &lt;- textGrob(\"High\", gp = gpar(fontsize = 9, col = GRAY6))\n\n\n\n# | Quadrant Plot ----\n# | - Quadrant Base Panel ----\n\nquadrant_base &lt;- kda_quadrant|&gt;\n  ggplot(aes(x = cor_to_cust_loyalty,\n             y = percent_score))+\n  scale_x_continuous(expand = c(0,0),limits = c(0.3,0.6))+\n  scale_y_continuous(expand = c(0,0),\n                     limits = c(0,80),\n                     breaks = c(0, 30, 50, 80), \n                     labels = c(\"0\" = \"0\", \"30\" = \"30%\", \"50\" = \"50%\", \"80\" = \"80%\"))+\n\n # Add the labels to the plot using annotation_custom()\n   \n \n  annotation_custom(grob = label1, xmin = 0.292, xmax = 0.292, ymin = 9, ymax = 9) +\n  annotation_custom(grob = label2, xmin = 0.292, xmax = 0.292, ymin = 36, ymax = 36) +\n  annotation_custom(grob = label3, xmin = 0.292, xmax = 0.292, ymin = 65, ymax = 65) +\n  annotation_custom(grob = label4, ymin = -2.5, ymax = -2.5, xmin = 0.35, xmax = 0.35)+\n  annotation_custom(grob = label5, ymin = -2.5, ymax = -2.5, xmin = 0.55, xmax = 0.55)+ \n  coord_cartesian(clip = \"off\")+\n  theme(axis.line = element_blank())\n \n   \n\n\n# | - Quadrant Chart ----\n\n# Set axis labels and title\n\nlabelled_quadrant &lt;-  quadrant_base +\n    labs(x = \"Correlation to customer loyalty\",\n         y = \"Customer satisfaction survey\",\n        title = \"Customer Loyalty Key Driver Report\\n\")+\n   theme(axis.title.x = element_text(hjust = 0.5,\n                                     vjust = 4,\n                                     face = \"bold\"),\n         axis.title.y = element_text(hjust = 0.5,\n                                     vjust = 0,\n                                     face = \"bold\"),\n        plot.title = element_text(color = GRAY2, size= 12),\n        plot.title.position = \"plot\"\n         )+\n \n\n  \n# add four rectangle type of annotations to fill the four quadrant areas\n# create a border and split lines for the quadrant chart\n  \n  annotate(\"rect\", xmin = 0.45, xmax = 0.60, ymin = 40, ymax = 80, fill= \"#F8F9F9\")+\n  annotate(\"rect\", xmin = 0.3, xmax = 0.60, ymin = 0, ymax = 80 , fill= \"#F8F9F9\")+\n  annotate(\"rect\", xmin = 0.45, xmax = 0.60, ymin = 40, ymax = 80, fill= \"white\")+\n  annotate(\"rect\", xmin = 0.3, xmax = 0.60, ymin = 0, ymax = 80, fill= \"white\")+\n  theme(panel.border = element_rect(colour = \"lightgrey\", fill = NA, linewidth = 3))+\n  geom_hline(yintercept= 40, color = \"lightgrey\", linewidth =1.5)+\n  geom_vline(xintercept= 0.45, color = \"lightgrey\", linewidth =1.5) +\n          \n# add label to quadrant area\n\n  geom_label(aes(x = 0.375,\n                 y = 77,\n                 label = \"DISREGARD\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  geom_label(aes(x = 0.525,\n                 y = 77,\n                 label = \"LEVERAGE GREAT\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  geom_label(aes(x = 0.525,\n                 y = 3,\n                 label = \"IMPROVE WEAKNESS\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  \n# draw the questions survey to the chart with the position corresponding to their “customer satisfaction percent” value and “correlation to customer” value.\n  \n   geom_jitter(aes(x = cor_to_cust_loyalty,\n             y = percent_score,\n             color = survey_quest,\n             shape = survey_quest,\n             fill = survey_quest),\n         size = 5,\n         alpha = 0.8)+\n  theme( legend.position = \"top\",\n         legend.box = \"vertical\",\n         legend.margin = margin(unit(c(0,-0.45,0,0), \"cm\")),\n         legend.title = element_blank(),\n         legend.text = element_text(color = GRAY6, size = 9)) +\n  guides(shape = guide_legend(nrow = 2, byrow = TRUE),\n         fill = guide_legend(nrow = 2, byrow = TRUE),\n         color = guide_legend(nrow = 2, byrow = TRUE))+\n  scale_colour_manual(values = survey_quest_palette) +\n  scale_shape_manual(values = survey_quest_shape) +\n  scale_fill_manual(values = survey_quest_palette)\n   \n\n\nlabelled_quadrant"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#footnotes",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#footnotes",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe case study and the data description are sourced from the book Predictive HR Analytics : Mastering the HR Metric by Dr. Martin R. Edwards and Kirsten Edwards↩︎\nData available here↩︎\nI learned about this analysis in the book People Analytics For Dummies by Mike West↩︎"
  },
  {
    "objectID": "posts/digital_intensity_index_eu/index.html#eus-digital-intensity-index-dii",
    "href": "posts/digital_intensity_index_eu/index.html#eus-digital-intensity-index-dii",
    "title": "EU’s Digital Intensity Index (DII) in 2023",
    "section": "EU’s Digital Intensity Index (DII)",
    "text": "EU’s Digital Intensity Index (DII)\nDigital Intensity Index (DII) is a composite indicator, derived from the EU survey on ICT usage and e-commerce in enterprises.\nThe indicator is calculated based on 12 variables, with each of the variables having a score of 1 point. The DII distinguishes four levels of digital intensity for each enterprise:\n\nEnterprises with very low digital intensity index (0-3 points)\nEnterprises with low digital intensity index (4-6 points)\nEnterprises with high digital intensity index (7-9 points)\nEnterprises with very high digital intensity index (10-12 points)\n\nAdditionally, based on the four levels of the DII, a “basic level” of digital intensity is calculated for monitoring the goal of the Digital Decade. A basic level of digital intensity entails the use of at least four of the twelve selected variables, which means it includes enterprises with a low, high and very high level of the DII, excluding the very low level.\nOne of the goals for the EU’s digital transformation of businesses is that by 2030, more than 90% of small and medium-sized enterprises (SMEs) should reach at least a basic level of digital intensity.\n\nEnterprises with basic level of digital intensity in 2023\n\n\nCode\nlibrary(DBI)\nlibrary(tidyverse)\nlibrary(DT)\nsleep_default &lt;- 3\n\nSys.sleep(sleep_default)\ncon &lt;- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = 'digital_transformation_of_business', \n                 host = 'localhost', \n                 port = 5432, \n                 user = Sys.getenv(\"DEFAULT_POSTGRES_USER_NAME\"),\n                 password = Sys.getenv(\"DEFAULT_POSTGRES_PASSWORD\"),\n                 bigint = \"integer\") # change integer64 to integer\n\ndii_eu_countries &lt;- dbGetQuery(con, '\nSELECT \n  y.\"ExpPeriod\" AS \"Year\",\n  c.\"ExpCountryCaption\" AS \"Country\",\n  c.\"ExpCountry\" AS \"geo\",\n  i.\"ExpIndicatorCaption\" AS \"Indicator\",\n  es.\"ExpEntSizeCaption\" AS \"Enterprise Size\",\n  a.\"ExpActivityCaption\" AS \"Activity\",\n  u.\"ExpUnitCaption\" AS \"Unit\",\n  COALESCE(CAST(dwa.\"Value\" AS decimal) *100, 0) AS \"Value\",\n  dwa.\"Flags\" ,\n  n.\"Note\" \nFROM public.\"DataWithAggregates\" dwa \nINNER JOIN public.\"Years\" y ON dwa.\"IdYear\" = y.\"IdYear\" \nINNER JOIN public.\"Countries\" c ON dwa.\"IdCountry\" = c.\"IdCountry\" \nINNER JOIN public.\"Indicators\" i ON dwa.\"IdIndicator\" = i.\"IdIndicator\" \nINNER JOIN public.\"EntSizes\" es ON dwa.\"IdEntSize\" = es.\"IdEntSize\" \nINNER JOIN public.\"Activities\" a ON dwa.\"IdActivity\" = a.\"IdActivity\" \nINNER JOIN public.\"Regions\" r ON dwa.\"IdRegion\" = r.\"IdRegion\" \nINNER JOIN public.\"CustBrkdwns\" cb ON dwa.\"IdCustBrkdwn\" = cb.\"IdCustBrkdwn\" \nINNER JOIN public.\"Units\" u ON dwa.\"IdUnit\" = u.\"IdUnit\" \nINNER JOIN public.\"Notes\" n ON dwa.\"IdYear\"  = n.\"IdYear\" AND dwa.\"IdNote\" = n.\"IdNote\" \nWHERE y.\"IdYear\" = 23\n  AND c.\"IdCountry\" IN (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,22,23,25,26,27,28,29,30,31,45,48)\n  AND i.\"IdIndicator\" IN (1785,1786,1787,1788,1940,1941,1942,1943,2400,2401,2402,2403,2534,2535,2536,2537,3159,3360)\n  AND es.\"IdEntSize\" = 2578\n  AND a.\"IdActivity\" = 2585\n  AND r.\"IdRegion\" = 2631\n  AND cb.\"IdCustBrkdwn\" = 2632 \n  AND u.\"IdUnit\" = 16\nORDER BY \"Value\";')\n\ndii_filtered &lt;- dii_eu_countries |&gt;\n  select(Year, Country, Indicator, Unit,Value) |&gt;\n  filter(Indicator == 'Enterprises with at least low (basic) digital intensity index (DII Version 3)') |&gt;\n  mutate(Value = as.numeric(round(Value, 2)),\n         Year = 2023)\n  \ndatatable(dii_filtered, \n          options = list(pageLength = 5, \n          scrollY = TRUE),\n          caption = \"Source: Eurostat (https://ec.europa.eu/eurostat/web/digital-economy-and-society/\\ndatabase/comprehensive-database)\" \n)\n\n\n\n\n\n\n\n\nDigital Intensity Index Composition\nThe DII composition varies between different survey years, depending on the questions included in the survey. Below is the composition for the 2023:\n\nEnterprises where more than 50% of the persons employed have access to the internet for business purposes.\nThe maximum contracted download speed of the fastest fixed internet connection is at least 30 Mb/s.\nEnterprises with e-commerce sales of at least 1% turnover.\nEnterprises where web sales were more than 1% of the total turnover and B2C web sales more than 10% of the web sales.\nBuy cloud computing services used over the internet.\nEnterprises buying sophisticated or intermediate cloud computing services.\nUse two or more social media.\nUse any social media.\nData analytics for the enterprise is performed by the enterprise’s own employees or by an external provider\nUse any AI technology.\nEnterprises having ERP software package to share information between different functional areas.\nEnterprises using Customer Relationship Management (CRM).\n\nMore information about Digital Intensity Index here.\nThe visualization was inspired by Milos Popovic and his tutorial on making a visualization with a graph and a map."
  },
  {
    "objectID": "posts/time_series/1_time_series.html",
    "href": "posts/time_series/1_time_series.html",
    "title": "Time Series Analysis (Part I)",
    "section": "",
    "text": "In this post, I will practice a few examples of time series analysis inspired by the book SQL for Data Analysis: Advanced Techniques for Transforming Data into Insights using Retail and Food Services Sales data from this source. The data source, Monthly Retail Trade Report: Retail and Food Services Sales, includes monthly total sales and sales for different subcategories of retail sales from 1992 to 2020. It is an Excel file that I chose to import into PostgreSQL and use SQL to retrieve the data.\nThe purpose of these examples is to practice analyzing time series data. The data will be analyzed in SQL and graphed in R to visualize trends by month and year. First, I will look at the total monthly retail and food services sales, then I will compare the sales of two subcategories from the dataset: sales at new car dealers and sales at used car dealers, across the same time range."
  },
  {
    "objectID": "posts/time_series/1_time_series.html#total-retail-and-food-services-in-us",
    "href": "posts/time_series/1_time_series.html#total-retail-and-food-services-in-us",
    "title": "Time Series Analysis (Part I)",
    "section": "Total retail and food services in US",
    "text": "Total retail and food services in US\nI will start by looking at total monthly retail and food services sales.\n\nMonthly Retail and Food Services in US\n\nmonthly_rfs_sales &lt;- \"\nSELECT \n    rs.sales_month ,\n    rs.sales \nFROM training_data.retail_sales rs \nWHERE upper(rs.kind_of_business) = upper('retail and food services sales, total');\n\"\nmonthly_rfs_sales_tbl &lt;- (dbGetQuery(con, monthly_rfs_sales))\n\n\n\nCode\n(monthly_rfs_sales_plot &lt;- ggplot(monthly_rfs_sales_tbl, aes(x = sales_month, y = sales))+\n  geom_line(color = \"#222222\", linewidth = 1)+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  scale_x_date(date_breaks = '5 years',\n               labels = scales::date_format(\"%Y\"))+\n  labs(\n    title = 'Monthly Retail and Food Services Sales in US',\n    subtitle = '1992 to 2020',\n    x = '',\n    y = '$MM Sales'\n  )+\n  theme_ts()+\n    theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\")))\n)\n\n\n\n\n\n\n\n\n\nThe trend shows an increase, with two periods of decreasing sales. However, it is not so clear at monthly level. We can aggregate the data from monthly to yearly to make the results easier to understand.\n\n\nHow do the retail and food services sales look by year?\n\nyearly_rfs_sales &lt;- \"\nSELECT \n    date_part('year', rs.sales_month) AS year,\n    sum(rs.sales) AS sales\nFROM training_data.retail_sales rs \nWHERE upper(rs.kind_of_business) = upper('retail and food services sales, total')\nGROUP BY date_part('year', rs.sales_month);\n\"\nyearly_rfs_sales_tbl &lt;- (dbGetQuery(con, yearly_rfs_sales))\n\n\n\n\n\nYearly Retail and Food Services Sales\n\n\n\n\nCode\nyearly_rfs_sales_tbl &lt;- yearly_rfs_sales_tbl |&gt;\n  mutate(year = as.Date(paste0(year, \"-01-01\")))\n\n(yearly_rfs_sales_plot &lt;- ggplot(yearly_rfs_sales_tbl, aes(x = year, y = sales))+\n  geom_line(color = \"#222222\", linewidth = 1)+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  scale_x_date(date_breaks = '5 years',\n               labels = scales::date_format(\"%Y\"))+\n  labs(\n    title = 'Yearly Retail and Food Services Sales in US 1992-2020',\n    subtitle = 'After increasing over time, sales dropped in 2009 but then increased again  \\nover the next ten years. In 2020, sales were flat compared to 2019.',\n    x = '',\n    y = '$MM Sales'\n  )+\n    theme_ts()+\n    theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\"))\n    )+\n    annotate(\n      \"text\",\n      x = as.Date(c(\"2009-01-01\", \"2019-01-01\")),\n      y = c(4000000, 6550000),\n      label = c(\"Financial \\n crisis\", \"COVID-19\\npandemic\"),\n      vjust = c(1, 0.5),\n      hjust = c(0.5, 1),\n      colour = \"#222222\",\n      size = 6\n    )\n  )\n\n\n\n\n\n\n\n\n\nFor the next examples, I will look at sales at new and used car dealers, two of the subcategories included in the retail sales dataset."
  },
  {
    "objectID": "posts/time_series/1_time_series.html#comparing-yearly-sales-of-new-car-dealers-with-used-car-dealers",
    "href": "posts/time_series/1_time_series.html#comparing-yearly-sales-of-new-car-dealers-with-used-car-dealers",
    "title": "Time Series Analysis (Part I)",
    "section": "Comparing yearly sales of new car dealers with used car dealers",
    "text": "Comparing yearly sales of new car dealers with used car dealers\n\nnew_used_car_sales &lt;- \"\nSELECT \n    EXTRACT(YEAR FROM rs.sales_month) AS year,\n    rs.kind_of_business,\n    sum(rs.sales) as sales\nFROM training_data.retail_sales rs \nWHERE upper(rs.kind_of_business) = upper('new car dealers') OR \n      upper(rs.kind_of_business) = upper('used car dealers')\nGROUP BY EXTRACT(YEAR FROM rs.sales_month), rs.kind_of_business\nORDER BY year;\n\"\nnew_used_car_sales_tbl &lt;- (dbGetQuery(con, new_used_car_sales))\n\n\n\n\n\nNew and Used Car Yearly Sales\n\n\n\n\nCode\nnew_used_car_sales_tbl &lt;- new_used_car_sales_tbl |&gt;\n  mutate(year = as.Date(paste0(year, \"-01-01\")))\n\nnew_used_car_sales_tbl_plot &lt;- ggplot(new_used_car_sales_tbl, aes(x = year, y = sales, color = kind_of_business))+\n  geom_line(linewidth = 1)+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  scale_x_date(date_breaks = \"5 years\",\n               label= scales::date_format(\"%Y\"))+\n  scale_color_manual(values = c('New car dealers' = \"#222222\", 'Used car dealers' = \"#1380A1\" ))+\n  labs(\n    title = 'Yearly New and Used Car Deales Sales in US 1992-2020',\n    subtitle = 'Sales at new car dealers grew faster than sales at used car dealers. \\nSales dropped during the financial crisis but increased again in the following years. \\nDuring the COVID-19 pandemic sales of new cars began to decline.',\n    x = '',\n    y = '$MM Sales',\n  )+\n  theme_ts()+\n  theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\")),\n      legend.position = \"none\")+\n  annotate(\n    'rect',\n    xmin = as.Date(c(\"2008-01-01\", \"2019-01-01\")),\n    xmax = as.Date(c(\"2010-01-01\", \"2020-01-01\")),\n    ymin = c(0, 0),\n    ymax = c(750000,1000000),\n    fill = '#A6A6A5',\n    alpha = 0.1\n  )+\n  annotate(\n    'text',\n    x = as.Date(c(\"2007-01-01\", \"2017-06-01\")),\n    y = c(460000, 950000),\n    label = c(\"2007–2008 financial crisis \\n2008-2010 automotive \\nindustry crisis\",\n                \"COVID-19 \\ncrisis\"),\n    size = 6,\n    hjust = 0,\n    vjust = c(1, 0)\n    )\n\n  \n (new_used_car_sales_tbl_plot &lt;- new_used_car_sales_tbl_plot +\n    geom_label(aes(x = as.Date(\"2019-07-01\"), y = 900000, label = \"New /ncar\"), \n                hjust = 0, \n                vjust = 0.5, \n                colour = \"#222222\", \n                fill = \"white\", \n                label.size = NA, \n                family=\"Microsoft Sans Serif\", \n                size = 6) +\n    geom_label(aes(x = as.Date(\"2019-07-01\"), y = 119000, label = \"Used /ncar\"), \n                hjust = 0, \n                vjust = 0.5, \n                colour = \"#1380A1\", \n                fill = \"white\", \n                label.size = NA, \n                family=\"Microsoft Sans Serif\", \n                size = 6)\n )\n\n\n\n\n\n\n\n\n\nAs we saw, new car sales are considerably higher than used car sales, but what exactly are the values of new and used car dealers’ sales as a percent of total monthly sales?\n\nnew_and_used_car_sales_percent &lt;- \"\nSELECT\n    rs.sales_month,\n    rs.kind_of_business,\n    sum(rs.sales) AS category_sales,\n    sum(sum(rs.sales)) OVER (PARTITION BY rs.sales_month) AS total_sales,\n    round(sum(rs.sales) / sum(sum(rs.sales)) OVER (PARTITION BY rs.sales_month) * 100, 2) AS category_percent\nFROM training_data.retail_sales rs \nWHERE rs.kind_of_business IN ('New car dealers', 'Used car dealers')\nGROUP BY rs.sales_month, rs.kind_of_business\nORDER BY rs.sales_month;;\n\"\nnew_and_used_car_sales_percent_tbl &lt;- (dbGetQuery(con, new_and_used_car_sales_percent))\n\n\n\n\n\n\n\n\n\nCode\nnew_and_used_car_sales_percent_plot &lt;- ggplot(new_and_used_car_sales_percent_tbl, aes(x = sales_month, y = category_percent, color = kind_of_business ))+\n  geom_line(linewidth = 1)+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_x_date(date_breaks = \"3 years\",\n               labels = scales::date_format(\"%Y\"))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1),\n                     breaks = seq(0,100,25))+\n  scale_color_manual(values = c('New car dealers' = \"#222222\", 'Used car dealers' = \"#1380A1\"))+\n  labs(\n    title = 'New and used car dealers sales as percent of monthly total \\nin the US 1992-2020',\n    subtitle = \"Car dealers' sales of new and used cars over the last few decades \\nhave not changed significantly as a percentage of the monthly total.\",\n    x = 'Sales Month',\n    y = 'Percent'\n  )+\n  theme_ts()+\n  theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\")),\n      axis.title.x = element_text(hjust = 0.5,  size = 18, \n                                  margin = margin(6, 0, 15, 0, \"pt\")),\n      legend.position = \"none\")\n\n (new_and_used_car_sales_percent_plot &lt;- new_and_used_car_sales_percent_plot +\n    geom_label(aes(x = as.Date(\"2020-01-01\"), y = 80, label = \"New \\ncar\"), \n                hjust = 0, \n                vjust = 0.5, \n                colour = \"#222222\", \n                fill = \"white\", \n                label.size = NA, \n                family=\"Microsoft Sans Serif\", \n                size = 6) +\n    geom_label(aes(x = as.Date(\"2020-01-01\"), y = 7, label = \"Used \\ncar\"), \n                hjust = 0, \n                vjust = 0.5, \n                colour = \"#1380A1\", \n                fill = \"white\", \n                label.size = NA, \n                family=\"Microsoft Sans Serif\", \n                size = 6)\n )"
  },
  {
    "objectID": "posts/time_series/1_time_series.html#during-the-past-few-decades-how-have-sales-of-new-and-used-cars-dealers-varied-in-dollars-and-percent",
    "href": "posts/time_series/1_time_series.html#during-the-past-few-decades-how-have-sales-of-new-and-used-cars-dealers-varied-in-dollars-and-percent",
    "title": "Time Series Analysis (Part I)",
    "section": "During the past few decades, how have sales of new and used cars dealers varied in dollars and percent?",
    "text": "During the past few decades, how have sales of new and used cars dealers varied in dollars and percent?\n\ngap_percent_sales_cars &lt;- \"\nWITH car_sales AS \n    (SELECT \n        EXTRACT (YEAR FROM rs.sales_month) AS year,\n        sum(CASE WHEN upper(rs.kind_of_business) = upper('New car dealers') THEN rs.sales END) AS new_car_sales,\n        sum(CASE WHEN upper(rs.kind_of_business) = upper('Used car dealers') THEN rs.sales END) AS used_car_sales\n    FROM training_data.retail_sales rs\n    GROUP BY EXTRACT (YEAR FROM rs.sales_month)\n    ORDER BY year)\nSELECT \n    cs.year,\n    cs.new_car_sales,\n    cs.used_car_sales,\n    (cs.new_car_sales - cs.used_car_sales) AS delta,\n    round((cs.new_car_sales / cs.used_car_sales), 2) AS ratio,\n    round(((cs.new_car_sales / cs.used_car_sales) -1)*100, 2) AS percent\nFROM car_sales cs;\n\"\ngap_percent_sales_cars_tbl &lt;- (dbGetQuery(con, gap_percent_sales_cars))\n\n\n\n\n\n\n\n\n\nCode\ngap_percent_sales_cars_tbl &lt;- gap_percent_sales_cars_tbl|&gt;\n  mutate(year = as.Date(paste0(year, \"-01-01\")))\n\ngap_sales_cars_tbl_plot &lt;- ggplot(gap_percent_sales_cars_tbl, aes(x = year, y = delta))+\n  geom_line(linewidth = 1, color = \"#222222\")+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_x_date(date_breaks = '5 years',\n              labels = scales::date_format('%Y'))+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    subtitle = 'The yearly difference in dollars between sales \\nof new and used cars increased from 1992 to 2006, \\nfollowed by a decrease until 2009 when \\nit returned to 1995 levels.Then it increased again until \\n2019 when it started to decrease.',\n    x = 'Year',\n    y = '$MM'\n    )+\n  theme_ts()+\n  theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\")),\n      axis.title.x = element_text(hjust = 0.5,  size = 18, \n                                  margin = margin(6, 0, 15, 0, \"pt\")),\n      plot.subtitle = element_text(size = 18))\n\npercent_sales_cars_tbl_plot &lt;- ggplot(gap_percent_sales_cars_tbl, aes(x = year, y = percent))+\n  geom_line(linewidth = 1, color = \"#222222\")+\n  geom_hline(yintercept = 0, linewidth = 1, colour=\"#333333\")+\n  scale_x_date(date_breaks = '5 years',\n              labels = scales::date_format('%Y'))+\n  scale_y_continuous(labels = scales::percent_format(scale = 1),\n                     breaks = seq(0, 1300, 250))+\n  labs(\n    subtitle = 'From 1993 to 2009, the percent difference between \\nsales at new car dealers and used car \\ndealers declined (it slightly increased in 2001). \\nThen, the percent diffrenece increased until 2014, \\nand again decreased until 2020, returning \\nto 2009 values.',\n    x = 'Year',\n    y = 'Percent'\n    )+\n  theme_ts()+\n  theme(\n      panel.grid.minor = element_line(),\n      axis.title.y = element_text(hjust = 0.5, size = 18,\n                                  margin = margin(0, 6, 0, 15, \"pt\")),\n      axis.title.x = element_text(hjust = 0.5,  size = 18, \n                                  margin = margin(6, 0, 15, 0, \"pt\")),\n      plot.subtitle = element_text(size = 18))\n  \n\n\n(combine_plot &lt;- gap_sales_cars_tbl_plot +\n  plot_spacer() +\n  percent_sales_cars_tbl_plot +\n  plot_layout(widths = c(8, -0.0005, 8)) +\n  plot_annotation(\n    title = 'Yearly sales and percent difference between sales at new \\nand used car dealers in the US 1992-2020') &\n    theme(plot.title = element_text(size = 28))\n  )"
  },
  {
    "objectID": "posts/time_series/1_time_series.html#conclusion",
    "href": "posts/time_series/1_time_series.html#conclusion",
    "title": "Time Series Analysis (Part I)",
    "section": "Conclusion",
    "text": "Conclusion\nIn the above examples, I practiced simple techniques to trend time series data, including aggregating data from monthly to yearly to make the results easier to understand, comparing components, and using percent of the total to compare parts to the whole. Time series analysis is a powerful way to analyze data. In the next post, I will practice and share more methods for smoothing time series data."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html",
    "href": "posts/digital_skills_indicator_eda(I)/index.html",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "",
    "text": "This post is part of a series that examines the composite indicators of the EU Digital Decade. Previously, I explored the Digital Intensity Index, which measures the digital transformation of businesses. This time, the focus is on the Digital Skills Indicator (DSI), which is one of key performance indicators in the context of the Digital Decade.\nThe goal of this analysis is to improve our understanding of the current state of digital competencies within the EU population and to evaluate the progress made in 2023 compared to 2021. First, I will provide an overview of composite indicators and introduce the DSI. Then, using open data from Eurostat, I will perform an exploratory data analysis of the DSI components and conclude by sharing key insights from the analysis."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#introducing-digital-skills-indicator",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#introducing-digital-skills-indicator",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Introducing Digital Skills Indicator",
    "text": "Introducing Digital Skills Indicator\nIn this section, I introduce the Digital Skills Indicator, a composite measure used to assess the digital competencies of individuals across the EU.\nBefore diving into composite indicators, it is essential to understand what indicators are. Indicators are tools used across various fields, such as economics, education, health, and environmental science, to monitor changes, trends, or conditions. You might already be familiar with key performance indicators (KPIs), which are quantitative or qualitative measures used to track progress toward specific goals. However, when addressing complex, multi-dimensional issues, relying on individual indicators alone may not be sufficient. This is where composite indicators come into play.\nComposite indicators\nComposite indicators aggregate multiple individual indicators into a single, comprehensive measure, offering a summarized view of complex phenomena. For instance, the Human Development Index (HDI) combines indicators like life expectancy, education level, and income to measure a country’s overall development.\nCreating a composite indicator involves several steps: selecting relevant individual indicators, normalizing them (especially when they are on different scales), assigning weights based on their importance, and then aggregating them into a final score. The primary purpose of composite indicators is to simplify complex data, making it easier to interpret, compare, and communicate findings, particularly in broad, multi-dimensional contexts.\nDigital Skills Indicator\nThe Digital Skills Indicator (DSI) is essential for monitoring the EU’s progress towards its Digital Decade goals. Specifically, it aims for at least 80% of citizens aged 16-74 to possess basic digital skills by 2030.\nThe DSI is a composite indicator derived from surveys on ICT (Information and Communication Technology) use in households and by individuals. It assesses five key areas: information and data literacy, communication and collaboration, digital content creation, safety, and problem-solving. The assumption is that individuals who perform specific digital activities possess the corresponding skills. To be classified as having at least basic digital skills, individuals must demonstrate competence in at least one activity in each of these areas.\nThe DSI focuses on people aged 16-741, and for detailed information on DSI levels and the activities related to each skill, Eurostat provides comprehensive metadata."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#competence-areas2",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#competence-areas2",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Competence Areas2\n",
    "text": "Competence Areas2\n\nThe Digital Skills Indicator covers five core competence areas, which are essential for assessing digital skills:\n\n\n\nInformation and Data Literacy\n\nArticulate information needs.\nLocate and retrieve digital data, information, and content.\nJudge the relevance of the source and its content.\nStore, manage, and organize digital data, information, and content.\n\n\n\nCommunication and Collaboration\n\nInteract, communicate, and collaborate through digital technologies.\nBe aware of cultural and generational diversity.\nParticipate in society through public and private digital services.\nManage one’s digital presence, identity, and reputation.\n\n\n\nDigital Content Creation\n\nCreate and edit digital content.\nImprove and integrate information and content into an existing body of knowledge.\nUnderstand how copyright and licenses are to be applied.\nKnow how to give understandable instructions for a computer system.\n\n\n\nSafety\n\nProtect devices, content, personal data, and privacy in digital environments.\nProtect physical and psychological health.\nBe aware of digital technologies for social well-being and social inclusion.\nBe aware of the environmental impact of digital technologies and their use.\n\n\n\nProblem Solving\n\nIdentify needs and problems in digital environments.\nResolve conceptual problems and problem situations in digital environments.\nUse digital tools to innovate processes and products.\nKeep up-to-date with the digital evolution."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#why-understanding-digital-skills-data-matters",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#why-understanding-digital-skills-data-matters",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Why Understanding Digital Skills Data Matters",
    "text": "Why Understanding Digital Skills Data Matters\nIn today’s digital world, possessing digital skills is a necessity. Understanding DSI data is essential as it provides insights into the current state of digital competencies within the EU population. This data is vital for policymakers, educators, businesses, and individuals to identify areas where digital skills are lacking, target interventions, and monitor progress toward digital literacy goals. Staying informed about digital skills data ensures that societies can effectively participate in the digital economy, foster innovation, and close the digital divide."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#exploratory-data-analysis",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#exploratory-data-analysis",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExploratory Data Analysis (EDA) focuses on understanding DSI data, identifying patterns, and generating hypotheses for further analysis. This involves visualizing data, calculating summary statistics, and identifying trends and relationships among variables.\nThe key question guiding this analysis is: What do the distributions of the Digital Skills Indicator components for 2021 and 2023 reveal about the overall shifts in digital skills across the EU population?\nData Collection\nThe data analyzed is sourced from Eurostat’s database on individuals’ digital skills.\nThe analysis uses several packages, including eurostat2 for data retrieval, tidyverse3 for data manipulation and visualization, janitor4 for data cleaning, reactable5 for interactive tables and patchwork6 for plot composition.\nPackages\n\nShow the codelibrary(eurostat)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(reactable)\nlibrary(patchwork)\n\nsource(\"theme_ts.R\")\n\n\nDownload data\n\nShow the code# Search for the data set\nsearch_results &lt;- search_eurostat(\"isoc_sk_dskl_i21\", column = \"code\")\n\nid &lt;- search_results$code[1]\n\n# Retrieve data \ndat &lt;- get_eurostat(id,\n                    time_format = \"num\",\n                    type = \"label\",\n                    stringsAsFactors = TRUE)\n\n\nindexed 0B in  0s, 0B/s\nindexed 2.15GB in  0s, 2.15GB/s\n                                                                              \n\nShow the code# Inspect the structure of the data set\nglimpse(dat)\n\nRows: 397,473\nColumns: 7\n$ freq        &lt;fct&gt; Annual, Annual, Annual, Annual, Annual, Annual, Annual, An…\n$ ind_type    &lt;fct&gt; \"Individuals who are born in another EU Member State\", \"In…\n$ indic_is    &lt;fct&gt; \"Individuals with above basic overall digital skills (all …\n$ unit        &lt;fct&gt; Percentage of individuals, Percentage of individuals, Perc…\n$ geo         &lt;fct&gt; \"Austria\", \"Austria\", \"Belgium\", \"Belgium\", \"Bulgaria\", \"B…\n$ TIME_PERIOD &lt;dbl&gt; 2021, 2023, 2021, 2023, 2021, 2023, 2021, 2023, 2021, 2023…\n$ values      &lt;dbl&gt; 42.73, 37.81, 35.50, 34.31, NA, 24.99, 7.34, 16.67, 30.24,…\n\n\nExplore data set\n\nShow the codeskimr::skim(dat)\n\n\nData summary\n\n\nName\ndat\n\n\nNumber of rows\n397473\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n5\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nfreq\n0\n1\nFALSE\n1\nAnn: 397473\n\n\nind_type\n0\n1\nFALSE\n126\nInd: 3476, Fem: 3476, Fem: 3476, Fem: 3476\n\n\nindic_is\n0\n1\nFALSE\n24\nInd: 16924, Ind: 16924, Ind: 16924, Ind: 16924\n\n\nunit\n0\n1\nFALSE\n2\nPer: 203038, Per: 194435\n\n\ngeo\n0\n1\nFALSE\n38\nSpa: 11633, Aus: 11609, Cze: 11562, Est: 11562\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nTIME_PERIOD\n0\n1.00\n2021.97\n1.00\n2021\n2021.00\n2021.00\n2023.00\n2023\n▇▁▁▁▇\n\n\nvalues\n14185\n0.96\n42.50\n34.28\n0\n10.97\n32.22\n76.74\n100\n▇▅▂▂▅\n\n\n\n\n\nThe data set contains 397.473 rows and 7 columns. Here are the columns and their data types:\n\n\nfreq - factor, representing the frequency of data collection\n\nind_type - factor, representing the category of individuals surveyed\n\nind_is - factor, representing the specific digital skills indicator\n\nunit - factor, describing the unit of measure\n\ngeo - factor, representing the country name\n\nTIME PERIOD - numeric, representing the year of the survey\n\nvalues - numeric, representing the actual value of the indicator in percentage\n\nThere are 54 ind_type with 14185 missing values. I will keep them as they are, as the data may not exist.\nFor more detailed information about the dataset, refer to metadata on individuals’ level of digital skills.\nData Cleaning\nRename columns\n\nShow the code# Rename columns\n\ndigital_skills &lt;- dat |&gt;\n  mutate(category = as.factor(ind_type),\n         indicator = as.factor(indic_is),\n         country = as.factor(geo),\n         year = as.factor(TIME_PERIOD),\n         value = as.numeric(values)) |&gt;\n  select(year, country, indicator, category, unit, value)\n\nglimpse(digital_skills)\n\nRows: 397,473\nColumns: 6\n$ year      &lt;fct&gt; 2021, 2023, 2021, 2023, 2021, 2023, 2021, 2023, 2021, 2023, …\n$ country   &lt;fct&gt; \"Austria\", \"Austria\", \"Belgium\", \"Belgium\", \"Bulgaria\", \"Bul…\n$ indicator &lt;fct&gt; \"Individuals with above basic overall digital skills (all fi…\n$ category  &lt;fct&gt; \"Individuals who are born in another EU Member State\", \"Indi…\n$ unit      &lt;fct&gt; Percentage of individuals, Percentage of individuals, Percen…\n$ value     &lt;dbl&gt; 42.73, 37.81, 35.50, 34.31, NA, 24.99, 7.34, 16.67, 30.24, 3…\n\n\nFiltering data\nThe dataset is filtered to include the five digital skills areas and overall digital skills, each categorized into three proficiency levels: “Above basic skills,” “Basic skills,” and “Basic or above basic skills (at least basic digital skills).” The analysis focuses on EU member states and the European Union - 27 countries (as of 2020), considering only the “percentage of individuals” as a unit and “all individuals” as the category.\n\nShow the codedigital_skills_filtered &lt;- digital_skills |&gt;\n  filter(!indicator %in% c(\"Individuals with online information and communication skills\",\n                           \"Individuals with limited overall digital skills (two out of five component indicators are at basic or above basic level)\",\n                           \"Individuals with low overall digital skills (four out of five component indicators are at basic or above basic level)\",\n                           \"Individuals with narrow overall digital skills (three out of five component indicators are at basic or above basic level)\",\n                           \"Digital skills could not be assessed because the individual has not used the internet in the last 3 months\",\n                           \"Individuals with no overall digital skills\"),\n         !country %in% c(\"Türkiye\", \"North Macedonia\",\"Montenegro\", \"Switzerland\", \"Bosnia and Herzegovina\",\"Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)\", \"Iceland\", \"Serbia\", \"Norway\", \"Albania\" ),\n         unit == \"Percentage of individuals\",\n         category == \"All Individuals\") |&gt;\n  mutate(value = round(value, 2),\n         country = ifelse(country == \"European Union - 27 countries (from 2020)\", \"EU\", country)) |&gt;\n  select(year, country, indicator, category, unit, value)\n\n\nSummary Statistics\nThis section explores the data related to the DSI components using using measures of central tendency (mean, median) and measures of spread (minimum, maximum, standard deviation).\nMeasures of central tendency\n\nShow the code# Summarize the data\ndigital_skills_summary &lt;- digital_skills_filtered |&gt;\n  filter(country != \"EU\") |&gt;\n  group_by(indicator, year) |&gt;\n  summarise(\n    mean = round(mean(value, na.rm = TRUE), 2),\n    median = round(median(value, na.rm = TRUE), 2),\n    count = n(),\n    minimum = min(value, na.rm = TRUE), \n    maximum = max(value, na.rm = TRUE),\n    standard_deviation = round(sd(value, na.rm = TRUE),2)\n  ) |&gt;\n  ungroup() |&gt;\n\n  # Extract `digital skills` and `indicator level` from the `indicator` column\n mutate(\n    digital_skills = case_when(\n      str_detect(indicator, \"communication and collaboration\") ~ \"Communication and Collaboration Skills\",\n      str_detect(indicator, \"digital content creation\") ~ \"Digital Content Creation Skills\",\n      str_detect(indicator, \"information and data literacy\") ~ \"Information and Data Literacy Skills\",\n      str_detect(indicator, \"overall digital skills\") ~ \"Overall Digital Skills\",\n      str_detect(indicator, \"problem solving skills\") ~ \"Problem Solving Skills\",\n      str_detect(indicator, \"safety skills\") ~ \"Safety Skills\"\n    ),\n    indicator_level = case_when(\n      # Special case for overall digital skills with basic level\n      str_detect(indicator, \"basic overall digital skills \\\\(all five component indicators are at basic or above basic level, without being all above basic\\\\)\") ~ \n        \"Individuals with basic skills\",\n      \n      # Other cases using ifelse() to handle the overall digital skills\n      str_detect(indicator, \"overall digital skills\") ~ ifelse(\n        str_detect(indicator, \"basic or above basic\"), \n        \"Individuals with basic or above basic skills\", \n        \"Individuals with above basic skills\"\n      ),\n      \n      # General cases\n      str_detect(indicator, \"basic or above basic\") ~ \"Individuals with basic or above basic skills\",\n      str_detect(indicator, \"above basic\") ~ \"Individuals with above basic skills\",\n      str_detect(indicator, \"basic\") ~ \"Individuals with basic skills\"\n    )\n  ) |&gt;\n  select(digital_skills, indicator_level, year, mean, median, count, minimum, maximum, standard_deviation)\n\n\n\nShow the codereactable(digital_skills_summary,\n          searchable = TRUE,\n          showPageInfo = TRUE,\n          groupBy = c(\"digital_skills\",\"year\"),\n          columnGroups = list(\n            colGroup(\"Indicator\", columns = c(\"digital_skills\", \"indicator_level\")),\n            colGroup(\"Year\", columns = \"year\"),\n            colGroup(\"Summary Statistics\", columns = c(\"mean\", \"median\", \"count\", \"minimum\", \"maximum\", \"standard_deviation\"))),\n          columns = list(digital_skills = colDef(minWidth = 300, defaultSortOrder = \"asc\"),\n                         indicator_level = colDef(minWidth = 300, defaultSortOrder = \"asc\")),\n          defaultSorted = c(\"digital_skills\",\"indicator_level\"),\n          resizable = TRUE,\n          wrap = FALSE,\n          bordered = TRUE\n          )\n\n\n\n\n\nMeasures of spread\nFilter the data set\n\nShow the code# Summarize the data\ndigital_skills_distrib &lt;- digital_skills_filtered |&gt;\n  filter(country != \"EU\") |&gt;\n  mutate(\n    digital_skills = case_when(\n      str_detect(indicator, \"communication and collaboration\") ~ \"Communication and Collaboration Skills\",\n      str_detect(indicator, \"digital content creation\") ~ \"Digital Content Creation Skills\",\n      str_detect(indicator, \"information and data literacy\") ~ \"Information and Data Literacy Skills\",\n      str_detect(indicator, \"overall digital skills\") ~ \"Overall Digital Skills\",\n      str_detect(indicator, \"problem solving skills\") ~ \"Problem Solving Skills\",\n      str_detect(indicator, \"safety skills\") ~ \"Safety Skills\"\n    ),\n    indicator_level = case_when(\n      # Special case for overall digital skills with basic level\n      str_detect(indicator, \"basic overall digital skills \\\\(all five component indicators are at basic or above basic level, without being all above basic\\\\)\") ~ \n        \"Individuals with basic skills\",\n      \n      # Other cases using ifelse() to handle the overall digital skills\n      str_detect(indicator, \"overall digital skills\") ~ ifelse(\n        str_detect(indicator, \"basic or above basic\"), \n        \"Individuals with basic or above basic skills\", \n        \"Individuals with above basic skills\"\n      ),\n      \n      # General cases\n      str_detect(indicator, \"basic or above basic\") ~ \"Individuals with basic or above basic skills\",\n      str_detect(indicator, \"above basic\") ~ \"Individuals with above basic skills\",\n      str_detect(indicator, \"basic\") ~ \"Individuals with basic skills\"\n    )\n  ) |&gt;\n  select(year, country, digital_skills, indicator_level, value)\n\n\nVisualization\nThe visualization presents the distribution of digital skills by proficiency level across EU countries, divided into three categories: Basic Skills, Above Basic Skills, and Basic or Above Skills. The data is compared between two years, 2021 and 2023, across five skill components :\nCommunication and Collaboration Skills Digital Content Creation Skills Information and Data Literacy Skills Problem Solving Skills Safety Skills\nand Overall Digital Skills\n\n\nHistogram\nBoxplot and Violin Plot\n\n\n\nThe histograms show the frequency distribution of proficiency levels across EU countries.\n\nBasic Skills: The histograms for basic skills generally show that most EU countries have a low to moderate percentage of individuals with basic digital skills, with some variability between 2021 and 2023. There is a slight shift in distribution between the two years for most components, indicating possible changes in proficiency levels over time.\nAbove Basic Skills: The histograms for above basic skills show higher proficiency levels. The data for 2023 often shows a broader spread or a slight shift compared to 2021, suggesting an increase in higher proficiency levels in some countries.\nBasic or Above Skills: The combined category shows that the majority of countries have a high percentage of individuals with at least basic digital skills. The distributions are generally skewed towards higher values, with some movement between the years.\n\n\nShow the code# Set global font family\ntheme_set(theme_minimal(base_family = \"Roboto\"))\n\n# Prepare data (pivot_wider)\ndigital_skills_hist &lt;- digital_skills_distrib |&gt;\n  pivot_wider(names_from = indicator_level, values_from = value) |&gt;\n  clean_names()\n\n# Define color for each proficiency level\ncolors &lt;- c(\"Above Basic Skills\" = \"white\",  \n            \"Basic Skills\" = \"white\",        \n            \"Basic or Above Skills\" = \"white\") \n\n\n# Function to generate the plots for each skill\nplot_skill_histograms &lt;- function(data, skill) {\n  skill_data &lt;- data |&gt;\n    filter(digital_skills == skill)\n\n\n  # Basic Skills plot\n  plot_basic &lt;- ggplot(skill_data, aes(x = individuals_with_basic_skills)) +\n    geom_histogram(color = \"#222222\",\n                   fill = colors[\"Basic Skills\"],\n                   binwidth = function(x) (max(x) - min(x)) / 5) +\n    facet_grid(. ~ year) +\n    labs(y = \"Frequency\",\n         x = \"\", \n         title = skill) +\n    theme_ts() +\n    theme(plot.title = element_text(size = 10, \n                                    hjust = 0,  \n                                    color = \"#525252\"),\n          axis.title.y = element_text(size = 10, \n                                      margin = margin(r = 10), \n                                      color = \"#525252\"),\n          axis.text = element_text(size = 8.5, \n                                   color = \"#525252\"),\n          strip.text = element_blank(),\n          panel.grid.minor = element_blank())\n\n\n\n  # Above Basic Skills plot\n  plot_above_basic &lt;- ggplot(skill_data, aes(x = individuals_with_above_basic_skills)) +\n    geom_histogram(color = \"#33645FFF\", \n                   fill = colors[\"Above Basic Skills\"], \n                   binwidth = function(x) (max(x) - min(x)) / 5) +\n    facet_grid(. ~ year) +\n    labs(y = \"\", \n         x = \"\") +\n    theme_ts() +\n    theme(plot.title = element_blank(),\n          axis.title.y = element_blank(),\n          axis.text = element_text(size = 8.5, \n                                   color = \"#525252\"),\n          strip.text = element_blank(),\n          panel.grid.minor = element_blank())\n\n  \n  # Basic or Above Skills plot\n  plot_basic_or_above &lt;- ggplot(skill_data, aes(x = individuals_with_basic_or_above_basic_skills)) +\n    geom_histogram(color = \"#9D1B1FFF\",\n                   fill = colors[\"Basic or Above Skills\"], \n                   binwidth = function(x) (max(x) - min(x)) / 5) +\n    facet_grid(. ~ year) +\n    labs(y = \"\", \n         x = \"\") +\n    theme_ts() +\n    theme(plot.title = element_blank(),\n          axis.title.y = element_blank(),\n          axis.text = element_text(size = 8.5, \n                                   color = \"#525252\"),\n          strip.text = element_blank(),\n          panel.grid.minor = element_blank())\n\n  # Combine the three plots into a single row\n  combined_plot &lt;- plot_basic + plot_above_basic + plot_basic_or_above +  plot_layout(ncol = 3,\n               widths = c(1.1, 1.1, 1.1), \n               guides = \"collect\")\n  \n  return(combined_plot)\n}\n\n# List of skills\nskills_list &lt;- c(\"Communication and Collaboration Skills\",\n                 \"Digital Content Creation Skills\",\n                 \"Information and Data Literacy Skills\",\n                 \"Problem Solving Skills\",\n                 \"Safety Skills\",\n                 \"Overall Digital Skills\")\n\n# Generate and combine all plots using patchwork\nall_plots &lt;- lapply(skills_list, function(skill) plot_skill_histograms(digital_skills_hist, skill)) |&gt;\n  wrap_plots(ncol = 1)\n\n\n# Create a custom legend plot \nlegend_plot &lt;- ggplot() +\n  # Row 1: Proficiency Level annotations\n  annotate(\"text\", x = 0.15, y = 0.98, label = \"Basic Skills\", size = 4, hjust = 0, color = \"#222222\") +\n  annotate(\"text\", x = 1.15, y = 0.98, label = \"Above Basic Skills\", size = 4, hjust = 0, color = \"#33645FFF\") +\n  annotate(\"text\", x = 2.1, y = 0.98, label = \"Basic or Above Skills\", size = 4, hjust = 0, color = \"#9D1B1FFF\") +\n  # Row 2: Year annotations\n  annotate(\"text\", x = 0.08, y = 0.9, label = \"2021\", size = 4, hjust = 0, color = \"#222222\") +\n  annotate(\"text\", x = 0.48, y = 0.9, label = \"2023\", size = 4, hjust = 0, color = \"#222222\") +\n  annotate(\"text\", x = 1.1, y = 0.9, label = \"2021\", size = 4, hjust = 0, color = \"#33645FFF\") +\n  annotate(\"text\", x = 1.6, y = 0.9, label = \"2023\", size = 4, hjust = 0, color = \"#33645FFF\") +\n  annotate(\"text\", x = 2.1, y = 0.9, label = \"2021\", size = 4, hjust = 0, color = \"#9D1B1FFF\") +\n  annotate(\"text\", x = 2.7, y = 0.9, label = \"2023\", size = 4, hjust = 1, color = \"#9D1B1FFF\") +\n  # Adjust themes to avoid extra elements\n  theme_void() +\n  theme(plot.margin = margin(0, 0, 0.5, 0, \"cm\")) +\n  coord_cartesian(clip = \"off\") # Ensure text isn't clipped\n# Adjust spacing\nlegend_plot &lt;- legend_plot + plot_layout(heights = unit(1, \"cm\"))\n\n\n\n# Combine the custom legend with the main plot\nhistogram_plot &lt;- (legend_plot / all_plots) +\n  plot_layout(heights = c(0.05, 0.95)) + # Adjust the height of the legend\n  plot_annotation(\n    title = \"Distribution of Digital Skills by Proficiency Level\",\n    subtitle = \"% of individuals | age 16-74 | EU countries\",\n    theme = theme(plot.title = element_text(size = 20,\n                                            color = \"#252525\", \n                                            face = \"bold\", \n                                            margin = margin(b = 10)),\n                  plot.subtitle = element_text(size = 16,\n                                            color = \"#525252\", \n                                            margin = margin(b = 15))\n)\n  )\n\n\n\n\nThe boxplots summarize the distribution of digital skills proficiency across EU countries by displaying the median (middle line), quartiles (the box), and potential outliers (dots outside the whiskers).\nThe violin plots add context by illustrating the density of the data, showing how the values are distributed across different proficiency levels.\nFor example, in “Problem Solving Skills” (Basic Skills), the boxplot shows the central 50% of countries within the box, with a clear median line. Also, the boxplot shows us clearly the outliers (extreme values), small circles or dots, indicating countries with significantly different proficiency levels compared to others.\nIn another example, “Communication and Collaboration Skills” (Above Basic Skills, 2023), the boxplot shows that the central 50% of countries have proficiency levels roughly between 70% and 90%, with the median at about 80%.\n\nShow the code# Set global font family\ntheme_set(theme_minimal(base_family = \"Roboto\"))\n\ncolor_palette = c(\"Individuals with basic skills\" = \"#252525\",\n                  \"Individuals with above basic skills\" = \"#33645FFF\",\n                  \"Individuals with basic or above basic skills\" = \"#9D1B1FFF\")\n\n\n# Reorder digital_skills so \"Overall Digital Skills\" appears last\ndigital_skills_distrib &lt;- digital_skills_distrib |&gt;\n  mutate(digital_skills = fct_relevel(digital_skills, \"Overall Digital Skills\", after = Inf))\n\nboxplot_plot &lt;- ggplot(digital_skills_distrib,\n       aes(x = value,\n           y = indicator_level,\n           color = indicator_level)) +\n  geom_violin() +\n  geom_boxplot(width = 0.3, alpha = 0.5) +\n  scale_color_manual(values = color_palette, \n                    labels = c(\"Individuals with basic skills\" = \"Basic Skills\",\n                              \"Individuals with above basic skills\" = \"Above Basic Skills\", \n                              \"Individuals with basic or above basic skills\" = \"Basic or Above Skills\")) +\n  scale_x_continuous(position = \"top\", labels = scales::percent_format(scale = 1)) +\n  facet_grid(digital_skills ~ year, labeller = label_wrap_gen(10), switch = \"y\") +\n  theme_minimal() +\n  labs(\n    title = \"Distribution of Digital Skills by Proficiency Level\",\n    subtitle = \"% of individuals | age 16-74 | EU countries\",\n  ) +\n  theme_ts() +\n  theme(\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 10, color = \"#525252\"),\n    axis.line.x = element_line(color = \"grey90\"),\n    axis.ticks.x = element_line(color = \"#525252\"),\n    strip.text.y.left = element_text(size = 10, color = \"#525252\",\n                              angle = 0, hjust = 0), \n    strip.text.x = element_text(size = 12, color = \"#525252\"),\n    strip.placement = \"outside\",\n    strip.background = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 9, color = \"#525252\"),\n    legend.justification.top = 0,\n    panel.spacing = unit(1.5, \"lines\"),\n    plot.title = element_text(size = 20, color = \"#252525\"),\n    plot.subtitle = element_text(size = 16, color = \"#525252\")\n  )\n\n\n\n\n\n\n\n\n\n\nHistogram7\n\n\n\n\n\nBoxplot8"
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#trends-in-digital-skills-across-categories-years-and-skill-levels",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#trends-in-digital-skills-across-categories-years-and-skill-levels",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Trends in Digital Skills Across Categories, Years, and Skill Levels",
    "text": "Trends in Digital Skills Across Categories, Years, and Skill Levels\nBelow are some key observations based on the above analysis:\n\nGeneral Trends Over Time\n\nAcross all skill categories, there is a general improvement in skill levels from 2021 to 2023. For example, the percentage of individuals with above basic Communication and Collaboration skills increased from 79.96% in 2021 to 82.84% in 2023. Similarly, individuals with above basic Problem-solving skills saw an increase from 55.53% in 2021 to 58.05% in 2023. These improvements suggest that the EU is making positive steps toward achieving its 2030 digital skills goals. However, the progress also highlights the need for sustained efforts to ensure that all areas of digital competency are advancing at a similar pace.\n\nStrengths and Opportunities in Digital Skills Development\n\nThe data shows a notable concentration of individuals with above basic skills, especially in categories like Communication and Collaboration and Information and Data Literacy. For example, in 2023, while only 6.64% of individuals had basic communication and collaboration skills, 82.84% had above-basic skills. This indicates a strong proficiency at higher levels in these areas, reflecting significant progress. However, this pattern is not consistent across all skill categories. In areas such as Safety, Problem-solving and Digital Content Creation, the proportion of individuals with above basic skills is much lower, highlighting the need for targeted efforts to boost advanced competencies in these critical domains.\n\nOverall Digital Skills\n\nWhen examining Overall Digital Skills, the percentage of individuals with above basic skills is considerably lower compared to specific skills. In 2023, only 28.98% of individuals had above basic overall digital skills. This suggests that while people may excel in specific areas, comprehensive digital proficiency across all indicators remains a challenge.\n\nSafety and Digital Content Creation Skills\n\nThe data indicates that Safety and Digital Content Creation skills are generally weaker compared to other areas. In 2021, only 43.65% of individuals had above basic safety skills, and 46.56% had above basic digital content creation skills. In contrast, higher percentages were observed in areas like Information and Data Literacy (74.42%) and Communication and Collaboration (79.96%). This trend continues in 2023, suggesting a need for targeted initiatives to improve safety and content creation skills.Targeted initiatives, such as specialized training programs or awareness campaigns, could help improve competencies in these critical domains.\n\nRange of Skills Levels\n\nThere is considerable variation across regions or countries, as implied by the minimum and maximum values. For instance, in 2023, the range for above basic Problem-solving skills spans from 21.93% to 87.4%, indicating a significant gap between the most and least proficient groups. Although country-specific details I will explore in a separate analysis, the overall variation highlights the need for tailored interventions that address the unique challenges faced by different regions within the EU.\n\nStability of Median Values\n\nThe median values across years are generally stable, indicating that improvements in mean values are not driven by outliers. This stability suggests consistent progress across the population rather than isolated improvements among a few groups. However, there are some exceptions, such as in Problem-solving skills and Overall Digital skills, basic or above skills, where extreme values are more prominent.\n\nVariability of skills\n\nThere is low variability in basic skills. For example, the standard deviations for basic skills, such as Information and Data Literacy and Communication and Collaboration skills, are low, indicating consistent skill levels among individuals. In contrast, there is higher variability in above basic skills. The standard deviations for above basic skills, particularly in Digital Content Creation and Information and Data Literacy, are significantly higher, reflecting greater differences in proficiency levels among individuals.\nAmong the six categories, Problem Solving Skills and Safety Skills exhibit the highest variability, suggesting a wide range of abilities within these areas."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#conclusion",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#conclusion",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Conclusion",
    "text": "Conclusion\nThe data analysis reveals both progress and challenges in the development of digital skills across the EU. While improvements from 2021 to 2023 are encouraging, disparities in skill levels and the slower progress in certain areas, such as Safety and Digital Content Creation, indicate that more targeted policies and initiatives are necessary.\nOverall, while there is positive momentum, the findings suggest that achieving comprehensive digital proficiency across the EU will require continued and targeted efforts. Addressing regional disparities and focusing on advancing individuals from basic to above basic skills will be crucial for meeting the EU’s 2030 digital literacy goals."
  },
  {
    "objectID": "posts/digital_skills_indicator_eda(I)/index.html#footnotes",
    "href": "posts/digital_skills_indicator_eda(I)/index.html#footnotes",
    "title": "Analyzing the Digital Skills Indicator in the Context of the EU Digital Decade",
    "section": "Footnotes",
    "text": "Footnotes\n\nSource: Digital Economy and Society. Information on data↩︎\nLahti L., Huovari J., Kainu M., and Biecek P. (2017). Retrieval and analysis of Eurostat open data with the eurostat package. The R Journal 9(1), pp. 385-392. doi: 10.32614/RJ-2017-019 Lahti, L., Huovari J., Kainu M., Biecek P., Hernangomez D., Antal D., and Kantanen P. (2023). eurostat: Tools for Eurostat Open Data [Computer software]. R package version 4.0.0. https://github.com/rOpenGov/eurostat↩︎\nWickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 https://doi.org/10.21105/joss.01686.↩︎\nFirke S (2023). janitor: Simple Tools for Examining and Cleaning Dirty Data. R package version 2.2.0, https://CRAN.R-project.org/package=janitor.↩︎\nLin G (2023). reactable: Interactive Data Tables for R. R package version 0.4.4, https://CRAN.R-project.org/package=reactable.↩︎\nPedersen T (2024). patchwork: The Composer of Plots. https://patchwork.data-imaginist.com, https://github.com/thomasp85/patchwork.↩︎\nHistogram ↩︎\nBoxplot ↩︎"
  }
]