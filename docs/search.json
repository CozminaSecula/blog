[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nKey Driver Analysis to understand customer loyalty in a financial organization (case study)\n\n\n\nkey driver analysis\n\n\ndata cleaning\n\n\ndata visualization\n\n\n\nAnalyzing a customer satisfaction survey to determine the most important factors influencing customer loyalty.\n\n\n\nJan 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a Dashboard with Quarto\n\n\n\ndashboard\n\n\ndata visualization\n\n\n\nCreating a customized dashboard with Quarto to visualize and present data.\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test\n\n\n\nsummary statistics\n\n\nindependent samples t-test\n\n\nquantitative analysis\n\n\n\nDiscover how to extract valuable insights from data using summary statistics and the independent samples t-test, with a case study on team diversity within a large…\n\n\n\nOct 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test\n\n\n\ncross-table\n\n\nchi-squared test\n\n\nquantitative analysis\n\n\n\nDiscover how to extract valuable insights from categorical data using cross-tables and the chi-squared test, with a case study on gender representation in senior roles.\n\n\n\nSep 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmployees’ perception of well-being at work: A qualitative study\n\n\n\nqualitative analysis\n\n\nempirical study\n\n\nwell-being at work\n\n\n\nAn empirical study that explores how employees perceive the work environment factors and managers’ behaviors influencing their well-being at work.\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/employee-well-being-at-work/index.html#presentation",
    "href": "posts/employee-well-being-at-work/index.html#presentation",
    "title": "Employees’ perception of well-being at work: A qualitative study",
    "section": "Presentation",
    "text": "Presentation\nUnable to display PDF file. Download instead."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html",
    "href": "posts/2023-12-05-create-a-dashboard/index.html",
    "title": "Creating a Dashboard with Quarto",
    "section": "",
    "text": "Over the last few weeks, I have spent some time doing data analysis and visualization. The chosen tools for analysis, documenting, presenting, and sharing my work are R and Quarto. To acquire specific skills and knowledge, I adopted a project-based approach and designed small projects around my learning objectives. However, I encountered a challenge: how can I effectively display different visual data in one place, such as a dashboard? I needed a tool to simplify data presentation while allowing for tailored content. That’s when I discovered Quarto Dashboards, a recent addition to Quarto. This feature allowed me to create a custom dashboard using R, complete with personalized colors and styles. In the following sections, I will share how I created the dashboard.\nYou can find the finished dashboard here:\nThe code for the dashboard can be accessed on GitHub."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#customization",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#customization",
    "title": "Creating a Dashboard with Quarto",
    "section": "Customization",
    "text": "Customization\nThe dashboard allows selecting from 25 themes or creating personalized themes using Sass. For this dashboard I opted for the litera theme and customized the background color of the navbar, text, and navigation."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#designing-navigation-bar",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#designing-navigation-bar",
    "title": "Creating a Dashboard with Quarto",
    "section": "Designing Navigation Bar",
    "text": "Designing Navigation Bar\nYou can choose a title and optionally add a logo or author. You can also decide between a single-page dashboard or multiple pages. I chose to use five pages in this dashboard."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#designing-the-dashboard-layout",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#designing-the-dashboard-layout",
    "title": "Creating a Dashboard with Quarto",
    "section": "Designing the Dashboard Layout",
    "text": "Designing the Dashboard Layout\nYou can arrange dashboard components using rows and columns and use tabsets to include multiple views of data. Here are more details and layout options. I organized the dashboard with columns and tabsets for clear visualizations. Each column had tabs displaying different visualizations. Below is an example: on the left, the average compensation by department and experience level is displayed, while on the right, a visualization summarizes the spread of data within each category."
  },
  {
    "objectID": "posts/2023-12-05-create-a-dashboard/index.html#finalizing-and-sharing-the-dashboard",
    "href": "posts/2023-12-05-create-a-dashboard/index.html#finalizing-and-sharing-the-dashboard",
    "title": "Creating a Dashboard with Quarto",
    "section": "Finalizing and Sharing the Dashboard",
    "text": "Finalizing and Sharing the Dashboard\nOnce your dashboard is done, you may want to share it with others. I hosted the dashboard using GitHub Pages. In the GitHub repository for your dashboard, go to ‘Settings’ and then ‘Pages.’ Select the branch and folder of your dashboard’s index.html file, click ‘Save,’ and you’ll get a URL to display your work. Here’s the final link for this dashboard: https://cozminasecula.github.io/dashboard/."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#case-study",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#case-study",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Case study",
    "text": "Case study\n\nFocused on diversity and inclusion (D&I)\nSourced from the book Predictive HR Analytics : Mastering the HR Metric\nWith data available here"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#problem-statement",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#problem-statement",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Problem Statement",
    "text": "Problem Statement\nA hypothetical company aims to employ data analytics to address a significant people problem: gender diversity.\nFrom a commercial perspective, the organization seeks to foster a greater diversity of thought in senior and strategic discussions. On the other hand, from a people perspective, the organization wants to assess whether it maintains gender balance by providing positive role models for younger employees."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analysis-question",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analysis-question",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Analysis question",
    "text": "Analysis question\nAre women underrepresented in senior leadership roles within the organization?"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#data-preparation-and-exploration",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#data-preparation-and-exploration",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Data Preparation and exploration",
    "text": "Data Preparation and exploration\n\nData set\nFor this case study I used a data set available here.\n\nDescriptionData summary\n\n\n\nA hypothetical organization, a management consulting firm, has 1.493 employees.\nThe data set contains 11 variables.\nData type (in the data set): numeric for all variables.\n\n\n\n\ndiversity1 &lt;- read_csv(\"./diversity1.csv\")\n\nskimr::skim(diversity1)\n\n\nData summary\n\n\nName\ndiversity1\n\n\nNumber of rows\n1493\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBossGender\n0\n1.00\n1.69\n0.46\n1\n1\n2\n2\n2\n▃▁▁▁▇\n\n\nGender\n2\n1.00\n1.50\n0.50\n1\n1\n1\n2\n2\n▇▁▁▁▇\n\n\nJobGrade\n0\n1.00\n4.02\n1.73\n1\n2\n4\n5\n8\n▆▅▇▃▂\n\n\nAge\n0\n1.00\n38.27\n9.57\n16\n31\n38\n46\n66\n▂▇▇▅▁\n\n\nTenure\n0\n1.00\n10.00\n9.88\n0\n2\n7\n14\n42\n▇▃▁▁▁\n\n\nStatus\n0\n1.00\n1.24\n0.76\n1\n1\n1\n1\n5\n▇▁▁▁▁\n\n\nPerformanceScore\n203\n0.86\n4.13\n0.34\n4\n4\n4\n4\n5\n▇▁▁▁▁\n\n\nBossPerformance\n44\n0.97\n3.74\n0.65\n2\n3\n4\n4\n5\n▁▅▁▇▂\n\n\nDivision\n0\n1.00\n8.27\n3.91\n1\n5\n10\n11\n12\n▂▁▁▁▇\n\n\nCountry\n0\n1.00\n8.21\n1.76\n1\n8\n9\n9\n10\n▁▁▁▂▇\n\n\nleaver\n2\n1.00\n1.07\n0.26\n1\n1\n1\n1\n2\n▇▁▁▁▁\n\n\n\n\n\n\n\n\n\n\nVariables of interest\nTo answer the question, the variables of interest are JobGrade and Gender.\nThe organization has eight distinct job grades, which are detailed below.\nOf the 1.493 employees, 746 are female and 745 are male.\n\n\n\n\n\nLevel\nJob Grade\n\n\n\n\n1\nClerical/Officer\n\n\n2\nAdministrator/Assistant\n\n\n3\nGraduate/Trainee Consultant\n\n\n4\nConsultant\n\n\n5\nSenior Consultant\n\n\n6\nManaging Consultant\n\n\n7\nPrincipal Consultant\n\n\n8\nPartner\n\n\n\n\n\n\n\nLevel\nGender\n\n\n\n\n1\nFemale\n\n\n2\nMale\n\n\n\n\n\n\n\nData preparation\n\nChange variables of interest as categorical\nIn the original data set, all variables are numeric. However, our variables of interest are not numeric; they are categorical. As a result, for the analysis, I will treat these variables as categorical. So, first, I will change the variables to categorical.\n\n\nCode\n# create new variables \"gender\" and \"jobgrade\"\ndiversity1 &lt;- diversity1 |&gt;\n  mutate(gender= factor(Gender,\n                        levels= c(1:2),\n                        labels= c(\"Female\", \"Male\")),\n         jobgrade= factor(JobGrade,\n                          levels= c(1:8),\n                          labels= c(\"Clerical/Officer\", \"Administrator/Assistant\", \"Graduate/Trainee Consultant\", \"Consultant\", \"Senior Consultant\", \"Managing Consultant\", \"Principal Consultant\", \"Partner\")))\n\n\n\n\n\nCreate Cross-Table with the data for the two variables\n\n\nCode\ndiversity1 |&gt;\n  filter(gender != \"NA\") |&gt;\n  tabyl(jobgrade, gender) |&gt;\n  gt()|&gt;\n  cols_label(jobgrade = \"Job Grade\") |&gt;\n  tab_header(title = \"Cross-table of gender and job grade \",\n             subtitle = \"Count\")\n\n\n\n\n\n\n\n\nCross-table of gender and job grade\n\n\nCount\n\n\nJob Grade\nFemale\nMale\n\n\n\n\nClerical/Officer\n31\n8\n\n\nAdministrator/Assistant\n227\n116\n\n\nGraduate/Trainee Consultant\n160\n103\n\n\nConsultant\n139\n104\n\n\nSenior Consultant\n98\n152\n\n\nManaging Consultant\n68\n171\n\n\nPrincipal Consultant\n19\n62\n\n\nPartner\n4\n29\n\n\n\n\n\n\n\nWe can see a pattern more clearly by expressing the data as percentages. I will convert the values to a percentage of the total numbers of each job grade.\n\n\nCode\ndiversity1 |&gt;\n  filter(gender != \"NA\") |&gt;\n  tabyl(jobgrade, gender) |&gt;\n  adorn_percentages() |&gt;\n  mutate(across(where(is.numeric), ~ round(.x, 2)*100)) |&gt;\n  gt()|&gt;\n  cols_label(jobgrade = \"Job Grade\") |&gt;\n  tab_header(title = \"Cross-table of gender and job grade \",\n             subtitle = \"Percent %\")\n\n\n\n\n\n\n\n\nCross-table of gender and job grade\n\n\nPercent %\n\n\nJob Grade\nFemale\nMale\n\n\n\n\nClerical/Officer\n79\n21\n\n\nAdministrator/Assistant\n66\n34\n\n\nGraduate/Trainee Consultant\n61\n39\n\n\nConsultant\n57\n43\n\n\nSenior Consultant\n39\n61\n\n\nManaging Consultant\n28\n72\n\n\nPrincipal Consultant\n23\n77\n\n\nPartner\n12\n88"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#are-women-underrepresented-in-senior-leadership-roles-within-the-organization",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#are-women-underrepresented-in-senior-leadership-roles-within-the-organization",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Are women underrepresented in senior leadership roles within the organization?",
    "text": "Are women underrepresented in senior leadership roles within the organization?\nUp to this point, the data reveal a clear pattern: males are more common in senior roles, while females tend to occupy junior positions.\n\n\nCode\n# Custom label function\n\npercent_label &lt;- function(x) {\n  paste0(100*x, \"%\")\n}\n\ndiversity1 |&gt;\nfilter(gender != \"NA\") |&gt;\nggplot(aes(x=jobgrade, fill= gender))+\n  geom_bar(position = \"fill\", width = 0.6)+\n  labs(title = \"Gender by Job Grade\",\n      x = \"Job Grade\",\n      y = \"Proportions\",\n      fill= \"Gender\")+\n  theme_minimal(base_size = 14)+\n  theme(plot.background = element_blank(),\n        panel.grid = element_blank())+\n  scale_fill_manual(values = c(\"Female\" = \"#414040\", \"Male\"= \"#BFBEBE\"))+\n  scale_y_continuous(labels = percent_label, breaks = seq(0, 1, 0.25))+\n  coord_flip()"
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#does-this-organization-have-a-gender-diversity-issue",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#does-this-organization-have-a-gender-diversity-issue",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Does this organization have a gender diversity issue?",
    "text": "Does this organization have a gender diversity issue?\n\nThe data indicate a pattern where women are more commonly in junior roles and men in senior roles.\nHowever, it’s unclear from the data whether this pattern is by chance or statistically significant.\nTo assess this, we can employ a chi-squared test to determine the statistical significance of the observed pattern."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#the-hypotheses",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#the-hypotheses",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "The hypotheses",
    "text": "The hypotheses\nH0: There is no association between gender and job grade within the organization.\n\nthe observed distribution of females and males across job grades is due to random chance.\n\nH1: There is a significant association between gender and job grade within the organization.\n\nthe observed distribution of females and males across job grades is not a result of random chance; it reflects a significant pattern of male predominance in senior roles and a greater representation of females in entry-level positions."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#chi-squared-test-in-r",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#chi-squared-test-in-r",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Chi squared test in R",
    "text": "Chi squared test in R\n\ncross_tab &lt;- table(diversity1$jobgrade, diversity1$gender)\nchisq.test(cross_tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  cross_tab\nX-squared = 164.7, df = 7, p-value &lt; 2.2e-16\n\n\n\nThe p-value is extremely small, less than 2.2e-16, which is very close to zero.\nSince the p-value is less than the significance level of 0.05, we can confidently reject the null hypothesis, concluding that the two variables are dependent.\nThis result indicates a statistically significant association between gender and job grade.\nIt suggests that certain factors are influencing the observed distribution of genders within job grades."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analyzing-gender-distribution-across-job-grades",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#analyzing-gender-distribution-across-job-grades",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Analyzing gender distribution across job grades",
    "text": "Analyzing gender distribution across job grades\n\nCross-tables and graphical visualization offer a concise summary of gender distribution across job grades, revealing a clear pattern: men are more common in senior roles, while women predominantly hold junior positions.\nThe results of the chi-squared test, with a p-value close to zero, confirm a very strong association between gender and job grade."
  },
  {
    "objectID": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#recommendation",
    "href": "posts/2023-09-14-cross-tables-and-chi-squared-test/index.html#recommendation",
    "title": "Unlocking Insights (I): Analyzing Categorical Data with Cross-Table and Chi-Squared Test",
    "section": "Recommendation",
    "text": "Recommendation\n\nWhile this statistical evidence does not directly imply a gender diversity issue within the organization, it signals that factors beyond chance influence the gender distribution across job grades.\nTo address potential gender bias or discrimination and foster diversity and inclusion within the organization, further analysis and actions are necessary."
  },
  {
    "objectID": "notes/quarto-tools.html",
    "href": "notes/quarto-tools.html",
    "title": "Quarto Tools",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\nQuarto Tools\nQuarto is an open-source scientific and technical publishing system with support for multiple languages and environments. It offers a wide range of functionalities, making it versatile for various tasks. There are many resources on the web to learn about Quarto. Here, I have collected some of them that I find particularly helpful for my Quarto code, blog, presentations, and workflow.\nIf you want to start your journey with Quarto, I recommend the Quarto documentation, which is the best place to learn everything you might want to know about Quarto."
  },
  {
    "objectID": "notes/analytics-project.html",
    "href": "notes/analytics-project.html",
    "title": "Insight-Oriented Data Projects Resources",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\nInsight-Oriented Data Projects Resources\nAn insight-oriented data project starts with a clear purpose: to discover, understand, explain, or solve business problems. Significant effort is focused on defining the problem, formulating the question you want to answer, and designing an analysis workflow to provide insights for resolving the question. Data are collected, analyzed, and interpreted systematically to address specific problems and assist with making informed decisions."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nTools\n\n\nDescription\n\n\n\n\n\n\nSales Revenue and Orders\n\n\nSQL, R, RStudio, Quarto, Git/Github\n\n\nAnalyzing annual and monthly sales revenue and orders using data from the Northwind database. \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Cozmina Secula",
    "section": "",
    "text": "Translate Widget\n    \n    \n    \nWith an extensive background in B2B sales and team management, I’m expanding my skill set into new areas like data analytics, R language programming, Quarto, and data visualization.\nThroughout this blog, I showcase my work in people analytics, a domain I am interested in."
  },
  {
    "objectID": "data_analysis/1_sales_revenue_and_orders.html#questions-and-solutions",
    "href": "data_analysis/1_sales_revenue_and_orders.html#questions-and-solutions",
    "title": "Sales Revenue and Orders",
    "section": "Questions and Solutions",
    "text": "Questions and Solutions\n\nWhat is the annual variation in sales revenue and number of orders?\nWhat is the monthly variation in sales revenue?\nHow do monthly revenue and orders compare to the yearly average?"
  },
  {
    "objectID": "data_analysis/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "href": "data_analysis/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "title": "Sales Revenue and Orders",
    "section": "Steps to answer the questions",
    "text": "Steps to answer the questions\n\nIdentify the tables that contain the sales revenue and order data\nUnderstand the schema, columns that store date, sales, and orders\nUse SQL and R to retrieve, prepare and summarize data\nData Visualization\nData Interpretation\n\n\nTools used to achieve this\n\nPrerequisites\n\nlibrary(DBI) \nlibrary(dbplyr)\nlibrary(tidyverse) \nlibrary(knitr)\nlibrary(DT)\nlibrary(patchwork)\nlibrary(glue)\ntheme_set(theme_minimal(base_size = 12))\n\n\n\nConnect to the database\n\ncon &lt;- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = 'northwind', \n                 host = 'localhost', \n                 port = 5432, \n                 user = 'postgres',\n                 password = 'postgres')\n \ndbListTables(conn = con) ## list tables in the database\n\n [1] \"us_states\"              \"customers\"              \"orders\"                \n [4] \"employees\"              \"shippers\"               \"products\"              \n [7] \"order_details\"          \"categories\"             \"suppliers\"             \n[10] \"region\"                 \"territories\"            \"employee_territories\"  \n[13] \"customer_demographics\"  \"customer_customer_demo\" \"sales_revenue\"         \n\n\n\n\nHow the data is stored in the database?\nThe data used to answer the questions can be found in two tables: orders and order_details.\nEntity Relationship Diagram. Source DBeaver"
  },
  {
    "objectID": "data_analysis/1_sales_revenue_and_orders.html#what-is-the-annual-variation-in-sales-revenue-and-number-of-orders",
    "href": "data_analysis/1_sales_revenue_and_orders.html#what-is-the-annual-variation-in-sales-revenue-and-number-of-orders",
    "title": "Sales Revenue and Orders",
    "section": "What is the annual variation in sales revenue and number of orders?",
    "text": "What is the annual variation in sales revenue and number of orders?\n\nSQL Query\n\nsales_revenue &lt;- \"\n\nselect \n    min(o.order_date) as start_date,\n    max(o.order_date) as end_date,\n    extract(year from o.order_date) as year,\n    count(*) as order_number,\n    round(cast(sum(od.unit_price* od.quantity) as numeric),\n    2) as total_revenue,\n    round(cast(avg(od.unit_price* od.quantity)as numeric),\n    2) as avg_revenue\nfrom public.order_details od\ninner join public.orders as o on od.order_id = o.order_id\ngroup by year\norder by year;\n\"\nsales_revenue_tbl &lt;- (dbGetQuery(con, sales_revenue))\n\n\nkable(sales_revenue_tbl)\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nend_date\nyear\norder_number\ntotal_revenue\navg_revenue\n\n\n\n\n1996-07-04\n1996-12-31\n1996\n405\n226298.5\n558.76\n\n\n1997-01-01\n1997-12-31\n1997\n1059\n658388.8\n621.71\n\n\n1998-01-01\n1998-05-06\n1998\n691\n469771.3\n679.84\n\n\n\nAnnual summary of sales, number of orders and average sale\n\n\n\n\nCode\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\n\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\norder_number &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = as.numeric(order_number)))+\n  geom_col()+\n  geom_text(aes(label = as.numeric(order_number)), vjust = 1.5, color = \"white\")+\n  labs(\n    title = \"Number of Orders per Year\",\n    x = NULL,\n    y = \"Total Number of Orders\"\n  )+\n   theme_minimal()\n\navg_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = avg_revenue))+\n  geom_col()+\n  geom_text(aes(label = avg_revenue), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Average Dollars per Sale\",\n    x = \"Years between July 04, 1996 to May 06, 1998\",\n    y = \"Average Sale Amount\"\n  )+\n   theme_minimal()\n\n(total_revenue  + plot_spacer() + order_number + plot_layout(widths = c(4, -1, 4))) / avg_revenue\n\n\n\n\n\nNorthwind annual sales performance\n\n\n\n\n\n\nInsights\n\nAs 1996 and 1998 are shorter than 1997, interpreting comparisons is difficult.\nThe sales revenue and the number of orders for the first five months of 1998 are greater than those for the last five months for the year of 1996. Since the comparison is not for the same period or consecutive years, it is difficult to determine if the sales are trending upward, downward, or flat. However even though the context is different, we can say that we have an evolution with sales revenue doubling in five months in 1998 compared with five months in 1996.\nFor each year, the average dollar amount of sales increases from year to year based on the average dollar amount of sales.\n\nHow about the monthly sales?"
  },
  {
    "objectID": "data_analysis/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "href": "data_analysis/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "title": "Sales Revenue and Orders",
    "section": "What is the monthly variation in sales revenue?",
    "text": "What is the monthly variation in sales revenue?\nTo have the monthly sales revenue and number of orders, the previous query is modified as follows:\n\nSQL Query\n\nmonthly_revenue &lt;- \"\nselect \n    cast(date_trunc('month', o.order_date) as date) as sales_month,\n    count(*) as total_number,\n    round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\nfrom public.orders o \ninner join public.order_details od on o.order_id = od.order_id \ngroup by sales_month\norder by sales_month;\n\"\nmonthly_revenue_tbl &lt;- (dbGetQuery(con, monthly_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\n\n\nCode\nmin_order_date &lt;- min(sales_revenue_tbl$start_date)\nmax_order_date &lt;- max(sales_revenue_tbl$end_date)\n\n(monthly_revenue_plot &lt;- ggplot(monthly_revenue_tbl, aes(x = sales_month, y = monthly_revenue))+\n  geom_col()+\n  scale_y_continuous(labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Sales by Month \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Sales Dollars\"\n  )+\n  theme_minimal())\n\n\n\n\n\nNorthwind monthly sales performance\n\n\n\n\nThe graph shows that the sales generally increase over time. However, there is much variation from one month to another. As there is month-over-month sales variation we can use the lag() function (SQL) to help to find the delta.\n\n\nSQL Query\n\nmonthly_var_revenue &lt;- \"\nwith monthly_revenue as\n    (select \n        cast(date_trunc('month', o.order_date) as date) as sales_month,\n        count(*) as total_number,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    group by sales_month\n    order by sales_month),\n    prev_month_revenue as\n    (select \n        mr.sales_month,\n        mr.total_number,\n        mr.monthly_revenue,\n        lag(mr.monthly_revenue, 1, mr.monthly_revenue) over (order by mr.sales_month) as prev_month_revenue\n    from monthly_revenue mr)\nselect\n    pmr.sales_month,\n    pmr.total_number,\n    pmr.monthly_revenue,\n    prev_month_revenue,\n    pmr.monthly_revenue - pmr.prev_month_revenue as delta_revenue\nfrom prev_month_revenue pmr;\n\"\nmonthly_var_revenue_tbl &lt;- (dbGetQuery(con, monthly_var_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\nAs the graph above shows that data has a left-tailed distribution, we can use the summary() function (R) to return descriptive statistics.\n\nmedian(monthly_var_revenue_tbl$delta_revenue)\n\n[1] 3707\n\n(summary_delta_revenue &lt;- summary(monthly_var_revenue_tbl$delta_revenue))\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-114732.0   -2405.0    3707.0    -447.5   14643.5   31563.0 \n\n\nWe can see that the median is positive ($3.707) while the mean is negative: (447.5). Month-over-month sales data shows a wide spread between the lower and upper quartiles.\n\n\nCode\n(monthly_var_revenue_plot &lt;- ggplot(monthly_var_revenue_tbl, aes(x = sales_month, y = delta_revenue))+\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\", date_minor_breaks = \"3 months\") +\n  geom_line()+\n  scale_y_continuous(limits = c(-200000, 150000), labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Monthly Sales Variation \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Dollars Change\"\n  )+\n  theme_minimal()\n  )\n\n\n\n\n\nNorthwind monthly sales variation\n\n\n\n\n\n\nInsights\n\nWith real data, we would want to investigate more to understand the business context that occurred in May of 1998. With these data, we know that the data collection ended at the beginning of May 1998 which can explain the gap compared with the previous month.\n\nWe have the data for the entire year of 1997 and we can look at revenue and number of orders together and compare the monthly data to the yearly average. By comparing monthly sales to yearly average, businesses can identify which months consistently perform above or below average, helping in informing various business decisions."
  },
  {
    "objectID": "data_analysis/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "href": "data_analysis/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "title": "Sales Revenue and Orders",
    "section": "How do monthly revenue and orders compare to the yearly average?",
    "text": "How do monthly revenue and orders compare to the yearly average?\n\nSQL Query\n\nmonth_data_year_avg &lt;- \"\nwith montly_data as\n    (select \n        cast(date_trunc('month', o.order_date) as date) year_month,\n        count(*) as monthly_orders,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    where extract(year from o.order_date) = 1997 \n    group by year_month\n    order by year_month)\nselect\n    md.year_month,\n    md.monthly_orders, \n    md.monthly_revenue\nfrom montly_data md\norder by md.year_month;\n\"\nmonth_data_year_avg_tbl &lt;- (dbGetQuery(con,month_data_year_avg))\n\n\n\n\n\nMonthly sales data and Yearly averages\n\n\n\n\nCode\nyearly_rev_avg &lt;- mean(month_data_year_avg_tbl$monthly_revenue)\nmonth_data_year_avg_rev_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = monthly_revenue))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  geom_hline(yintercept = yearly_rev_avg ,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_rev_avg +1000,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Revenue Average \\n\",\n                  \"Monthly Revenue \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Revenue Dollars\"\n  )+\n  theme_minimal()\n\n\nyearly_order_avg &lt;- mean(month_data_year_avg_tbl$monthly_orders)\nmonth_data_year_avg_order_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = as.numeric(monthly_orders)))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  geom_hline(yintercept = yearly_order_avg ,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_order_avg +1,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Order Average \\n\",\n                  \"Monthly Orders \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Number of Orders\"\n  )+\n  theme_minimal()\n\n\nmonth_data_year_avg_rev_plot + plot_spacer() + month_data_year_avg_order_plot+ plot_layout(widths = c(4, -1, 4))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\nBoth the monthly sales revenue and number of orders vary widely compared with the yearly average.\nThe highest values for sales revenue are at the beginning and the end of the year while the lowest values are in the first half of the year. This indicates that the business can have seasonal fluctuations in sales.\nThis is also supported by the number of orders placed each month. The highest number of orders is in the second half of the year which can explain the increased revenue at the final of the year.\n\nKnowing in which months the business performs below or above the average can help in the strategic planning of the company and the allocation of resources. - For example : - when the sales volumes are low the business can design loyalty programs that encourage repeated business during slower months; - during off-peak times the company can plan training programs to ensure that the staff are fully equipped for busy periods; - targeted campaigns by allocating budgets to peak seasons to maximize returns or promotions during low-performing months to increase sales.\nComparing monthly sales data to yearly averages is a powerful analytical tool that provides deep insights into business performance, aids in strategic planning and drives informed decision-making. It allows businesses to adapt proactively to changes, optimize operations, and achieve better financial outcomes.\n\n# Close the database connection\ndbDisconnect(con)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Translate Widget\n    \n    \n    \nI am passionate about making sense of data and working on problems in the data space. I have experience analyzing data using SQL and R and creating data visualizations in R using ggplot.\nPreviously, I have worked +17 years in business-to-business sales having various roles."
  },
  {
    "objectID": "notes/notes.html#why-this-space",
    "href": "notes/notes.html#why-this-space",
    "title": "Learning resources",
    "section": "Why this space?",
    "text": "Why this space?\nWorking on data-based projects while developing my R and Quarto skills, I gathered resources to help myself. Learning from others inspired me to share these resources with anyone interested. This space is meant to be helpful for those looking to learn about the R programming language, Quarto, and related topics."
  },
  {
    "objectID": "notes/notes.html#what-is-in-this-space",
    "href": "notes/notes.html#what-is-in-this-space",
    "title": "Learning resources",
    "section": "What is in this space?",
    "text": "What is in this space?\n\n\nR Resources\n\nThis section includes links\nto resources to learn\nhow to perform data extraction,\nwrangling, cleaning, analysis,\nand visualization with R.\n\n\nQuarto Tools\n\nThis section includes links\nto tools, examples, and articles\nrelated to Quarto\navailable on the internet.\n\n\n\nPlease note that this is a work in progress, and I am constantly adding resources."
  },
  {
    "objectID": "notes/R-resources.html",
    "href": "notes/R-resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Translate Widget\n\n\n    \n    \n    \n\n\n\n\n\n\n\n\n\n\nR Resources\nR is an open-source statistical and data visualization software. It supports end-to-end analytics workflows, including data extraction, wrangling, cleaning, analysis, and visualization. All resources in this section are related to R/R Studio."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#case-study",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#case-study",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Case study",
    "text": "Case study\n\nFocused on diversity and inclusion (D&I)\nSourced from the book Predictive HR Analytics : Mastering the HR Metric\nWith data available here"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#problem-statement",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#problem-statement",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Problem Statement",
    "text": "Problem Statement\nA hypothetical company aims to employ data analytics to tackle a significant people problem: employee diversity. It recognizes that:\n\nCommercial Perspective : a more diverse workforce can provide a competitive advantage by enhancing the organization’s understanding of its customers, consequently improving overall performance.\nPeople Perspective : the organization gains access to a broader candidate pool, increases employee engagement, and elevates retention rates."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analysis-question",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analysis-question",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Analysis question",
    "text": "Analysis question\nHow does the distribution of Black, Asian, or Minority Ethnic (BAME) employees vary across different professions?"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#load-packages",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#load-packages",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Load packages",
    "text": "Load packages\n\n library(tidyverse)\n library(car)\n library(paletteer)\n library(kableExtra)"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-set",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-set",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Data set",
    "text": "Data set\nFor this case study I used a data set available here.\n\nDescriptionData summary\n\n\n\nThe company, a hypothetical organization, comprises 29,976 employees in two functional areas across the UK, and these employees are organized into 928 teams.\nThe data set contains 30 variables.\nData type (in the data set): numeric for all variables.\n\n\n\n\ndiversity &lt;- read_csv(\"diversity2.csv\")\n\nskimr::skim(diversity)\n\n\n\nData summary\n\n\n\n\nName\n\n\ndiversity\n\n\n\n\nNumber of rows\n\n\n928\n\n\n\n\nNumber of columns\n\n\n30\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nnumeric\n\n\n30\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\nVariable type: numeric\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\n\nDepartmentGroupNumber\n\n\n0\n\n\n1.00\n\n\n470.62\n\n\n270.05\n\n\n1.00\n\n\n237.75\n\n\n470.50\n\n\n704.25\n\n\n937.00\n\n\n▇▇▇▇▇\n\n\n\n\nGroupSize\n\n\n1\n\n\n1.00\n\n\n32.30\n\n\n16.24\n\n\n10.00\n\n\n18.00\n\n\n28.00\n\n\n45.00\n\n\n71.00\n\n\n▇▆▃▃▂\n\n\n\n\nPercentMale\n\n\n1\n\n\n1.00\n\n\n58.95\n\n\n22.27\n\n\n1.00\n\n\n45.00\n\n\n65.00\n\n\n67.00\n\n\n100.00\n\n\n▁▃▅▇▃\n\n\n\n\nBAME\n\n\n182\n\n\n0.80\n\n\n0.12\n\n\n0.11\n\n\n0.00\n\n\n0.03\n\n\n0.09\n\n\n0.20\n\n\n0.45\n\n\n▇▃▂▂▁\n\n\n\n\nNumberTeamLeads\n\n\n1\n\n\n1.00\n\n\n4.61\n\n\n2.33\n\n\n1.00\n\n\n3.00\n\n\n4.00\n\n\n6.00\n\n\n10.00\n\n\n▅▇▅▃▂\n\n\n\n\nNumberFeMaleTeamLeads\n\n\n20\n\n\n0.98\n\n\n0.68\n\n\n1.06\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n1.00\n\n\n8.00\n\n\n▇▂▁▁▁\n\n\n\n\nLocation\n\n\n0\n\n\n1.00\n\n\n2.12\n\n\n0.85\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n3.00\n\n\n3.00\n\n\n▆▁▅▁▇\n\n\n\n\nLondonorNot\n\n\n0\n\n\n1.00\n\n\n1.43\n\n\n0.49\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n▇▁▁▁▆\n\n\n\n\nFunction\n\n\n1\n\n\n1.00\n\n\n1.46\n\n\n0.50\n\n\n1.00\n\n\n1.00\n\n\n1.00\n\n\n2.00\n\n\n2.00\n\n\n▇▁▁▁▇\n\n\n\n\nEMPsurvEngage_1\n\n\n1\n\n\n1.00\n\n\n88.14\n\n\n11.24\n\n\n22.00\n\n\n83.00\n\n\n91.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_2\n\n\n1\n\n\n1.00\n\n\n87.50\n\n\n10.88\n\n\n45.00\n\n\n82.00\n\n\n90.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▂▅▇\n\n\n\n\nEMPsurvEngage_3\n\n\n1\n\n\n1.00\n\n\n85.63\n\n\n13.43\n\n\n33.00\n\n\n80.00\n\n\n89.00\n\n\n95.00\n\n\n100.00\n\n\n▁▁▁▃▇\n\n\n\n\nEMPsurvEngage_4\n\n\n1\n\n\n1.00\n\n\n75.98\n\n\n13.77\n\n\n29.00\n\n\n68.00\n\n\n78.00\n\n\n86.00\n\n\n100.00\n\n\n▁▂▅▇▅\n\n\n\n\nEMPsurvEngage_5\n\n\n1\n\n\n1.00\n\n\n91.49\n\n\n8.80\n\n\n44.00\n\n\n88.00\n\n\n93.00\n\n\n98.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_6\n\n\n1\n\n\n1.00\n\n\n68.60\n\n\n15.96\n\n\n11.00\n\n\n58.00\n\n\n69.00\n\n\n80.00\n\n\n100.00\n\n\n▁▂▆▇▃\n\n\n\n\nEMPsurvEngage_7\n\n\n1\n\n\n1.00\n\n\n89.98\n\n\n9.82\n\n\n25.00\n\n\n86.00\n\n\n92.00\n\n\n97.00\n\n\n100.00\n\n\n▁▁▁▂▇\n\n\n\n\nEMPsurvEngage_8\n\n\n1\n\n\n1.00\n\n\n66.75\n\n\n15.31\n\n\n0.00\n\n\n57.00\n\n\n68.00\n\n\n78.00\n\n\n100.00\n\n\n▁▁▅▇▃\n\n\n\n\nEMPsurvEngage_9\n\n\n1\n\n\n1.00\n\n\n76.64\n\n\n15.54\n\n\n10.00\n\n\n68.00\n\n\n79.00\n\n\n88.00\n\n\n100.00\n\n\n▁▁▃▇▇\n\n\n\n\nEMPsurvEngagement\n\n\n1\n\n\n1.00\n\n\n81.18\n\n\n10.02\n\n\n39.00\n\n\n75.00\n\n\n83.00\n\n\n89.00\n\n\n99.00\n\n\n▁▁▃▇▆\n\n\n\n\nEMPorgIntegrity1\n\n\n1\n\n\n1.00\n\n\n69.99\n\n\n14.33\n\n\n18.00\n\n\n61.00\n\n\n71.00\n\n\n80.00\n\n\n100.00\n\n\n▁▂▅▇▃\n\n\n\n\nEMPorgIntegrity2\n\n\n1\n\n\n1.00\n\n\n85.74\n\n\n10.94\n\n\n35.00\n\n\n80.00\n\n\n88.00\n\n\n94.00\n\n\n100.00\n\n\n▁▁▂▆▇\n\n\n\n\nEMPorgIntegrity3\n\n\n1\n\n\n1.00\n\n\n88.73\n\n\n10.31\n\n\n35.00\n\n\n83.00\n\n\n91.00\n\n\n96.00\n\n\n100.00\n\n\n▁▁▁▃▇\n\n\n\n\nEMPorgIntegrity4\n\n\n1\n\n\n1.00\n\n\n84.91\n\n\n10.88\n\n\n27.00\n\n\n80.00\n\n\n86.00\n\n\n92.00\n\n\n100.00\n\n\n▁▁▁▆▇\n\n\n\n\nEMPorgIntegrity5\n\n\n1\n\n\n1.00\n\n\n470.11\n\n\n269.76\n\n\n1.00\n\n\n237.50\n\n\n470.00\n\n\n703.50\n\n\n936.00\n\n\n▇▇▇▇▇\n\n\n\n\nEmpSurvOrgIntegrity\n\n\n1\n\n\n1.00\n\n\n159.89\n\n\n54.53\n\n\n54.00\n\n\n113.10\n\n\n164.60\n\n\n207.60\n\n\n258.20\n\n\n▅▇▇▇▇\n\n\n\n\nEMPsurvSUP1\n\n\n1\n\n\n1.00\n\n\n82.96\n\n\n10.65\n\n\n33.00\n\n\n77.00\n\n\n84.00\n\n\n91.00\n\n\n100.00\n\n\n▁▁▂▇▇\n\n\n\n\nEMPsurvSUP2\n\n\n1\n\n\n1.00\n\n\n85.24\n\n\n10.99\n\n\n30.00\n\n\n79.00\n\n\n87.00\n\n\n93.00\n\n\n100.00\n\n\n▁▁▂▆▇\n\n\n\n\nEMPsurvSUP3\n\n\n1\n\n\n1.00\n\n\n79.89\n\n\n12.72\n\n\n34.00\n\n\n73.00\n\n\n81.00\n\n\n89.00\n\n\n100.00\n\n\n▁▂▃▇▆\n\n\n\n\nEMPsurvSUP4\n\n\n1\n\n\n1.00\n\n\n81.35\n\n\n12.13\n\n\n27.00\n\n\n73.00\n\n\n82.00\n\n\n91.00\n\n\n100.00\n\n\n▁▁▃▇▇\n\n\n\n\nEmpSurvSupervisor\n\n\n1\n\n\n1.00\n\n\n82.36\n\n\n10.07\n\n\n35.75\n\n\n76.50\n\n\n83.50\n\n\n89.75\n\n\n100.00\n\n\n▁▁▂▇▆"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#variables-of-interest",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#variables-of-interest",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Variables of interest",
    "text": "Variables of interest\n\nBAME: Percentage of the team comprised of Black, Asian, or Minority Ethnic employees.\nFunction: Function 1 = Sales staff (customer-facing roles) or 2 = Professional Service (non-customer-facing roles).\nThe data set contains both variables of interest as numbers.\nThe “BAME” variable is numeric, while the “Function” variable is categorical and needs to be transformed into a factor for analysis in R."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-preparation",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#data-preparation",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Data preparation",
    "text": "Data preparation\n\nChange the variable “Function” to categorical by creating a new variable named “profession” with two levels “Sales Staff” and “Professional Service”.\n\n\n\nCode\n# Create a new variable named \"profession\" with two levels \"Sales Staff\" and \"Professional Service\"\n# Drop \"NA\" levels as they are not meaningful for the analysis\n\ndiversity &lt;- diversity|&gt;\n  mutate(profession = factor(Function,\n                           levels = c(1:2),\n                           labels = c(\"Sales Staff\", \"Professional Service\")))|&gt;\n  filter(profession != \"NA\")|&gt;\n  droplevels()"
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-i",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-i",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "How does the distribution of BAME employees vary across different professions? (I)",
    "text": "How does the distribution of BAME employees vary across different professions? (I)\n\nBAME employees are distributed differently across the two professions. There are more “Sales Staff” teams with a lower percentage of BAME employees, while “Professional Service” teams have a more even distribution.\nIt’s essential to note that these findings are based on summary statistics and visual examinations, which may not be highly precise.\nTo gain more confidence in comparing BAME representation between the two professions and to deepen our understanding of the organization’s ethnicity dynamics, we will conduct an Independent Samples t-Test."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#levenes-test-for-equality-of-variances",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#levenes-test-for-equality-of-variances",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Levene’s Test for Equality of Variances",
    "text": "Levene’s Test for Equality of Variances\nOne of the requirements for the independent Samples t-test is the homogeneity of variances (i.e., variances approximately equal across groups).\nHowever, if this requirement is violated and the sample sizes for each group differ, we can calculate t-test statistics. The independent samples t-test output also includes an approximate t-statistic, which doesn’t assume equal variances across populations. The Welch t-test statistic can be employed when equal variances between populations cannot be assumed.\nThe hypotheses\n\nH0: The population variances of “Sales Staff” and “Professional Service” are equal.\nH1: The population variances of “Sales Staff” and “Professional Service” are not equal.\n\n\nleveneTest(diversity$BAME, group = diversity$profession, center=mean)\n\nLevene's Test for Homogeneity of Variance (center = mean)\n       Df F value    Pr(&gt;F)    \ngroup   1  35.396 4.141e-09 ***\n      744                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value is 4.141e-09, which is less than 0.05. This indicates very strong evidence against the null hypothesis, leading us to reject the null hypothesis of Levene’s Test.\nThis suggests that the variances of the two groups are not equal, meaning the assumption of homogeneity of variances is violated."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#independent-samples-t-test-1",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#independent-samples-t-test-1",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Independent Samples t-Test",
    "text": "Independent Samples t-Test\n\nWe want to determine if there is a statistically significant difference between the mean percentages of BAME employees in the “Sales Staff” and “Professional Service” professions within this organization.\nTo achieve this, we can employ an Independent Samples t-Test to compare the means of BAME percentages for “Sales Staff” and “Professional Service.”\n\nThe hypotheses\n\nH0: The difference of the means is equal to 0\nH1: The difference of the means is not equal to 0.\n\n\nt.test(diversity$BAME ~ diversity$profession, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  diversity$BAME by diversity$profession\nt = -5.7695, df = 744, p-value = 1.166e-08\nalternative hypothesis: true difference in means between group Sales Staff and group Professional Service is not equal to 0\n95 percent confidence interval:\n -0.06302979 -0.03102614\nsample estimates:\n         mean in group Sales Staff mean in group Professional Service \n                        0.09683168                         0.14385965 \n\nt.test(diversity$BAME ~ diversity$profession, var.equal = FALSE)\n\n\n    Welch Two Sample t-test\n\ndata:  diversity$BAME by diversity$profession\nt = -5.6553, df = 640.61, p-value = 2.345e-08\nalternative hypothesis: true difference in means between group Sales Staff and group Professional Service is not equal to 0\n95 percent confidence interval:\n -0.06335727 -0.03069866\nsample estimates:\n         mean in group Sales Staff mean in group Professional Service \n                        0.09683168                         0.14385965 \n\n\n\nThe result of Levene’s Test suggests that we should consider using the Welch Two Sample t-test because the variances of the two groups are not equal.\nThe p-value is 2.345e-08 for the t-test for unequal variances, which is less than 0.001. Therefore, we can conclude that there is a significant difference in the mean percentage of BAME employees between the two functions."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-ii",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#how-does-the-distribution-of-bame-employees-vary-across-different-professions-ii",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "How does the distribution of BAME employees vary across different professions? (II)",
    "text": "How does the distribution of BAME employees vary across different professions? (II)\n\nWhen comparing the “Sales Staff” and “Professional Service” functions, it becomes evident that the mean proportion of BAME staff is significantly lower in “Sales Staff” than in “Professional Service.”\nSpecifically, the average proportion of BAME staff in teams within the “Sales Staff” function is 9.7%, while in “Professional Service” teams, it stands at 14.39%.\nA more in-depth analysis reveals that the likelihood of this difference occurring by chance alone is less than 1 in 1,000, suggesting that there is a significant issue within the “Sales Staff” function that requires attention in the organization."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analyzing-bame-distribution-across-professional-functions",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#analyzing-bame-distribution-across-professional-functions",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Analyzing BAME distribution across professional functions",
    "text": "Analyzing BAME distribution across professional functions\n\nSummary statistics and graphical visualization offer a concise overview of the distribution of BAME employees in the two professions. It’s evident that more “Sales Staff” teams have a lower percentage of BAME employees, while “Professional Service” teams exhibit a more even distribution.\nThe results of the independent samples t-test, with a p-value close to 0, confirm a significant difference in the mean percentage of BAME employees between the two functions. This implies that there is an issue that needs attention within the “Sales Staff” function in the organization."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#recommendation",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#recommendation",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Recommendation",
    "text": "Recommendation\n\nAccording to our analysis, the organization faces challenges in BAME representation across professions, particularly in the “Sales Staff”.\nFurther research should be conducted to identify the factors influencing or associated with the diversity disparities between these two teams."
  },
  {
    "objectID": "posts/2023-10-11-summary-statistics-and-t-test/index.html#footnotes",
    "href": "posts/2023-10-11-summary-statistics-and-t-test/index.html#footnotes",
    "title": "Unlocking Insights (II): Analyzing Data with Summary Statistics and Independent Samples t-Test",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\n\n\nA typical boxplot. The ends of the box mark the quartiles, and the vertical line through the box is located at the median. The whiskers of a boxplot extend to values known as adjacent values. These are the values in the data that are furthest away from the median on either side of the box, but are still within a distance of 1.5 times the interquartile range from the nearest end of the box (that is, the nearer quartile). In many cases the whiskers actually extend right out to the most extreme values in the data set. However, in other cases they do not. Any values in the data set that are more extreme than the adjacent values are plotted as separate points on the boxplot. This identifies them as potential outliers that may need further investigation.\n\n\n↩︎"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html",
    "href": "posts/2024-01-15-key-driver-analysis/index.html",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "",
    "text": "In the competitive business landscape, every organization strives to cultivate a loyal customer base. This loyalty, often a result of trust and satisfaction with a company’s products and services, is a key driver of repeat business. Consequently, companies are increasingly focusing on identifying and enhancing the critical factors influencing customer loyalty and encouraging repeat investments.\nThis post will guide you on how to use key driver analysis to identify the essential factors that impact customer satisfaction and, consequently, customer loyalty."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#load-packages",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#load-packages",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Load packages",
    "text": "Load packages\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggtext)\nsource(\"helper_functions.R\")\nsource(\"theme_msd.R\")\nlibrary(janitor)"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#data-set2",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#data-set2",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Data Set2",
    "text": "Data Set2\n\nRead dataScan data\n\n\nThe data set includes responses from 2,507 customers and 8 variables.\n\n\nRows: 2,507\nColumns: 8\n$ Sat1             &lt;dbl&gt; 1, 2, 3, 3, NA, 3, 4, 1, 4, 3, 4, 3, 4, 5, 3, 3, 4, 4…\n$ Sat2             &lt;dbl&gt; 1, 3, 5, 4, NA, 3, 4, 2, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4…\n$ Sat3             &lt;dbl&gt; 1, 3, 4, 4, NA, 3, 4, 1, NA, 3, 4, 3, 3, 4, 5, 3, 4, …\n$ Sat4             &lt;dbl&gt; 3, 3, 5, 3, NA, 3, 5, 1, 5, 3, 4, 3, 4, 5, 4, 4, 4, 4…\n$ CustSatMean      &lt;dbl&gt; 1.50, 2.75, 4.25, 3.50, NA, 3.00, 4.25, 1.25, 4.67, 3…\n$ Custloyalty      &lt;dbl&gt; 4, 2, 2, 3, 5, 3, 4, 1, 3, 3, 4, 4, 4, 4, 1, 4, 4, 4,…\n$ INvestMore       &lt;dbl&gt; 3, 1, 3, 3, 3, 3, 2, 1, 3, NA, 2, 3, 3, 3, 3, 2, NA, …\n$ SexOfSalesperson &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n\n\n\n\nAll variables in the data set are numeric.\nFor each variable, there are missing values (NAs).\n\n\nCode\nskimr::skim(cssurvey_raw)\n\n\n\nData summary\n\n\nName\ncssurvey_raw\n\n\nNumber of rows\n2507\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSat1\n128\n0.95\n3.47\n1.04\n1\n3\n4.00\n4\n5\n▁▃▇▇▃\n\n\nSat2\n124\n0.95\n3.79\n0.95\n1\n3\n4.00\n4\n5\n▁▁▅▇▅\n\n\nSat3\n142\n0.94\n3.43\n1.10\n1\n3\n4.00\n4\n5\n▂▃▇▇▅\n\n\nSat4\n450\n0.82\n3.59\n0.98\n1\n3\n4.00\n4\n5\n▁▂▆▇▃\n\n\nCustSatMean\n66\n0.97\n3.56\n0.91\n1\n3\n3.67\n4\n5\n▁▂▆▇▆\n\n\nCustloyalty\n338\n0.87\n3.80\n1.10\n1\n3\n4.00\n5\n5\n▁▂▃▇▇\n\n\nINvestMore\n476\n0.81\n2.93\n0.82\n1\n3\n3.00\n3\n5\n▁▁▇▂▁\n\n\nSexOfSalesperson\n121\n0.95\n1.79\n0.41\n1\n2\n2.00\n2\n2\n▂▁▁▁▇"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#understanding-data-structure",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#understanding-data-structure",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Understanding data structure",
    "text": "Understanding data structure\n\nData structure:\n\nThe dataset consists of 2.507 rows, as per the description provided by the data source.\nIt contains 8 variables. Seven of them represent the questions from the survey, and an additional variable calculates the mean value of the customer satisfaction survey responses."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#understanding-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#understanding-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Understanding variables",
    "text": "Understanding variables\n\nData DictionaryProblems and Solutions\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDetail\nUnit\nRange\n\n\n\n\nSat1\nThe salesperson understanding your needs\nnumeric\n1-5\n\n\nSat2\nThe salesperson seems confident\nnumeric\n1-5\n\n\nSat3\nThe salesperson has a recommendation\nnumeric\n1-5\n\n\nSat4\nThe salesperson is knowledgeable\nnumeric\n1-5\n\n\nCustSatMean\nValue derived from mathematical operation (mean)  of customer responses\nnumeric\n1-5\n\n\nCustloyalty\nLikelihood of reinvesting\nnumeric\n1-5\n\n\nINvestMore\nHow much they may or may not reinvest\nnumeric\n1-5\n\n\nSexOfSalesperson\nGender\nnumeric\n1-2\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nProblem\nSolution\n\n\n\n\nSat1, Sat2, Sat3, Sat4\nvariables’names are not meaningful\nrename variables\n\n\nCustSatMean, Custloyalty, INvestMore\ninconsistent entries\nrename variables\n\n\nAll except CustSatMean\nvariable type is not numeric; they are ordinal and binary\nchange variable type\n\n\nAll except CustSatMean\nvariable labels\nassign labels"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#clean-name-and-rename-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#clean-name-and-rename-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Clean name and rename variables",
    "text": "Clean name and rename variables\n\nProblemSolution\n\n\nCustSatMean, Custloyalty, INvestMore have inconsistent entries (e.g. IN..More).\n\n\n\nClean names and rename these variables\n\n\n\nCode\n# use janitor::clean_name()\n\n(cssurvey_clean &lt;- cssurvey_raw|&gt;\n   rename(invest_more = INvestMore,\n          cust_loyalty = Custloyalty)|&gt;\n    clean_names())\n\n\n# A tibble: 2,507 × 8\n    sat1  sat2  sat3  sat4 cust_sat_mean cust_loyalty invest_more\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1     1     1     1     3          1.5             4           3\n 2     2     3     3     3          2.75            2           1\n 3     3     5     4     5          4.25            2           3\n 4     3     4     4     3          3.5             3           3\n 5    NA    NA    NA    NA         NA               5           3\n 6     3     3     3     3          3               3           3\n 7     4     4     4     5          4.25            4           2\n 8     1     2     1     1          1.25            1           1\n 9     4     5    NA     5          4.67            3           3\n10     3     4     3     3          3.25            3          NA\n# ℹ 2,497 more rows\n# ℹ 1 more variable: sex_of_salesperson &lt;dbl&gt;"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#assign-labels-and-rename-variables",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#assign-labels-and-rename-variables",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Assign labels and rename variables",
    "text": "Assign labels and rename variables\n\nProblemSolutionConfirm\n\n\n\nThe variable names ‘Sat1’, ‘Sat2’, ‘Sat3’, and ‘Sat4’ lack clarity. Although they are numeric in the data set, the data source classifies them as ordinal variables.\nThe variable ‘sex_of_salesperson’ could be more appropriately named as ‘gender’.\n\n\n\n\nCreate new variables based on the existing variables, rename variables, assign labels, and change variable type in factor.\n\n\n\nCode\n# Create new variables, assign labels, change variable type in factor\n\n(cssurvey_clean &lt;- cssurvey_clean |&gt;\n  mutate(undst_cust_need = factor(sat1,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         sales_confidence = factor(sat2,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         give_recomm = factor(sat3,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         product_know = factor(sat4,\n                         levels = c(1:5),\n                         labels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n         gender = factor(sex_of_salesperson,\n                           levels = c(1:2),\n                           labels = c(\"female\", \"male\"))))\n\n\n# A tibble: 2,507 × 13\n    sat1  sat2  sat3  sat4 cust_sat_mean cust_loyalty invest_more\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1     1     1     1     3          1.5             4           3\n 2     2     3     3     3          2.75            2           1\n 3     3     5     4     5          4.25            2           3\n 4     3     4     4     3          3.5             3           3\n 5    NA    NA    NA    NA         NA               5           3\n 6     3     3     3     3          3               3           3\n 7     4     4     4     5          4.25            4           2\n 8     1     2     1     1          1.25            1           1\n 9     4     5    NA     5          4.67            3           3\n10     3     4     3     3          3.25            3          NA\n# ℹ 2,497 more rows\n# ℹ 6 more variables: sex_of_salesperson &lt;dbl&gt;, undst_cust_need &lt;fct&gt;,\n#   sales_confidence &lt;fct&gt;, give_recomm &lt;fct&gt;, product_know &lt;fct&gt;, gender &lt;fct&gt;\n\n\n\n\n\n\nCode\ncssurvey_clean|&gt;\n  skimr::skim()\n\n\n\nData summary\n\n\nName\ncssurvey_clean\n\n\nNumber of rows\n2507\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n5\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nundst_cust_need\n128\n0.95\nFALSE\n5\nSat: 828, Neu: 747, Ver: 393, Dis: 315\n\n\nsales_confidence\n124\n0.95\nFALSE\n5\nSat: 1014, Neu: 620, Ver: 562, Dis: 125\n\n\ngive_recomm\n142\n0.94\nFALSE\n5\nSat: 780, Neu: 717, Ver: 417, Dis: 313\n\n\nproduct_know\n450\n0.82\nFALSE\n5\nSat: 803, Neu: 648, Ver: 360, Dis: 183\n\n\ngender\n121\n0.95\nFALSE\n2\nmal: 1884, fem: 502\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nsat1\n128\n0.95\n3.47\n1.04\n1\n3\n4.00\n4\n5\n▁▃▇▇▃\n\n\nsat2\n124\n0.95\n3.79\n0.95\n1\n3\n4.00\n4\n5\n▁▁▅▇▅\n\n\nsat3\n142\n0.94\n3.43\n1.10\n1\n3\n4.00\n4\n5\n▂▃▇▇▅\n\n\nsat4\n450\n0.82\n3.59\n0.98\n1\n3\n4.00\n4\n5\n▁▂▆▇▃\n\n\ncust_sat_mean\n66\n0.97\n3.56\n0.91\n1\n3\n3.67\n4\n5\n▁▂▆▇▆\n\n\ncust_loyalty\n338\n0.87\n3.80\n1.10\n1\n3\n4.00\n5\n5\n▁▂▃▇▇\n\n\ninvest_more\n476\n0.81\n2.93\n0.82\n1\n3\n3.00\n3\n5\n▁▁▇▂▁\n\n\nsex_of_salesperson\n121\n0.95\n1.79\n0.41\n1\n2\n2.00\n2\n2\n▂▁▁▁▇"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#percentage-of-responses-in-the-customer-survey-data",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#percentage-of-responses-in-the-customer-survey-data",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Percentage of Responses in the Customer Survey Data",
    "text": "Percentage of Responses in the Customer Survey Data\nSurveyed customers expressed satisfaction and high satisfaction with the ‘The salesperson seems confident’. However, they were less satisfied with ‘The salesperson understanding your needs’ and ‘The salesperson has a recommendation’.\n\n\nCode\n# Get the column names of the initial dataset\ninitial_order &lt;- colnames(cssurvey_clean)[9:12]\n\n\n# Calculate percentages for each category for each survey question\n\nkda &lt;- cssurvey_clean |&gt;\n  drop_na()|&gt;\n  pivot_longer(cols = 9:12, names_to = \"question\", values_to = \"value\" )|&gt;\n  mutate(question= factor(question,\n                          levels= initial_order))|&gt;\n  count(question, value) |&gt;\n  group_by(question)|&gt;\n  mutate(prtc = round(n/sum(n) * 100),\n         prtc = ifelse(row_number() == n(), 100 - sum(prtc[-n()]), prtc)) |&gt;\n  pivot_wider(id_cols = question, names_from = value, values_from = prtc)\n\nkda$question &lt;- c(\"The salesperson \\nunderstanding your needs\",\n                 \"The salesperson \\nseems confident\",\n                 \"The salesperson \\nhas a recommendation\",\n                 \"The salesperson \\nis knowledgeable\")\n\nkda|&gt;\n  kableExtra::kable(col.names = c(\"Question\", \"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\"),\n                    align = \"lccccc\",\n                    caption = \"Customer Satisfaction with Salesperson Competencies (%)\")\n\n\n\nCustomer Satisfaction with Salesperson Competencies (%)\n\n\nQuestion\nVery Dissatisfied\nDissatisfied\nNeutral\nSatisfied\nVery Satisfied\n\n\n\n\nThe salesperson understanding your needs\n4\n14\n33\n35\n14\n\n\nThe salesperson seems confident\n2\n6\n27\n43\n22\n\n\nThe salesperson has a recommendation\n5\n14\n31\n33\n17\n\n\nThe salesperson is knowledgeable\n3\n9\n33\n39\n16\n\n\n\n\n\n\n\n\n\nCode\ntheme_set(theme_msd() + theme(\n  axis.title.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.text.y = element_text(color = GRAY3, size = 10),\n  panel.border = element_blank(),\n  axis.line = element_line(),\n  axis.title.x = element_text(hjust = 0.03, color = GRAY6, size = 10),\n  axis.text.x = element_text(size = 8),\n  plot.subtitle = element_markdown(hjust = 0.65),\n  axis.line.y = element_blank()\n))\n\n\ndf &lt;- kda |&gt;\n  rename(Item = \"question\") |&gt;\n  pivot_longer(cols = -Item, names_to = \"Answer\", values_to = \"Value\") |&gt;\n  mutate(\n    Answer = factor(Answer, levels = c(\"Very Dissatisfied\", \"Dissatisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\")),\n    Value = as.numeric(Value) /100\n  )\n\ndf$Answer &lt;- fct_rev(df$Answer)\n\n\n\ncolor_scale &lt;- c(\n  \"Very Dissatisfied\" = GRAY2,\n  \"Dissatisfied\" = GRAY2,\n  \"Neutral\" = GRAY9,\n  \"Satisfied\" = GRAY5,\n  \"Very Satisfied\" = GRAY5)\n\n\nformatted_subtitle &lt;- paste0(\n  \"&lt;span style='color:\", color_scale[1], \"'&gt;**\", names(color_scale)[1], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[2], \"'&gt;**\", names(color_scale)[2], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[3], \"'&gt;**\", names(color_scale)[3], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[4], \"'&gt;**\", names(color_scale)[4], \"**&lt;/span&gt;\",\n  \" | \",\n  \"&lt;span style='color:\", color_scale[5], \"'&gt;**\", names(color_scale)[5], \"**&lt;/span&gt;\"\n)\n\npt &lt;- df |&gt;\n  ggplot(aes(y = Item, x = Value, fill = Answer)) +\n  geom_bar(stat = \"Identity\", width = 0.65, color = \"white\") +\n  scale_fill_manual(values = color_scale, guide = \"none\") +\n  labs(\n    title = \"Customer Satisfaction with Salesperson Competencies \\n\",\n    subtitle = formatted_subtitle,\n    x = \"\\nPercent of total\"\n  ) +\n  scale_x_continuous(position = \"top\", \n                     breaks = seq(0,1,by = 0.2),\n                     labels = scales::percent_format(accuracy = 1)) +\n  lemon::coord_capped_cart(top = \"both\")\n\npt |&gt;\n  save_and_show_plot(width = 6, height = 4, \"FIG01.png\")"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#correlation",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#correlation",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Correlation",
    "text": "Correlation\nAnother approach to analyzing the customer survey data is through correlation. Correlation is a statistical measure of the relationship between two variables, how they are interconnected.\nAmong the four questions on the survey, at this stage, I aim to identify which ones have the strongest correlation with the question related to customer loyalty: the likelihood of reinvestment.\n\n\nCode\n# Correlation for several pairs of variables\n     \ncor_cust_loyalty &lt;- cssurvey_clean |&gt;\n  select(sat1, sat2, sat3, sat4, cust_loyalty)|&gt;\n  cor(method = \"spearman\",\n      use = \"pairwise.complete.obs\")|&gt;\n  round(digits = 2)\n\nsurvey_quest = c(\"The salesperson understanding your needs\",\n                 \"The salesperson seems confident\",\n                 \"The salesperson has a recommendation\",\n                 \"The salesperson is knowledgeable\")\n\n                        \ncor_to_cust_loyalty = c(0.49, 0.37, 0.49, 0.40)\n                            \n(cor_matrix &lt;- tibble(survey_quest, cor_to_cust_loyalty)|&gt;\n    arrange(desc(cor_to_cust_loyalty))|&gt;\n  kableExtra::kable(col.names = c(\"Survey Question\", \"Correlation to \\nCustomer Loyalty\"),\n                    align = \"lr\",\n                    caption = \"Correlation of survey questions to customer loyalty\"))\n\n\n\nCorrelation of survey questions to customer loyalty\n\n\nSurvey Question\nCorrelation to Customer Loyalty\n\n\n\n\nThe salesperson understanding your needs\n0.49\n\n\nThe salesperson has a recommendation\n0.49\n\n\nThe salesperson is knowledgeable\n0.40\n\n\nThe salesperson seems confident\n0.37\n\n\n\n\n\n\n\n‘The salesperson understanding your needs’ , ‘The salesperson has a recommendation’ , and ‘The salesperson is knowledgeable’ are the most highly correlated to the question related to loyalty (0.49, respectively 0.40). The company might see these areas to focus in its efforts to improve customer loyalty."
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#consolidating-the-percentage-and-correlation",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#consolidating-the-percentage-and-correlation",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Consolidating the Percentage and Correlation",
    "text": "Consolidating the Percentage and Correlation\nIn this step, I will integrate the customer satisfaction questions and their correlation to customer loyalty into a unified view for enhanced insights. To calculate the customer’s importance of loyalty, I calculated the percentage of dissatisfied and very dissatisfied customers in a single metric, percent dissatisfaction. The ‘Customer Loyalty Importance’ is a calculated metric that combines percent dissatisfaction and the correlation to customer loyalty in one measure (see the table below). It allows us to rank survey questions by importance.\n\n\nCode\n# we need to consolidate data from \"kda\" data set and \"cor_matrix\" data set\n\n# define cor_matrix as data frame\n\ncor_matrix &lt;- as.data.frame(cor_matrix)\n\ncor_matrix &lt;- tibble(survey_quest, cor_to_cust_loyalty)\n\n\nkda_cor &lt;- bind_cols(kda, cor_matrix)\n  \n            \nkda_cor &lt;- kda_cor |&gt;\n  mutate(percent_dissatisfied = Dissatisfied + `Very Dissatisfied`,\n         percent_satisfied = Satisfied + `Very Satisfied`,\n         percent_neutral = Neutral) |&gt;\n  group_by(percent_dissatisfied, cor_to_cust_loyalty) |&gt;\n  mutate(cust_loyalty_importance = percent_dissatisfied*cor_to_cust_loyalty)|&gt;\n  ungroup()\n \n\nkda_consolidate &lt;- kda_cor |&gt;\n  select(question, percent_dissatisfied, cor_to_cust_loyalty, cust_loyalty_importance)|&gt;\n  arrange(desc(cust_loyalty_importance))|&gt;\n  kableExtra::kable(col.names = c(\"Survey Question\", \"Percent Dissatisfaction\", \"Correlation to \\nCustomer Loyalty\", \"Customer Loyalty \\nImportance\"),\n                    align = \"lrrr\",\n                    caption = \"Customer Satisfaction items ranked by importance\")\n  \nkda_consolidate\n\n\n\nCustomer Satisfaction items ranked by importance\n\n\nSurvey Question\nPercent Dissatisfaction\nCorrelation to Customer Loyalty\nCustomer Loyalty Importance\n\n\n\n\nThe salesperson has a recommendation\n19\n0.49\n9.31\n\n\nThe salesperson understanding your needs\n18\n0.49\n8.82\n\n\nThe salesperson is knowledgeable\n12\n0.40\n4.80\n\n\nThe salesperson seems confident\n8\n0.37\n2.96\n\n\n\n\n\n\n\nWhat is the data from the table telling us?\n\n\nCode\ntheme_set(theme_msd() + theme(\n  axis.title.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.text.y = element_text(color = GRAY3, size = 10),\n  panel.border = element_blank(),\n  axis.line = element_line(),\n  axis.title.x = element_text(hjust = 0.03, color = GRAY6, size = 9),\n  axis.text.x = element_text(color = GRAY3, size = 10),\n  plot.subtitle = element_markdown(hjust = 0),\n  axis.line.y = element_blank()\n))\n\n\nkda_consolidate_plot &lt;- kda_cor |&gt;\n  mutate(question = fct_reorder(question, cust_loyalty_importance))|&gt;\n  ggplot(aes(x = cust_loyalty_importance, y = question))+\n  geom_bar(stat = \"identity\", width = 0.6, color = GRAY2)+\n  geom_text(aes(label = cust_loyalty_importance), hjust = -0.15, size = 3.5)+\n  labs(\n    title = \"The sales person having a recommendation and understanding customers \\nneeds are the issues that require some improvments \\n\",\n    subtitle = \"\",\n    x = \"Customer Loyalty Importance\"\n  )\n  \n  \nkda_consolidate_plot |&gt;\n  save_and_show_plot(width = 6.5, height = 4, \"FIG02.png\")"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#key-driver-analysis-results",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#key-driver-analysis-results",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Key Driver Analysis Results",
    "text": "Key Driver Analysis Results\nThe findings of the key driver analysis are presented below in a key driver quadrant. It allows us to see the two intersecting information points: the correlation of the four survey questions to customer loyalty, our chosen indicator to understand (axis x), and the satisfaction of customers’ responses (axis y).\nKey drivers for customer loyalty\n\nImprove Weakness: The correlation to customer loyalty is 0.49, and customer satisfaction is low (dissatisfied and very dissatisfied). In the lower right quadrant of the key driver analysis chart, customer satisfaction with the salesperson competency “has a recommendation” is 19%, and with the salesperson competency “understanding your needs” is 18%. On the upper side of this quadrant, it is essential to note the significant percentage of neutral responses for these two questions.\nLeverage Great: The correlation to customer loyalty is 0.49, and customer satisfaction is high (satisfied and very satisfied). In the upper right quadrant, customer satisfaction with salesperson competency “has a recommendation” is 50%, and with salesperson competency “understanding your needs” is 49%.\nDisregard: The remaining survey questions have a mix of positive and negative customer responses. However, they are not as important for customer loyalty as the other two questions.\n\n\n\n\n\n\n\nKey driver analysis explores a wide range of measures to uncover what is most important in influencing the chosen objective. It helps you understand where to focus your energy and resources to obtain the results you are looking for.\n\n\n\n\n\nCode\nlibrary(glue)\nlibrary(grid)\n\n# Data ----\n# |- KDA Quadrant ----\n\n# First, I organize columns and rows in the data frame to make easier \n# to work with. I made a column \"sum_satisfaction\" with 3 categories where\n# I summed up the percentage of categories satisfied and very satisfied, dissatisfied and very dissatisfied and neutral to keep the plot simple to visualize\n\nkda_quadrant &lt;- kda_cor |&gt;\n    pivot_longer(cols = 2:6, names_to = \"satisfaction\", values_to = \"score\")\n\nkda_quadrant &lt;- kda_quadrant|&gt;\n  pivot_longer(cols = c(4:6), names_to = \"sum_satisfaction\", values_to = \"percent_score\")\n\n# Set the theme for the plot\n\ntheme_set(theme_msd()+ theme(\n  axis.text.y = element_text(color = GRAY6, size = 9),\n  axis.title.x = element_text(color = GRAY6, size = 10, margin = margin(6, 0, 15, 0, \"pt\")),\n  axis.title.y = element_text(color = GRAY6, size = 10),\n  axis.text.x = element_text(color = GRAY6, size = 9, margin = margin(0, 6, 0, 15, \"pt\"))\n))\n\n# Set seed for reproducible plot\n\nset.seed(123)\n\n\n# Plot ----\n# |- Palette ----\nsurvey_quest_palette &lt;- list(\"The salesperson has a recommendation\" = \"#1A242F\",\n                             \"The salesperson understanding your needs\" = \"#94989D\",\n                             \"The salesperson seems confident\" = \"#1A242F\",\n                             \"The salesperson is knowledgeable\" = \"#1A242F\",\n                             \"dark_text\" = \"#1A242F\",\n                             \"light_text\" = \"#94989D\")\n\n# |- Shape ----\n\nsurvey_quest_shape &lt;- list(\"The salesperson has a recommendation\" = 22,\n                             \"The salesperson understanding your needs\" = 21,\n                             \"The salesperson seems confident\" = 0,\n                             \"The salesperson is knowledgeable\" = 1)\n\n# Create text grobs for the labels with a specific font size and color\n\nlabel1 &lt;- textGrob(\"Very Dissatisfied\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6) )\nlabel2 &lt;- textGrob(\"Neutral\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6))\nlabel3 &lt;- textGrob(\"Very Satisfied\", rot = 90, gp = gpar(fontsize = 9, col = GRAY6))\nlabel4 &lt;- textGrob(\"Low\", gp = gpar(fontsize = 9, col = GRAY6))\nlabel5 &lt;- textGrob(\"High\", gp = gpar(fontsize = 9, col = GRAY6))\n\n\n\n# | Quadrant Plot ----\n# | - Quadrant Base Panel ----\n\nquadrant_base &lt;- kda_quadrant|&gt;\n  ggplot(aes(x = cor_to_cust_loyalty,\n             y = percent_score))+\n  scale_x_continuous(expand = c(0,0),limits = c(0.3,0.6))+\n  scale_y_continuous(expand = c(0,0),\n                     limits = c(0,80),\n                     breaks = c(0, 30, 50, 80), \n                     labels = c(\"0\" = \"0\", \"30\" = \"30%\", \"50\" = \"50%\", \"80\" = \"80%\"))+\n\n # Add the labels to the plot using annotation_custom()\n   \n \n  annotation_custom(grob = label1, xmin = 0.292, xmax = 0.292, ymin = 9, ymax = 9) +\n  annotation_custom(grob = label2, xmin = 0.292, xmax = 0.292, ymin = 36, ymax = 36) +\n  annotation_custom(grob = label3, xmin = 0.292, xmax = 0.292, ymin = 65, ymax = 65) +\n  annotation_custom(grob = label4, ymin = -2.5, ymax = -2.5, xmin = 0.35, xmax = 0.35)+\n  annotation_custom(grob = label5, ymin = -2.5, ymax = -2.5, xmin = 0.55, xmax = 0.55)+ \n  coord_cartesian(clip = \"off\")+\n  theme(axis.line = element_blank())\n \n   \n\n\n# | - Quadrant Chart ----\n\n# Set axis labels and title\n\nlabelled_quadrant &lt;-  quadrant_base +\n    labs(x = \"Correlation to customer loyalty\",\n         y = \"Customer satisfaction survey\",\n        title = \"Customer Loyalty Key Driver Report\\n\")+\n   theme(axis.title.x = element_text(hjust = 0.5,\n                                     vjust = 4,\n                                     face = \"bold\"),\n         axis.title.y = element_text(hjust = 0.5,\n                                     vjust = 0,\n                                     face = \"bold\"),\n        plot.title = element_text(color = GRAY2, size= 12),\n        plot.title.position = \"plot\"\n         )+\n \n\n  \n# add four rectangle type of annotations to fill the four quadrant areas\n# create a border and split lines for the quadrant chart\n  \n  annotate(\"rect\", xmin = 0.45, xmax = 0.60, ymin = 40, ymax = 80, fill= \"#F8F9F9\")+\n  annotate(\"rect\", xmin = 0.3, xmax = 0.60, ymin = 0, ymax = 80 , fill= \"#F8F9F9\")+\n  annotate(\"rect\", xmin = 0.45, xmax = 0.60, ymin = 40, ymax = 80, fill= \"white\")+\n  annotate(\"rect\", xmin = 0.3, xmax = 0.60, ymin = 0, ymax = 80, fill= \"white\")+\n  theme(panel.border = element_rect(colour = \"lightgrey\", fill = NA, linewidth = 3))+\n  geom_hline(yintercept= 40, color = \"lightgrey\", linewidth =1.5)+\n  geom_vline(xintercept= 0.45, color = \"lightgrey\", linewidth =1.5) +\n          \n# add label to quadrant area\n\n  geom_label(aes(x = 0.375,\n                 y = 77,\n                 label = \"DISREGARD\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  geom_label(aes(x = 0.525,\n                 y = 77,\n                 label = \"LEVERAGE GREAT\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  geom_label(aes(x = 0.525,\n                 y = 3,\n                 label = \"IMPROVE WEAKNESS\"),\n             label.padding = unit(2, \"mm\"),\n             fill = \"lightgrey\",\n             color = \"white\")+\n  \n# draw the questions survey to the chart with the position corresponding to their “customer satisfaction percent” value and “correlation to customer” value.\n  \n   geom_jitter(aes(x = cor_to_cust_loyalty,\n             y = percent_score,\n             color = survey_quest,\n             shape = survey_quest,\n             fill = survey_quest),\n         size = 5,\n         alpha = 0.8)+\n  theme( legend.position = \"top\",\n         legend.box = \"vertical\",\n         legend.margin = margin(unit(c(0,-0.45,0,0), \"cm\")),\n         legend.title = element_blank(),\n         legend.text = element_text(color = GRAY6, size = 9)) +\n  guides(shape = guide_legend(nrow = 2, byrow = TRUE),\n         fill = guide_legend(nrow = 2, byrow = TRUE),\n         color = guide_legend(nrow = 2, byrow = TRUE))+\n  scale_colour_manual(values = survey_quest_palette) +\n  scale_shape_manual(values = survey_quest_shape) +\n  scale_fill_manual(values = survey_quest_palette)\n   \n\n\nlabelled_quadrant"
  },
  {
    "objectID": "posts/2024-01-15-key-driver-analysis/index.html#footnotes",
    "href": "posts/2024-01-15-key-driver-analysis/index.html#footnotes",
    "title": "Key Driver Analysis to understand customer loyalty in a financial organization (case study)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe case study and the data description are sourced from the book Predictive HR Analytics : Mastering the HR Metric by Dr. Martin R. Edwards and Kirsten Edwards↩︎\nData available here↩︎\nI learned about this analysis in the book People Analytics For Dummies by Mike West↩︎"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#questions-and-solutions",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#questions-and-solutions",
    "title": "Sales Revenue and Orders",
    "section": "Questions and Solutions",
    "text": "Questions and Solutions\n\nWhat is the annual variation in sales revenue and number of orders?\nWhat is the monthly variation in sales revenue?\nHow do monthly revenue and orders compare to the yearly average?"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#steps-to-answer-the-questions",
    "title": "Sales Revenue and Orders",
    "section": "Steps to answer the questions",
    "text": "Steps to answer the questions\n\nIdentify the tables that contain the sales revenue and order data\nUnderstand the schema, columns that store date, sales, and orders\nUse SQL and R to retrieve, prepare and summarize data\nData Visualization\nData Interpretation\n\n\nPrerequisites\n\nlibrary(DBI) \nlibrary(dbplyr)\nlibrary(tidyverse) \nlibrary(knitr)\nlibrary(DT)\nlibrary(patchwork)\nlibrary(glue)\ntheme_set(theme_minimal(base_size = 12))\n\n\n\nConnect to the database\n\ncon &lt;- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = 'northwind', \n                 host = 'localhost', \n                 port = 5432, \n                 user = 'postgres',\n                 password = 'postgres')\n \ndbListTables(conn = con) ## list tables in the database\n\n [1] \"us_states\"              \"customers\"              \"orders\"                \n [4] \"employees\"              \"shippers\"               \"products\"              \n [7] \"order_details\"          \"categories\"             \"suppliers\"             \n[10] \"region\"                 \"territories\"            \"employee_territories\"  \n[13] \"customer_demographics\"  \"customer_customer_demo\" \"sales_revenue\"         \n\n\nThe data used to answer the questions can be found in two tables: orders and order_details.\n\n\nEntity Relationship Diagram\n\n\n\n\n\nSource DBeaver"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-variation-in-sales-revenue-and-number-of-orders",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-variation-in-sales-revenue-and-number-of-orders",
    "title": "Sales Revenue and Orders",
    "section": "What is the annual variation in sales revenue and number of orders?",
    "text": "What is the annual variation in sales revenue and number of orders?\n\nsales_revenue &lt;- \"\n\nselect \n    min(o.order_date) as start_date,\n    max(o.order_date) as end_date,\n    extract(year from o.order_date) as year,\n    count(*) as order_number,\n    round(cast(sum(od.unit_price* od.quantity) as numeric),\n    2) as total_revenue,\n    round(cast(avg(od.unit_price* od.quantity)as numeric),\n    2) as avg_revenue\nfrom public.order_details od\ninner join public.orders as o on od.order_id = o.order_id\ngroup by year\norder by year;\n\"\nsales_revenue_tbl &lt;- (dbGetQuery(con, sales_revenue))\n\n\nkable(sales_revenue_tbl)\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nend_date\nyear\norder_number\ntotal_revenue\navg_revenue\n\n\n\n\n1996-07-04\n1996-12-31\n1996\n405\n226298.5\n558.76\n\n\n1997-01-01\n1997-12-31\n1997\n1059\n658388.8\n621.71\n\n\n1998-01-01\n1998-05-06\n1998\n691\n469771.3\n679.84\n\n\n\nAnnual summary of sales, number of orders and average sale\n\n\n\n\nCode\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\n\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\norder_number &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = as.numeric(order_number)))+\n  geom_col()+\n  geom_text(aes(label = as.numeric(order_number)), vjust = 1.5, color = \"white\")+\n  labs(\n    title = \"Number of Orders per Year\",\n    x = NULL,\n    y = \"Total Number of Orders\"\n  )+\n   theme_minimal()\n\navg_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = avg_revenue))+\n  geom_col()+\n  geom_text(aes(label = avg_revenue), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Average Dollars per Sale\",\n    x = \"Years between July 04, 1996 to May 06, 1998\",\n    y = \"Average Sale Amount\"\n  )+\n   theme_minimal()\n\n(total_revenue  + plot_spacer() + order_number + plot_layout(widths = c(4, -1, 4))) / avg_revenue\n\n\n\n\n\nNorthwind annual sales performance\n\n\n\n\n\nInsights\n\nAs 1996 and 1998 are shorter than 1997, interpreting comparisons is difficult.\nThe sales revenue and the number of orders for the first five months of 1998 are greater than those for the last five months for the year of 1996. Since the comparison is not for the same period or consecutive years, it is difficult to determine if the sales are trending upward, downward, or flat. However even though the context is different, we can say that we have an evolution with sales revenue doubling in five months in 1998 compared with five months in 1996.\nFor each year, the average dollar amount of sales increases from year to year based on the average dollar amount of sales.\n\nHow about the monthly sales?"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-monthly-variation-in-sales-revenue",
    "title": "Sales Revenue and Orders",
    "section": "What is the monthly variation in sales revenue?",
    "text": "What is the monthly variation in sales revenue?\nTo have the monthly sales revenue and number of orders, the previous query is modified as follows:\n\nmonthly_revenue &lt;- \"\nselect \n    cast(date_trunc('month', o.order_date) as date) as sales_month,\n    count(*) as total_number,\n    round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\nfrom public.orders o \ninner join public.order_details od on o.order_id = od.order_id \ngroup by sales_month\norder by sales_month;\n\"\nmonthly_revenue_tbl &lt;- (dbGetQuery(con, monthly_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\nNext, let’s create a graph to visualize the monthly sales data.\n\n\nCode\nmin_order_date &lt;- min(sales_revenue_tbl$start_date)\nmax_order_date &lt;- max(sales_revenue_tbl$end_date)\n\n(monthly_revenue_plot &lt;- ggplot(monthly_revenue_tbl, aes(x = sales_month, y = monthly_revenue))+\n  geom_col()+\n  scale_y_continuous(labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Sales by Month \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Sales Dollars\"\n  )+\n  theme_minimal())\n\n\n\n\n\nNorthwind monthly sales performance\n\n\n\n\nThe graph shows that there is much variation from one month to another. As there is month-over-month sales variation we can use the lag() function (SQL) to help to see the differences.\n\nmonthly_var_revenue &lt;- \"\nwith monthly_revenue as\n    (select \n        cast(date_trunc('month', o.order_date) as date) as sales_month,\n        count(*) as total_number,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    group by sales_month\n    order by sales_month),\n    prev_month_revenue as\n    (select \n        mr.sales_month,\n        mr.total_number,\n        mr.monthly_revenue,\n        lag(mr.monthly_revenue, 1, mr.monthly_revenue) over (order by mr.sales_month) as prev_month_revenue\n    from monthly_revenue mr)\nselect\n    pmr.sales_month,\n    pmr.total_number,\n    pmr.monthly_revenue,\n    prev_month_revenue,\n    pmr.monthly_revenue - pmr.prev_month_revenue as delta_revenue\nfrom prev_month_revenue pmr;\n\"\nmonthly_var_revenue_tbl &lt;- (dbGetQuery(con, monthly_var_revenue))\n\n\n\n\n\nMonthly sales revenue and number of orders\n\n\nAlso, based on the graph, it is evident that the data follows a left-tailed distribution. I will utilize the summary() function in R to examine the descriptive statistics.\n\nmedian(monthly_var_revenue_tbl$delta_revenue)\n\n[1] 3707\n\n(summary_delta_revenue &lt;- summary(monthly_var_revenue_tbl$delta_revenue))\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-114732.0   -2405.0    3707.0    -447.5   14643.5   31563.0 \n\n\nThe median is positive ($3.707) while the mean is negative: (447.5). Month-over-month sales data shows a wide spread between the lower and upper quartiles.\nThe plot below shows how the sales vary month-over-month.\n\n\nCode\n(monthly_var_revenue_plot &lt;- ggplot(monthly_var_revenue_tbl, aes(x = sales_month, y = delta_revenue))+\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\", date_minor_breaks = \"3 months\") +\n  geom_line()+\n  scale_y_continuous(limits = c(-200000, 150000), labels = scales::dollar_format())+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue(\"Monthly Sales Variation \\n\",\n                 \"Between \", {format(min_order_date, \"%B %d, %Y\")}, \" and \",\n                 {format(max_order_date, \"%B %d, %Y\")}\n  ),\n  x = \"Month\",\n  y = \"Dollars Change\"\n  )+\n  theme_minimal()\n  )\n\n\n\n\n\nNorthwind monthly sales variation\n\n\n\n\n\nInsights\n\nWith real data, we would want to investigate more to understand the business context that occurred in May of 1998.\nFrom the data available in the Northwind database, we know that the data collection ended at the beginning of May 1998 which can explain the high difference compared with the previous month.\n\nWe have the data for the entire year of 1997 and we can look at revenue and number of orders together and compare the monthly data to the yearly average. By comparing monthly sales to yearly average, businesses can identify which months consistently perform above or below average, helping in informing various business decisions."
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#how-do-monthly-revenue-and-orders-compare-to-the-yearly-average",
    "title": "Sales Revenue and Orders",
    "section": "How do monthly revenue and orders compare to the yearly average?",
    "text": "How do monthly revenue and orders compare to the yearly average?\n\nmonth_data_year_avg &lt;- \"\nwith montly_data as\n    (select \n        cast(date_trunc('month', o.order_date) as date) year_month,\n        count(*) as monthly_orders,\n        round(cast(sum(od.unit_price* od.quantity)as numeric)) as monthly_revenue\n    from public.orders o \n    inner join public.order_details od on o.order_id = od.order_id \n    where extract(year from o.order_date) = 1997 \n    group by year_month\n    order by year_month)\nselect\n    md.year_month,\n    md.monthly_orders, \n    md.monthly_revenue\nfrom montly_data md\norder by md.year_month;\n\"\nmonth_data_year_avg_tbl &lt;- (dbGetQuery(con,month_data_year_avg))\n\n\n\n\n\nMonthly sales data and Yearly averages\n\n\n\n(yearly_revenue_average &lt;- mean(month_data_year_avg_tbl$monthly_revenue))\n\n[1] 54865.67\n\n(yearly_order_average &lt;- mean(month_data_year_avg_tbl$monthly_orders))\n\ninteger64\n[1] 88\n\n\n\n\nCode\nmonth_data_year_avg_rev_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = monthly_revenue))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  geom_hline(yintercept = yearly_revenue_average ,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_revenue_average +1000,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Revenue Average \\n\",\n                  \"Monthly Revenue \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Revenue Dollars\"\n  )+\n  theme_minimal()\n\n\nmonth_data_year_avg_order_plot &lt;- ggplot(month_data_year_avg_tbl, aes(x = year_month, y = as.numeric(monthly_orders)))+\n  geom_line()+\n  scale_x_date(date_labels = \"%m\", date_minor_breaks = \"1 month\")+\n  geom_hline(yintercept = yearly_order_average,\n             color = \"darkred\",\n             linetype = \"dashed\")+\n  annotate(\"text\",\n           x = min(month_data_year_avg_tbl$year_month),\n           y = yearly_order_average +1,\n           label = \"AVG\",\n           color = \"darkred\",\n           hjust = 0\n           )+\n  theme(\n    plot.title = element_text(size= 12),\n    plot.title.position = \"plot\"\n  )+\n  labs(\n    title = glue( \"Yearly Order Average \\n\",\n                  \"Monthly Orders \\n\",\n                  \"Year 1997\"),\n    x = \"Date\",\n    y = \"Number of Orders\"\n  )+\n  theme_minimal()\n\n\nmonth_data_year_avg_rev_plot + plot_spacer() + month_data_year_avg_order_plot+ plot_layout(widths = c(4, -1, 4))\n\n\n\n\n\n\n\n\n\n\nInsights\n\nBoth the monthly sales revenue and number of orders vary widely compared with the yearly average.\nThe highest values for sales revenue are at the beginning and the end of the year while the lowest values are in the first half of the year. This indicates that the business can have seasonal fluctuations in sales.\nThis is also supported by the number of orders placed each month. The highest number of orders is in the second half of the year which can explain the increased revenue at the final of the year.\n\nKnowing in which months the business performs below or above the average can help in the strategic planning of the company and the allocation of resources.\n\nFor example :\n\nwhen the sales volumes are low the business can design loyalty programs that encourage repeated business during slower months;\nduring off-peak times the company can plan training programs to ensure that the staff are fully equipped for busy periods;\ntargeted campaigns by allocating budgets to peak seasons to maximize returns or promotions during low-performing months to increase sales.\n\n\nComparing monthly sales data to yearly averages is a powerful analytical tool that provides deep insights into business performance, aids in strategic planning and drives informed decision-making. It allows businesses to adapt proactively to changes, optimize operations, and achieve better financial outcomes.\n\n# Close the database connection\ndbDisconnect(con)"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html",
    "title": "Sales Revenue and Orders",
    "section": "",
    "text": "For this analysis, I will use sales data from Northwind database1 to answer the following questions:"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-sales-revenue-and-number-of-orders",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#what-is-the-annual-sales-revenue-and-number-of-orders",
    "title": "Sales Revenue and Orders",
    "section": "What is the annual sales revenue and number of orders?",
    "text": "What is the annual sales revenue and number of orders?\n\nsales_revenue &lt;- \"\n\nselect \n    min(o.order_date) as start_date,\n    max(o.order_date) as end_date,\n    extract(year from o.order_date) as year,\n    count(*) as order_number,\n    round(cast(sum(od.unit_price* od.quantity) as numeric),\n    2) as total_revenue,\n    round(cast(avg(od.unit_price* od.quantity)as numeric),\n    2) as avg_revenue\nfrom public.order_details od\ninner join public.orders as o on od.order_id = o.order_id\ngroup by year\norder by year;\n\"\nsales_revenue_tbl &lt;- (dbGetQuery(con, sales_revenue))\n\n\nkable(sales_revenue_tbl)\n\n\n\n\n\n\n\n\n\n\n\n\nstart_date\nend_date\nyear\norder_number\ntotal_revenue\navg_revenue\n\n\n\n\n1996-07-04\n1996-12-31\n1996\n405\n226298.5\n558.76\n\n\n1997-01-01\n1997-12-31\n1997\n1059\n658388.8\n621.71\n\n\n1998-01-01\n1998-05-06\n1998\n691\n469771.3\n679.84\n\n\n\nAnnual summary of sales, number of orders and average sale\n\n\n\n\nCode\ntotal_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y =(total_revenue/1000)))+\n  geom_col()+\n  geom_text(aes(label = round(total_revenue/1000)), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Total Sales Revenue per Year - Thousands\",\n    x = NULL,\n    y = \"Sales $M\"\n  )+\n   theme_minimal()\n\norder_number &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = as.numeric(order_number)))+\n  geom_col()+\n  geom_text(aes(label = as.numeric(order_number)), vjust = 1.5, color = \"white\")+\n  labs(\n    title = \"Number of Orders per Year\",\n    x = NULL,\n    y = \"Total Number of Orders\"\n  )+\n   theme_minimal()\n\navg_revenue &lt;- ggplot(sales_revenue_tbl, aes(x = year, y = avg_revenue))+\n  geom_col()+\n  geom_text(aes(label = avg_revenue), vjust = 1.5, color = \"white\")+\n  scale_y_continuous(labels = scales::dollar_format())+\n  labs(\n    title = \"Average Dollars per Sale\",\n    x = \"Years between July 04, 1996 to May 06, 1998\",\n    y = \"Average Sale Amount\"\n  )+\n   theme_minimal()\n\n(total_revenue  + plot_spacer() + order_number + plot_layout(widths = c(4, -1, 4))) / avg_revenue\n\n\n\n\n\nNorthwind annual sales performance\n\n\n\n\n\nInsights\n\nThe available periods for 1996 and 1998 are shorter than those for 1997, making it difficult to interpret comparisons.\nThe graph shows that the sales revenue and the number of orders for the first five months of 1998 are greater than those for the last six months of the year 1996. However, since the data is not for the same period or consecutive years, it is difficult to determine the sales trend. Even though the context is different, we can say that sales revenue doubled in the first four months of 1998 compared with the last six months of 1996.\nIn the absence of data for an entire year for more than one year, we can look at the average dollar amount of sales. Based on the average dollar amount of sales, the graph shows an increase from year to year.\n\nHow about the monthly sales?"
  },
  {
    "objectID": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#footnotes",
    "href": "data_analysis/sales_revenue/1_sales_revenue_and_orders.html#footnotes",
    "title": "Sales Revenue and Orders",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Northwind database is a sample database that was originally created by Microsoft for demonstrating the features of their database management systems. It contains a variety of tables and data related to a fictional company called Northwind Traders, which imports and exports specialty foods from around the world.↩︎"
  }
]